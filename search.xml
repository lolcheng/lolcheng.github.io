<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>第一篇文章</title>
      <link href="/2024/04/03/2024-4-3/"/>
      <url>/2024/04/03/2024-4-3/</url>
      
        <content type="html"><![CDATA[<h2 id="这是我的第一篇文章"><a href="#这是我的第一篇文章" class="headerlink" title="这是我的第一篇文章"></a>这是我的第一篇文章</h2>]]></content>
      
      
      <categories>
          
          <category> 其他 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2024/04/03/hello-world/"/>
      <url>/2024/04/03/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      <categories>
          
          <category> 其他 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>AlphaZero算法</title>
      <link href="/2022/08/09/AlphaZero/"/>
      <url>/2022/08/09/AlphaZero/</url>
      
        <content type="html"><![CDATA[<p>蒙特卡洛树搜索：</p><p>UCB(Upper Confidence Bound/上限置信区间)：探索-利用(Exploration-Exploitation)，基于过去产生的平均回报和对未来期望回报的累加，UCB1值最高的被认为是最有潜力的节点，即那些过去产生过很大价值，或是那些过去没有探索过但可能会产生更大价值的节点。</p><p>n代表number of visits，指访问次数</p><p>左半式为了找到最大的价值，右半式为了广泛探索可能</p><p>Value和迭代次数n均累加</p><p>根节点是当前状态<br>选取根节点的直接子节点中最大的一个行为<br>蒙特卡洛算法</p><p>Minimax算法：</p><p>Alpha-Beta剪枝算法：</p>]]></content>
      
      
      <categories>
          
          <category> 强化学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AlphaZero </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>anaconda虚拟环境</title>
      <link href="/2022/08/09/Anaconda/"/>
      <url>/2022/08/09/Anaconda/</url>
      
        <content type="html"><![CDATA[<p>安装torch的方法：有驱动的前提下，取pytorch官网寻找命令安装torch+cuda<br>查询虚拟环境：conda env list<br>创建虚拟环境：conda create -n name python=3.xx<br>删除虚拟环境：conda remove -n name all<br>进入虚拟环境：conda activate name<br>退出虚拟环境：conda deactivate</p><p>能正常运行我电脑里的一个torch代码需要以下包：<br>pip3 install torch torchvision torchaudio —index-url <a href="https://download.pytorch.org/whl/cu121">https://download.pytorch.org/whl/cu121</a><br>Conda install nb_conda<br>Pip install jupyter matplotlib d2l tensorboard</p>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
          <category> 编译进化 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Anaconda </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>C学习</title>
      <link href="/2022/08/09/C/"/>
      <url>/2022/08/09/C/</url>
      
        <content type="html"><![CDATA[<p>文件架构：每个.c文件只包含对应的.h文件，每个.h文件只包含要用到的.h文件</p><h1 id="ifndef只能解决重复包含的问题，比如a-h包含了c-h，b-h也包含了c-h，此时如果在d-h里同时包含a-h和b-h，那么如果没有ifndef就会报错。"><a href="#ifndef只能解决重复包含的问题，比如a-h包含了c-h，b-h也包含了c-h，此时如果在d-h里同时包含a-h和b-h，那么如果没有ifndef就会报错。" class="headerlink" title="ifndef只能解决重复包含的问题，比如a.h包含了c.h，b.h也包含了c.h，此时如果在d.h里同时包含a.h和b.h，那么如果没有ifndef就会报错。"></a>ifndef只能解决重复包含的问题，比如a.h包含了c.h，b.h也包含了c.h，此时如果在d.h里同时包含a.h和b.h，那么如果没有ifndef就会报错。</h1><p>如果a.h里包含了b.h，b.h里又包含了a.h，那么这样也会报错，且这个问题无法使用ifndef解决，且有时不会显式报错，发现的时候已经为时已晚，可谓代码杀手。<br>建议在规划文件时先把文件的架构以图的形式捋顺再动手。</p><p>extern置于变量前,标示变量的定义在别的文件中,提示编译器遇到此变量和函数时在其他模块中寻找其定义。</p><p>函数指针<br>函数指针 —存放函数地址的指针；<br>&amp;函数名 —得到的就是一个函数的地址；<br>正如数组名=&amp;数组名，函数名也是等于&amp;函数名的<br>函数指针定义：函数的返回值类型（<em>指针名）（函数的参数列表类型）=&amp;函数名/=函数名<br>函数指针调用：(</em>函数指针)(函数的参数列表类型)=函数指针(函数的参数列表类型)=函数名(函数的参数列表类型)<br>例：<br>void Add(int x, int y){return x+y;}<br>int main(){<br>int (<em>pf)(int,int)=&amp;Add=Add;<br>int ret=(</em>pf)(3,5)=pf(3,5)=Add(3,5)=8;</p>]]></content>
      
      
      <categories>
          
          <category> 编程语言学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> C </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>FOC电机控制算法</title>
      <link href="/2022/08/09/FOC/"/>
      <url>/2022/08/09/FOC/</url>
      
        <content type="html"><![CDATA[<p>直流无刷电机的工作原理：<br>由于没有一般直流电机的换向刷，故控制直流无刷电机实质上就是对其硬件mos管开关规律的控制。假设Q0、Q1代表A相，Q2、Q3代表B相，Q4、Q5代表C相。以打开Q1，Q2为例，此时A线圈上S下N，B线圈左S右N，所以转子磁铁会转到图中的状态。以此类推，我们依序将AB-&gt;AC-&gt;BC-&gt;BA-&gt;CA-&gt;CB-&gt;AB……通电，则转子便可以以一定的速度循环转动起来。而要让mos管按照我们的要求开闭，就需要编写单片机程序来实现高速规律控制。这种程序就是FOC算法，FOC算法就是对电机的运动建立数学模型，把电机的运动抽象化，使单片机能够根据这个算法控制电机产生我们想要的力矩和速度。</p><p>我们知道，直流无刷电机由三相线接入三股相位相差120°的电流分别作用于ABC三相，用相量法将其写作向量形式即如下图所示，同时我们将三相电流利用矢量分解合成到α-β坐标系下：</p><p>写作矩阵形式即：</p><p>这个变换就是所谓的克拉克变换，利用克拉克变换，我们就可以把三相电流降维成两个向量<br>Iα和Iβ，由基尔霍夫电流定律和电机的对称性，如果我们假设电流从A相流入，我们可以得到两个方程：ia+ib+ic=0,ib=ic。故有ib=ic=-0.5ia，代入克拉克变换的第一个方程就有Iα=1.5ia。在实际应用时，为了简化运算，我们希望Iα能完全等于ia，故因此我们对克拉克变换额外乘以一个系数2/3，这样子Iα就等于ia了。反映在坐标变换下，就是除了进行矢量的分解合成外，还对合成到α-β坐标系下的矢量作了比例变换。此时的克拉克变换称为等幅值形式的克拉克变换。其格式如下图所示，即比普通的克拉克变换多了一个系数2/3。</p><p>借助基尔霍夫电流定律我们还可以知道，我们并非要得到ia，ib，ic三相电流而只需要知晓其中两相即可，已知在等幅值形式的克拉克变换下有Iα=ia。进一步我们可以求由两相电流表示的Iβ：</p><p>于是简化的等幅值形式克拉克变换即：</p><p>反过来，如果我们已知了ia，ib，ic三相电流，则我们也可以得到Iα和Iβ，这个过程被称为等幅值形式的克拉克逆变换：</p><p>写作矩阵形式即：</p><p>利用克拉克变换，我们成功实现了把三相电流降维成两个向量Iα和Iβ，但通过Iα和Iβ还不足以直观的反映电机旋转的物理状态，为此，我们进一步引入帕克变换。<br>容易得到，克拉克变换所建立的α-β坐标系是固定在定子上的，为了反映电机旋转的物理状态，我们于是在转子上也建立一个被称为Q-D（交轴-直轴）的坐标系，这个坐标系随转子旋转，定义D轴方向为沿转子N极中心线的方向。此时Q-D坐标系与α-β坐标系的角度差即为电机转动的电角度，它反映了电机的转动；而IQ和ID（交轴电流，直轴电流）即为两个定值（且通常ID=0），它们反映了电机给定的力矩。</p><p>借助坐标转换我们容易得到IQ、ID和Iα、Iβ的关系如下，这个关系就是帕克变换：</p><p>同理它的逆变换式就是：</p><p>帕克变换的精髓在于，他通过坐标转换得到了大小与方向分离的两组量，作为定值的IQ和ID仅反映了电机的力矩，而电机的旋转过程则完全由变量电角度θ体现，于是乎，我们想要控制电机的力矩，只需要为IQ和ID赋值即可，而电机旋转带来的矢量变化则通过电角度θ，借助帕克逆变换和克拉克逆变换自然地反映到了三相电流ia，ib，ic中，进而控制电机的运动，整个过程省去了复杂的矢量旋转与计算。<br>综上，整个FOC算法的过程就是：</p><p>而三相电流ia，ib，ic驱动电机转过一个角度后，在下一瞬间角度传感器便会更新θ的值，从而在新的时刻重复这一循环。<br>同理，我们也可以得到电压形式的帕克逆变换和克拉克逆变换，两者实质上没有区别：</p>]]></content>
      
      
      <categories>
          
          <category> 控制理论 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> FOC </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PT与PVT路径规划</title>
      <link href="/2022/08/09/PVT/"/>
      <url>/2022/08/09/PVT/</url>
      
        <content type="html"><![CDATA[<p>本文介绍位置-时间（PT）和位置-速度-时间（PVT）路径插值算法。下面包含了两种算法的优缺点。<br>PT和PVT算法将一系列的点-时间对写入到控制卡中，在每个采样创建一个实时的位置。PVT插值类型还需要附加每个点上的速度。一个点可以有多个维度。<br>在PT模式下：<br>PT算法计算出一个合适的速度曲线。PT算法保证控制卡的轨迹计算符合每一个已知的点和时间，达到这一条件所需的分段速度只需由该分段的位置和时间的差分就可以计算出来。</p><p>什么时候适用PT算法？<br>PT算法非常适用于密集点或低速。这是一个非常简单的算法，只需要很少的计算，运算速度很快。由上图可以看到，这里的速度跃变都是理想情况的突变，没有加速度的加入，因而如果点之间的距离太远，运动将很粗糙，存在较大的误差。最好将点间距保持在几个样本内。默认采样率为500微秒。<br>在PVT模式下：<br>在保证PT的同时，这个算法还保证在对应的时间，对应的位置达到对应的速度。这个计算源自标准运动学方程，具体原理不详述。</p><p>简单的PVT示例例如，可以使用三个位置、速度和时间点的列表生成梯形速度轮廓运动：</p><p>值得注意的是，PVT算法不关心非特征点的位置、速度和时间情况，而只保证特征点满足需要，因而点之间的轮廓（v-t图像）可能不是期望的，这与PVT路径的计算有关。<br>例如，考虑上面PVT轮廓（梯形）图中的简单三点梯形轮廓。如果点0和1处的速度太小，轮廓将拉伸以覆盖适当的距离；如果点0和1处的速度太大，轮廓将缩小以覆盖适当的距离。</p><p>什么时候适用PVT算法？<br>PVT算法非常适合于平滑和闭合路径控制。这些点可以间隔得非常近或非常远。对于复杂路径部分，点应紧密间隔。对于简单路径部分，点可以间隔很远。PVT几乎可以处理任何点列表，最困难的部分是确定每个点的适当速度。<br>测试用例：<br>使用三种类型的点时间序列（步进、锯齿形和八角形）来评估PT/PVT算法创建的路径。大多数高阶（多项式）插值算法比具有直线和锐角的截面更适合于描述路径的连续曲线截面。<br>当路径不太适合高阶多项式时，步长和Z字形路径测试确定算法的性能。八边形路径测试算法在给定圆周围少量（8）点的情况下对路径的圆形截面进行插值的效果。<br>先看步进模式：（左边为PT，右边为PVT，从上到下分别为位置，速度，加速度表示）</p><p>可以看到PT的路径是连续的，但速度、加速度都是瞬间的，因而要求两点在时间上非常接近或速度非常低。而PVT位置和速度是连续的，加速度不是。<br>再看锯齿形：</p><p>可以看到PT运动非常适合于由直线和锐角组成的路径。PVT路径往往比PT路径平滑得多，但需要在每个提供的点处提供每个轴的速度。这会增加应用程序的复杂性，因为每个点的速度通常难以确定。<br>最后是八角形：</p><p>同样，PT路径由简单的直线组成。径向误差是从插值路径到中心的距离与通过点的圆半径之间的差，最大误差在点之间的中间。而PVT路径则接近于一个圆了，这在PT中可能需要更大量的点才能近似。</p>]]></content>
      
      
      <categories>
          
          <category> 控制理论 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 轨迹规划 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>git联合创作</title>
      <link href="/2022/08/09/git/"/>
      <url>/2022/08/09/git/</url>
      
        <content type="html"><![CDATA[<p>Vscode中下载适用于windows的git，同时加入Gitlens工具包<br>安装时注意在这个界面选择使用visual studio code，其他全点next就可以</p><p>在cmd中键入git验证是否安装</p><p>Git配置完成后显示如此</p><p>第一次时选择初始化仓库而后显示如此</p><p>.gitignore选择git要忽略的文件（一般是.vscode和build）</p><p>终端加入git bash</p><p>配置username和useremail键入命令：<br>设置用户名和邮箱<br>git config —global user.name “username”<br>git config —global user.email  useremail@qq.com<br>查看是否设置成功<br>git config user.name<br>git config user.email<br>查看全局配置<br>git config —global -l </p><p>在设置里去掉勾选use Editor As commit input</p><p>由此我们便完成了vscode+github的基本配置，之后对同一文件不需再次配置</p><p>接下来我们学习git的提交与发布（推送）<br>这是两个不同的步骤，提交是将程序文件保存到本地仓库，发布则是将程序文件发送到云端（也就是github上），具体地：</p><p>点击√后提示“请提供提交信息”，键入分支名（一般为master）</p><p>如此便得到了一个本地的master分支，然后就是把他发布到github上，点击发布branch</p><p>期间抛出的所有token全部点击是<br>成功后vscode会自动捕捉我们在github上的库</p><p>我们既可以直接键入名称，这样就会在github上自动创建一个该名称的分支。<br>也可以搜索已经在github上创建好的分支来保存它，补充介绍下如何在github上创建分支。<br>我们在自己的github上首页建一个新的库保存它，点击new</p><p>键入名称，描述以及是否公开</p><p>点击确定后就得到了一个空的github库</p><p>回到正题，我们选定好github的远程库后便可以点击发布branch将其上传到github<br>初次上传时vscode需要登录github，依次在弹出的token中点击sign in-&gt;authorize-&gt;confirm</p><p>完成后vscode弹出提示，发布完成。</p><p>之后每次修改程序，提交按钮都会再次高亮，同时显示修改了的（也就是要上传的）文件</p><p>我们只需要点击提交，然后同步更改即可完成覆写</p><p>在存在一个主分支(master)的情况下，还可以上传若干个其他分支</p><p>点击左下角的分支名，在上方弹出框中选择创建新分支，已创建的分支会显示在下方<br>分支创建成功后，右边的git又显示为“√提交”，则此时按照上面介绍的正常步骤便可以在主分支下创建一个新的分支。</p><p>由于github通常需要翻墙而且不太稳定，因而上传可能失败，记得检查网络配置<br>不行的话可以重启clash</p><p>常见警告/报错token：</p><p>直接点击始终就可以，之后不会再弹出</p><p>直接点击don’t show again就可以，之后不会再弹出</p><p>最简单粗暴的是关闭代理再打开就可以！更多方法参见附录</p><p>git命令集</p><ol><li>git clone <a href="https://……">https://……</a> 下载</li><li>git push 上传</li><li>git remote add origin <a href="https://……">https://……</a>. 添加远程仓库</li><li>git init 初始化本地仓库</li><li>git config —global https.proxy <a href="http://127.0.0.1:7890">http://127.0.0.1:7890</a> 添加远程端口 </li></ol><p>有时候出现连接不上网络的情况时使用该方法，需要在电脑设置上打开手动代理，http:// 后面的是代理ip地址和端口，仅限在挂梯子之后打开手动代理，否则会出现网络连接不上的问题</p><ol><li>git config —global http.proxy <a href="http://127.0.0.1:7890">http://127.0.0.1:7890</a> 添加远程端口</li><li>git config —global —list 配置信息列表</li><li>git config —global user.name name 配置名称</li><li>git config —global user.name email 配置邮件</li><li>git commit -m “initial commit” 提交初始仓库</li></ol><p>附录：<br>参考视频<a href="https://www.bilibili.com/video/BV1dK411p7RF">https://www.bilibili.com/video/BV1dK411p7RF</a><br>Git for Windows下载：<a href="https://git-scm.com/download/win">https://git-scm.com/download/win</a><br>Github官网：<a href="https://github.com">https://github.com</a><br>解决unable to access…的一些方法：<br><a href="https://blog.csdn.net/qq_39808156/article/details/117510950">https://blog.csdn.net/qq_39808156/article/details/117510950</a><br><a href="https://blog.csdn.net/risroy/article/details/128887648">https://blog.csdn.net/risroy/article/details/128887648</a><br><a href="https://blog.csdn.net/qq_40520596/article/details/108479892">https://blog.csdn.net/qq_40520596/article/details/108479892</a></p>]]></content>
      
      
      <categories>
          
          <category> 编译进化 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> git </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Keil学习</title>
      <link href="/2022/08/09/keil/"/>
      <url>/2022/08/09/keil/</url>
      
        <content type="html"><![CDATA[<p>Keil+vscode联合开发：<a href="https://www.yisu.com/zixun/607208.html">https://www.yisu.com/zixun/607208.html</a><br>字体问题：Edit-&gt;Configuration-&gt;Encoding 可以选择ANSI，UTF-8或GB2312<br>有时透过vscode打开时中文会出现乱码，此时一定要先把vscode的字体改成GB2312再保存，否则keil工程的中文会全部变成乱码<br>当然，上面这个博客写的很详细了，直接参照博客的方法也可以</p>]]></content>
      
      
      <categories>
          
          <category> 嵌入式 </category>
          
          <category> 编译进化 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Keil </tag>
            
            <tag> STM32 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LaTeX学习</title>
      <link href="/2022/08/09/latex/"/>
      <url>/2022/08/09/latex/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      <categories>
          
          <category> 编译进化 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LaTex </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>C#学习</title>
      <link href="/2022/08/09/C#/"/>
      <url>/2022/08/09/C#/</url>
      
        <content type="html"><![CDATA[<p>1.C# 数据类型<br>在 C# 中，变量分为以下几种类型：<br>值类型（Value types）：如需得到一个类型或一个变量在特定平台上的准确尺寸，可以使用sizeof方法。表达式sizeof(type)产生以字节为单位存储对象或类型的存储尺寸。<br>引用类型（Reference types）：<br>指针类型（Pointer types）：C# 中的指针与 C 或 C++ 中的指针有相同的功能。</p><p>2.C# 强制类型转换<br>在 C# 中，强制类型转换有两种方法：<br>其一是在变量前面加(type)，例如将一个 int 类型的变量赋值给 byte 类型的变量：<br>int i = 10;<br>byte b = (byte)i;<br>其二是使用Convert中的方法，例如将一个 double 类型的变量转化成 single 类型的变量：<br>double i=3.14;<br>float b=Convert.ToSingle(i);<br>强制类型转换也作用于字符串与数字的转换，其中将数字转换成字符串既可以使用i.ToString(“Fx”)也可以使用Convert.ToString(i)。<br>强制类型转换可能会造成数据丢失。</p><p>3.C# 支持的其他一些重要的运算符</p><p>4.C# 中的foreach循环：<br>C# 的 foreach 循环可以用来遍历集合类型，例如数组、列表、字典等。<br>以下是 foreach 循环的语法：<br>foreach (var item in collection)<br>{<br>    // 循环<br>}<br>collection 是要遍历的集合，item 是当前遍历到的元素。</p><p>5.C# 封装<br>C# 支持的访问修饰符如下所示：<br>public：所有对象都可以访问；<br>private：只有在该类对象内部可以访问；<br>protected：只有该类对象及其子类对象可以访问<br>internal：同一个程序文件内的对象可以访问；</p><p>6.C#方法与参数传递：<br>在 C# 中，定义方法的语法如下：<br>&lt;访问修饰符&gt; &lt;返回类型&gt; &lt;方法名&gt;(参数列表)<br>{<br>   //方法主体<br>}<br>按值传递参数：是参数传递的默认方式。在这种方式下，当调用一个方法时，会为每个值参数创建一个新的存储位置。实际参数的值会复制给形参，实参和形参使用的是两个不同内存中的值。所以，当形参的值发生改变时，不会影响实参的值，从而保证了实参数据的安全。<br>按引用传递参数：引用参数是一个对变量的内存位置的引用。当按引用传递参数时，它不会为这些参数创建一个新的存储位置，而是与提供给方法的实际参数具有相同的内存位置。在 C# 中，使用 ref 关键字声明引用参数。例如在定义时public void swap(ref int x, ref int y)，在使用时int a=3,b=5;swap(ref a, ref b)。<br>按输出传递参数：return 语句只能从函数中返回一个值。如果要从函数中返回多个值，可以使用输出参数，输出参数会把方法输出的数据赋给自己以供外部调用。在 C# 中，使用 out 关键字声明输出参数。例如：<br>public void getValue(out int x )<br>{<br>    int temp = 5;<br>    x = temp;<br>}<br>int a = 100;<br>getValue(out a);        //提醒：作为输出参数的变量可以不提前赋值<br>Console.WriteLine(a);    //a=5</p><p>7.C# 可空类型：<br>C# 提供了一个特殊的数据类型，nullable 类型（可空类型），可空类型可以表示其基础值类型正常范围内的值再加上一个 null 值。例如Nullable&lt; bool &gt; 变量可以被赋值为 true 或 false 或 null。声明一个 nullable 类型（可空类型）的语法如下：<br>&lt;变量类型&gt; ? &lt;变量名&gt; = null;    //例如int? num1 = null;<br>此外，C#还提供了一个被称为Null 合并运算符的功能，Null 合并运算符为类型转换定义了一个预设值，以防可空类型的值为 Null。它的格式为：<br>&lt;变量名&gt;??&lt;常量&gt;        //例如num3=num2 ?? 5.34<br>其意义是，如果第一个操作数的值为 null，则运算符返回第二个操作数的值，否则返回第一个操作数的值。在上例中，如果num2为空值则num3=5.34。</p><p>8.C# 数组：<br>（1）一维数组：<br>在 C# 中声明一个一维数组的语法是：&lt;变量类型&gt;[] &lt;数组名&gt;;<br>声明一个数组不会在内存中初始化数组。只有数组被初始化后，才可以赋值给数组。<br>数组是一个引用类型，所以数组初始化需要使用 new 关键字来创建数组的实例。<br>例如：<code>double[] balance = new double[10];</code><br>我们也可以在初始化数组的同时为其赋值，比如：<code>int [] marks = new int[5] &#123; 99, 98, 92, 97, 95&#125;;</code><br>其中new int[5]中的5可以省略，即可以改写为<code>int [] marks = new int[] &#123; 99, 98, 92, 97, 95&#125;;</code><br>我们可以使用foreach来遍历一个数组。<br>（2）多维数组：<br>在 C# 中声明一个多维数组的语法是：&lt;变量类型&gt;[,…,] &lt;数组名&gt;;<br>其中逗号的数量是数组的维数，数组中的每个元素使用形式为 a[ i , j , k, …]的元素名称来标识，其中 a 是数组名称， i , j , k, …是各维度的值。<br>初始化赋值公式例如：<code>int[,] a = new int[5, 2] &#123;&#123;0,0&#125;, &#123;1,2&#125;, &#123;2,4&#125;, &#123;3,6&#125;, &#123;4,8&#125; &#125;;//&#123;&#125;为行,为列`（3）交错数组：交错数组是数组的数组，也就是说交错数组是一维数组，而数组中的每个元素也都是数组。在 C# 中声明一个交错数组的语法是：<变量类型>[][] <数组名>;初始化赋值公式例如：`int[][] scores = new int[2][]&#123;new int[]&#123;92,93,94&#125;,new int[]&#123;85,66,87,88&#125;&#125;;</code><br>交错数组中各元素的数组长度可以不一样。<br>（4）传递数组给函数：可以通过数组名称来给函数传递一个指向数组的指针。<br>例如：<code>double getAverage(int[] arr, int size);</code><br><code>int [] balance = new int[]&#123;1000, 2, 3, 17, 50&#125;;</code><br><code>avg = getAverage(balance, 5 ) ;</code><br>（5）参数数组：当声明一个方法时，如果不能确定要传递给函数的参数数目，则可以使用参数数组解决这个问题，参数数组通常用于传递未知数量的参数给函数。为此，C# 提供了 params 关键字，当调用数组为形参的方法时，既可以传递数组实参，也可以传递一组数组元素。其格式为：访问修饰符 返回类型 方法名称( params 类型名称[] 数组名称)<br>例如：<code>public int AddElements(params int[] arr);</code><br>         <code>int sum = AddElements(512, 720, 250, 567, 889);</code><br>（6）：数组具有很多方法，可以用数组名.或Array.呼出。比较常用的有：<br>数组名.Length，Array.Copy/Sort/Reverse等</p><p>9.C# 字符串：<br>C# 定义字符串既可以使用char数组进行new创建，也可以直接用字符串string。<br>例如：<code>string Name=”Alan”;</code><br>又例如：<code>char[] letters = &#123; &#39;H&#39;, &#39;e&#39;, &#39;l&#39;, &#39;l&#39;,&#39;o&#39; &#125;;</code><br>            <code>string greetings = new string(letters);</code><br>字符串string同数组array类似，也具有很多的内置方法。比较常用的有：</p><p>10.C# 结构体：<br>在 C# 中，结构体是值类型数据结构。它使得一个单一变量可以存储各种数据类型的相关数据。struct 关键字用于创建结构体。<br>例如，您可以按照如下的方式声明 Book 结构体：<br>struct Books{<br>   public string title;<br>   public string author;<br>   public string subject;<br>   public int book_id;<br>};<br>在 C# 中的结构体与传统的 C 或 C++ 中的结构体不同。C# 中的结构体有以下特点：<br>结构体可带有方法、字段、索引、属性、运算符方法和事件。<br>结构体可定义构造函数，但不能定义析构函数。<br>结构不能继承其他的结构或类，也不能作为其他结构或类的基，但可实现一个或多个接口。<br>结构成员的访问修饰符只能为public。<br>可以使用 New 操作符调用适当的构造函数创建结构体，也可以不使用 New 操作符即可被实例化，如果不使用 New 操作符，只有在所有的字段都被初始化之后，对象才能被使用。<br>比较类和结构，可以发现两者的不同在于：类是引用类型，结构是值类型且不支持继承。</p><p>11.C# 枚举：<br>C#声明枚举的一般语法是：<br>enum &lt;枚举体名&gt;<br>{<br>    枚举列表    //用逗号分隔的标识符列表<br>};<br>枚举列表中的每个符号代表一个比它前面的符号大一的整数值。默认情况下，第一个枚举符号的值是0，但我们也可以对第一个枚举符号进行赋值定义以规定其值。<br>例如：enum Days { Sun=1, Mon, tue, Wed, thu, Fri, Sat };<br>枚举体可以看做是一个类，因而使用对应枚举体符号时必须加上枚举体名前缀，例如Day.Sun。<br>枚举列表的符号类型属于枚举体名，因而在使用时通常需要进行强制类型转换来得到需要的数据类型（通常为int）。例如：int x = (int)Day.Sun;         //x=1</p><p>12.C# 类：<br>类的定义是以关键字 class 开始，后跟类的名称。类的主体，包含在一对花括号内。<br>下面是类定义的一般形式：<br>&lt;访问修饰符&gt; class  类名<br>{<br>    //成员变量<br>    &lt;访问修饰符&gt; &lt;变量类型&gt; 变量名1;<br>    …<br>     &lt;访问修饰符&gt; &lt;变量类型&gt; 变量名n;<br>    //成员方法<br>    &lt;访问修饰符&gt; &lt;返回类型&gt; 方法名1(参数列表)<br>    {<br>        //方法体<br>    }<br>    …<br>    &lt;访问修饰符&gt; &lt;返回类型&gt; 方法名m(参数列表)<br>    {<br>        //方法体<br>    }<br>}<br>类的默认访问修饰符是 internal，成员的默认访问修饰符是 private。<br>如果要访问类的成员，需要使用点（.）运算符。<br>类的成员函数是一个在类定义中有它的定义或原型的函数，就像其他变量一样。作为类的一个成员，它能在类的任何对象上操作，且能访问该对象的类的所有成员。<br>构造函数是类的一个特殊成员函数，当创建类的新对象时执行。构造函数的名称与类的名称完全相同，它没有返回类型，即public 类名(初值参数){方法体}。例如class line的构造函数：<br>public Line(double len)  // 参数化构造函数<br>{<br>Console.WriteLine(“对象已创建，length = {0}”, len);<br>length = len;<br>}<br>析构函数的名称是在类的名称前加上一个波浪形（~）作为前缀，它不返回值，也不带任何参数。析构函数用于在结束程序之前释放资源。析构函数不能继承或重载。例如~Line(){}。<br>可以使用 static 关键字把类成员定义为静态成员。这意味着无论有多少个类的对象被创建，只会有一个该静态成员的副本，换句话说，这意味着类中只有一个该成员的实例。例如：<br>class StaticVar<br>{<br>public static int num;<br>public void count()<br>{<br>num++;    //所有类的实例每调用一次count()，都只会给唯一的num加一<br>}<br>}<br>你也可以把一个成员函数声明为 static，这样的函数只能访问静态变量。<br>13.C# 继承<br>继承是面向对象程序设计中最重要的概念之一。继承允许我们根据一个类来定义另一个类，这使得创建和维护应用程序变得更容易。同时也有利于重用代码和节省开发时间。当创建一个类时，程序员不需要完全重新编写新的数据成员和成员函数，只需要设计一个新的类，继承已有的类的成员即可。这个已有的类被称为的基类，这个新的类被称为派生类。<br>一个类可以派生自多个类或接口，这意味着它可以从多个基类或接口继承数据和函数。<br>C# 中创建派生类的语法如下：<br>&lt;访问修饰符&gt; class &lt;基类&gt;<br>{<br>     //基类内容<br>}<br>&lt;访问修饰符&gt;class &lt;派生类&gt; : &lt;基类&gt;<br>{<br>//派生类内容<br>}<br>基类的初始化<br>派生类继承了基类的成员变量和成员方法。因此父类对象应在子类对象创建之前被创建。您可以在成员初始化列表中进行父类的初始化。<br>C# 多重继承：<br>多重继承指的是一个类别可以同时从多于一个父类继承行为与特征的功能。与单一继承相对，单一继承指一个类别只可以继承自一个父类。<br>C# 不支持多重继承。但是，我们可以使用接口来实现多重继承。</p><p>14.C# 多态性<br>多态是同一个行为具有多个不同表现形式或形态的能力。在面向对象编程中，多态性往往表现为”一个接口，多个功能”。<br>多态性可以是静态的或动态的。在静态多态性中，函数的响应是在编译时发生的。在动态多态性中，函数的响应是在运行时发生的。<br>（1）静态多态性：<br>在编译时，函数和对象的连接机制被称为早期绑定，也被称为静态绑定。C# 提供了两种技术来实现静态多态性，分别为函数重载和运算符重载。<br>函数重载：您可以在同一个范围内对相同的函数名有多个定义。函数的定义必须彼此不同，可以是参数列表中的参数类型不同，也可以是参数个数不同，但不能只是返回类型不同。<br>（2）动态多态性：<br>C# 允许您使用关键字 abstract 创建抽象类，用于提供接口的部分类的实现。当一个派生类继承自该抽象类时，实现即完成。抽象类包含抽象方法，抽象方法可被派生类实现（需要使用重载关键字override）。派生类具有更专业的功能。下面是有关抽象类的一些规则：<br>您不能创建一个抽象类的实例。<br>您不能在一个抽象类外部声明一个抽象方法。<br>通过在类定义前面放置关键字 sealed，可以将类声明为密封类。当一个类被声明为 sealed 时，它不能被继承。抽象类不能被声明为 sealed。<br>下面的例子演示了一个抽象类及其实现：<br>abstract class Shape            //抽象类，可以包含虚方法<br>{<br>abstract public int area();    //抽象方法，可以在派生类中实现，用abstract声明<br>}<br>class Rectangle:  Shape            //派生类实现抽象方法<br>{<br>private int length;<br>private int width;<br>public Rectangle( int a, int b)<br>{<br>length = a;<br>width = b;<br>}<br>public override int area ()    //实现抽象方法，用override声明<br>{<br>Console.WriteLine(“Rectangle 类的面积：”);<br>return (width * length);<br>}<br>}<br>当有一个定义在类中的函数需要在继承类中实现时，可以使用虚方法，虚方法是使用关键字 virtual 声明的，虚方法可以在不同的继承类中有不同的实现，而对虚方法的调用是在运行时发生的。动态多态性是通过抽象类和虚方法实现的。</p><p>15.C# 运算符重载<br>您可以重定义或重载 C# 中内置的运算符。因此，程序员也可以使用用户自定义类型的运算符。重载运算符是具有特殊名称的函数，是通过关键字 operator 后跟运算符的符号来定义的。与其他函数一样，重载运算符有返回类型和参数列表。C#要求所有的运算符重载都声明为public和static，且重载的运算符需要与原运算符有相同的操作数，故其格式为：<br>public static &lt;返回类型&gt; operator&lt;重载运算符&gt; (与与原运算符数量相同的参数列表)<br>{<br>//重载体<br>}<br>例如：<br>public static Box operator+ (Box b, Box c)    //重载运算符+<br>{<br>    Box box = new Box();<br>    box.length = b.length + c.length;<br>    box.breadth = b.breadth + c.breadth;<br>    box.height = b.height + c.height;<br>    return box;<br>}<br>Box3 = Box1 + Box2;                    //使用新重载的运算符</p><p>16.C# 接口<br>接口一般与其派生类结合使用，其中接口定义了所有派生类继承接口时应遵循的结构。即接口定义了 “是什么” 部分，派生类定义了 “怎么做” 部分。接口定义了属性、方法和事件，这些都是接口的成员。接口只包含了成员的声明，其本身并不实现任何功能，只是和实现该接口的派生类订立一个必须实现哪些行为的契约；而成员的具体定义是接口的派生类的责任。<br>接口使得实现接口的派生类在形式上保持一致。<br>抽象类在某种程度上与接口类似，但是，它们大多只是用在当只有少数方法由基类声明由派生类实现时。<br>接口使用 interface 关键字声明，它与类的声明类似。接口声明默认是 public 的。<br>下面是一个接口声明的实例：<br>interface IMyInterface<br>{<br>    void MethodToImplement();<br>}<br>以上代码定义了接口 IMyInterface。通常接口命令以 I 字母开头，这个接口只有一个方法 MethodToImplement()，且该方法在接口中并没有具体的实现。<br>接下来我们定义一个继承自该接口的派生类来实现以上接口：<br>class InterfaceImplementer : IMyInterface    //实现接口的派生类继承自接口<br>{<br>    static void Main()    //接口不能被实例化，只有实现了接口功能的派生类才能被实例化<br>    {<br>        InterfaceImplementer iImp = new InterfaceImplementer();<br>        iImp.MethodToImplement();<br>    }<br>    public void MethodToImplement()    //实现接口<br>    {<br>        Console.WriteLine(“MethodToImplement() called.”);<br>}<br>}<br>InterfaceImplementer 类实现了 IMyInterface 接口，接口的实现与类的继承语法格式类似。<br>当一个派生类继承接口后，就必须实现接口的方法 , 且方法名必须与接口定义的方法名一致。<br>接口继承：<br>如果一个接口继承其他接口，那么实现该接口的派生类就需要实现该接口以及其父类接口的所有成员。<br>以下实例定义了两个接口，分别是IMyInterface 和 IParentInterface。其中IMyInterface 继承自IParentInterface 接口，因此接口IMyInterface对应的派生类必须实现MethodToImplement() 和ParentInterfaceMethod()两个方法：<br>interface IParentInterface<br>{<br>    void ParentInterfaceMethod();<br>}<br>interface IMyInterface : IParentInterface    //接口IMyInterface继承自接口IParentInterface<br>{<br>    void MethodToImplement();<br>}<br>class InterfaceImplementer : IMyInterface    //实现接口的派生类继承自接口<br>{<br>    static void Main()                    //实例化派生类后可以同时使用所有接口的方法<br>    {<br>        InterfaceImplementer iImp = new InterfaceImplementer();<br>        iImp.MethodToImplement();<br>        iImp.ParentInterfaceMethod();<br>    }<br>    public void MethodToImplement()        //实现IMyInterface的方法<br>    {<br>        Console.WriteLine(“MethodToImplement() called.”);<br>    }<br>    public void ParentInterfaceMethod()    //实现IParentInterface的方法<br>    {<br>        Console.WriteLine(“ParentInterfaceMethod() called.”);<br>    }<br>}</p><p>17.C# 命名空间<br>命名空间的设计目的是提供一种让一组名称与其他名称分隔开的方式。在一个命名空间中声明的类的名称与另一个命名空间中声明的相同的类的名称不冲突，即不同命名空间中的名称可以重复。定义命名空间以关键字 namespace 开始，后跟命名空间的名称，如下所示：<br>namespace &lt;命名空间名&gt;<br>{<br>   // 代码声明<br>}<br>为了调用对应命名空间的函数或变量，会把命名空间的名称置于前面并用点分隔，如下所示：<br> &lt;命名空间名&gt;. &lt;函数或变量名&gt;;<br>下面的程序演示了命名空间的用法：<br>namespace first_space<br>{<br>   class namespace_cl<br>   {<br>      public void func()<br>      {<br>         Console.WriteLine(“Inside first_space”);<br>      }<br>   }<br>}<br>namespace second_space<br>{<br>   class namespace_cl<br>   {<br>      public void func()<br>      {<br>         Console.WriteLine(“Inside second_space”);<br>      }<br>   }<br>}<br>class TestClass<br>{<br>   static void Main(string[] args)<br>   {<br>      first_space.namespace_cl fc = new first_space.namespace_cl();<br>      second_space.namespace_cl sc = new second_space.namespace_cl();<br>      fc.func();<br>      sc.func();<br>   }<br>}<br>当上面的代码被编译和执行时，它会产生下列结果：<br>Inside first_space<br>Inside second_space<br>此外，我们也可以用using 关键字表明程序使用的是给定命名空间中的名称，这样在使用的时候就不用在前面加上命名空间名称，编译器在随后的代码会默认使用指定命名空间中的名称。例如，我们在程序中使用 System 命名空间，其中定义了类 Console。<br>我们可以只写：Console.WriteLine (“Hello there”);<br>当然，我们也可以写全称：System.Console.WriteLine(“Hello there”);<br>此外，命名空间可以被嵌套，即您可以在一个命名空间内定义另一个命名空间，如下所示：<br>namespace &lt;外部命名空间名&gt;<br>{<br>   // 代码声明<br>   namespace &lt;内嵌命名空间名&gt;<br>   {<br>     // 代码声明<br>   }<br>}<br>其访问关系仍然是使用点运算符访问嵌套的命名空间的成员。</p><p>18.C# 预处理器指令</p><h1 id="define-DEBUG"><a href="#define-DEBUG" class="headerlink" title="define DEBUG"></a>define DEBUG</h1><h1 id="define-VC-V10"><a href="#define-VC-V10" class="headerlink" title="define VC_V10"></a>define VC_V10</h1><p>public static void Main()<br>{</p><h1 id="if-DEBUG-amp-amp-VC-V10"><a href="#if-DEBUG-amp-amp-VC-V10" class="headerlink" title="if (DEBUG &amp;&amp; !VC_V10)"></a>if (DEBUG &amp;&amp; !VC_V10)</h1><p>Console.WriteLine(“DEBUG is defined”);</p><h1 id="elif-DEBUG-amp-amp-VC-V10"><a href="#elif-DEBUG-amp-amp-VC-V10" class="headerlink" title="elif (!DEBUG &amp;&amp; VC_V10)"></a>elif (!DEBUG &amp;&amp; VC_V10)</h1><p>Console.WriteLine(“VC_V10 is defined”);</p><h1 id="elif-DEBUG-amp-amp-VC-V10-1"><a href="#elif-DEBUG-amp-amp-VC-V10-1" class="headerlink" title="elif (DEBUG &amp;&amp; VC_V10)"></a>elif (DEBUG &amp;&amp; VC_V10)</h1><p>Console.WriteLine(“DEBUG and VC_V10 are defined”);</p><h1 id="else"><a href="#else" class="headerlink" title="else"></a>else</h1><p>Console.WriteLine(“DEBUG and VC_V10 are not defined”);</p><h1 id="endif"><a href="#endif" class="headerlink" title="endif"></a>endif</h1><p>}<br>19.C# 异常处理<br>异常是在程序执行期间出现的问题。C# 中的异常是对程序运行时出现的特殊情况的一种响应，比如尝试除以零。异常提供了一种把程序控制权从某个部分转移到另一个部分的方式。C# 异常处理时建立在四个关键词之上的：try、catch、finally 和 throw。<br>①try：一个 try 块标识了一个将被激活的特定的异常的代码块。后跟一个或多个 catch 块。<br>②catch：程序通过异常处理程序捕获try块中的异常。<br>③finally：finally 块用于执行给定的语句，不管异常是否被抛出都会执行。<br>④throw：当问题出现时，程序抛出一个异常，使用 throw关键字来完成。一般用于抛出用户自定义的异常，当try语句捕捉到throw抛出的异常，就会进入catch捕获阶段。<br>使用 try/catch 语法如下所示：<br>try<br>{<br>   // 可能引起异常的语句<br>}<br>catch( ExceptionName e1 )    //检测这些语句抛出的异常<br>{<br>   // 错误处理代码<br>}<br>….<br>catch( ExceptionName eN )    //可以列出多个 catch 语句捕获不同类型的异常<br>{<br>   // 错误处理代码<br>}<br>finally<br>{<br>   // 最终执行代码<br>}<br>C# 异常是使用类来表示的。C# 中的异常类主要是直接或间接地派生于 System.Exception 类。System.ApplicationException 和 System.SystemException 类是派生于 System.Exception 类的异常类。System.ApplicationException 类支持由应用程序生成的异常。程序员定义的异常都派生自该类；而System.SystemException 类是所有预定义的系统异常的基类。<br>下表列出了一些派生自 System.SystemException 类的预定义的异常类：<br>System.IO.IOException                处理 I/O 错误。<br>System.IndexOutOfRangeException    处理当方法指向超出范围的数组索引时生成的错误。<br>System.ArrayTypeMismatchException    处理当数组类型不匹配时生成的错误。<br>System.NullReferenceException        处理当依从一个空对象时生成的错误。<br>System.DivideByZeroException        处理当除以零时生成的错误。<br>System.InvalidCastException            处理在类型转换期间生成的错误。<br>下面是一个当除以零时抛出系统异常的实例：<br>public void division(int num1, int num2)<br>{<br>try<br>{<br>result = num1 / num2;<br>}<br>catch (DivideByZeroException e)<br>{<br>Console.WriteLine(“Exception caught: {0}”, e);<br>}<br>finally<br>{<br>Console.WriteLine(“Result: {0}”, result);<br>}<br>}<br>static void Main(string[] args)<br>{<br>DivNumbers d = new DivNumbers();<br>d.division(25, 0);<br>}<br>当上面的代码被编译和执行时，它会产生下列结果：<br>Exception caught: System.DivideByZeroException: Attempted to divide by zero.<br>下面的实例演示了抛出用户自定义的异常：<br>static void Main(string[] args)<br>{<br>Temperature temp = new Temperature();<br>try<br>{<br>temp.showTemp();            //当temperature=0时会抛出自定义异常被try捕捉<br>}<br>catch(TempIsZeroException e)    //捕获到自定义异常<br>{<br>Console.WriteLine(“TempIsZeroException: {0}”, e.Message);<br>}<br>}<br>public class TempIsZeroException: ApplicationException//自定义异常，继承ApplicationException<br>{<br>public TempIsZeroException(string message): base(message)<br>       {<br>       }<br>}<br>public class Temperature<br>{<br>int temperature = 0;<br>public void showTemp()<br>{<br>if(temperature == 0)    //抛出自定义异常TempIsZeroException的时机<br>          {<br>                 throw (new TempIsZeroException(“Zero Temperature found”));<br>          }<br>          else<br>          {<br>                 Console.WriteLine(“Temperature: {0}”, temperature);<br>          }<br>       }<br>}<br>当上面的代码被编译和执行时，它会产生下列结果：<br>TempIsZeroException: Zero Temperature found</p>]]></content>
      
      
      <categories>
          
          <category> 编程语言学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> C# </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PID控制</title>
      <link href="/2022/08/09/PID/"/>
      <url>/2022/08/09/PID/</url>
      
        <content type="html"><![CDATA[<p>引言：<br>在工业应用中PID及其衍生算法是应用最广泛的算法之一，是当之无愧的万能算法，如果能够熟练掌握PID算法的设计与实现过程，对于一般的研发人员来讲，应该是足够应对一般研发问题了，而难能可贵的是，在我所接触的控制算法当中，PID控制算法又是最简单，最能体现反馈思想的控制算法，可谓经典中的经典。经典的未必是复杂的，经典的东西常常是简单的，而且是最简单的。</p><p>PID控制算法的C语言实现一 PID算法原理<br>先看看PID算法的一般形式：<br>PID的流程简单到了不能再简单的程度，通过误差信号控制被控量，而控制器本身就是比例、积分、微分三个环节的加和。这里我们规定（在t时刻）：<br>   1.输入量为rin(t);（设定值）<br>   2.输出量为rout(t);（实际值）<br>   3.偏差量为err(t)=rin(t)-rout(t);</p><p>   理解一下这个公式，主要从下面几个问题着手，为了便于理解，把控制环境具体一下：<br>   1.规定这个流程是用来为直流电机调速的;<br>   2.输入量rin(t)为电机转速预定值;<br>   3.输出量rout(t)为电机转速实际值;<br>   4.执行器为直流电机;<br>   5.传感器为光电码盘，假设码盘为10线;<br>   6.直流电机采用PWM调速 转速用单位 转/min 表示;</p><p>  不难看出以下结论：<br>   1.输入量rin（t）为电机转速预定值（转/min）;</p><ol><li><p>输出量rout(t)为电机转速实际值（转/min）;<br>3.偏差量为预定值和实际值之差（转/min）;</p><p>那么以下几个问题需要弄清楚：<br>1.通过PID环节之后的U(t)是什么值呢？<br>2.控制执行器（直流电机）转动转速应该为电压值（也就是PWM占空比）。<br>3.那么U(t)与PWM之间存在怎样的联系呢？</p></li></ol><p><a href="http://blog.21ic.com/user1/3407/archives/2006/33541.html（见附录1）这篇文章上给出了一种方法，即，每个电压对应一个转速，电压和转速之间呈现线性关系。但是我考虑这种方法的前提是把直流电机的特性理解为线性了，而实际情况下，直流电机的特性绝对不是线性的，或者说在局部上是趋于线性的，这就是为什么说PID调速有个范围的问题。具体看一下http://articles.e-works.net.cn/component/article90249.htm（见附录2）这篇文章就可以了解了。所以在正式进行调速设计之前，需要现有开环系统，测试电机和转速之间的特性曲线（或者查阅电机的资料说明），然后再进行闭环参数整定。这篇先写到这，下一篇说明连续系统的离散化问题。并根据离散化后的特点讲述位置型PID和增量型PID的用法和C语言实现过程。">http://blog.21ic.com/user1/3407/archives/2006/33541.html（见附录1）这篇文章上给出了一种方法，即，每个电压对应一个转速，电压和转速之间呈现线性关系。但是我考虑这种方法的前提是把直流电机的特性理解为线性了，而实际情况下，直流电机的特性绝对不是线性的，或者说在局部上是趋于线性的，这就是为什么说PID调速有个范围的问题。具体看一下http://articles.e-works.net.cn/component/article90249.htm（见附录2）这篇文章就可以了解了。所以在正式进行调速设计之前，需要现有开环系统，测试电机和转速之间的特性曲线（或者查阅电机的资料说明），然后再进行闭环参数整定。这篇先写到这，下一篇说明连续系统的离散化问题。并根据离散化后的特点讲述位置型PID和增量型PID的用法和C语言实现过程。</a><br>PID控制算法的C语言实现二 PID算法的离散化<br>上一节中，我论述了PID算法的基本形式，并对其控制过程的实现有了一个简要的说明，通过上一节的总结，基本已经可以明白PID控制的过程。这一节中先继续上一节内容补充说明一下。<br>1.PID控制其实是对偏差的控制过程<br>2.如果偏差为0,则比例环节不起作用，只有存在偏差时，比例环节才起作用。<br>3.积分环节主要是用来消除静差——静差，是系统稳定后输出值和设定值之间的差值，积分环节实际上就是偏差累计的过程，把累计的误差加到原有系统上以抵消系统造成的静差。<br>这里我的理解是，如果在静差持续存在的时候，说明u(t)仍不够大/小，通过对该偏差的持续累积增大/减小u(t)的值，来使实际值向设定值靠近。<br>4.而微分信号则反应了偏差信号的变化趋势，根据偏差信号的变化趋势来进行超前调节，从而增加了系统的快速性。这里我的理解是，进行预测未来，当增长量过大时du(t)/dt也会反向很大，起到来拒去留，稳定系统的效果。</p><p>这是PID的数学表述：</p><p>下面将对PID连续系统离散化，从而方便在处理器上实现：<br>假设采样间隔为T，则在第K T时刻：<br>偏差err(K)=rin(K)-rout(K);<br>积分环节用加和的形式表示，即err(K)+err(K-1)+……;<br>微分环节用斜率的形式表示，即[err(K)-err(K-1)]/T;（T为采样时间）<br>从而形成如下PID离散表示形式：<br>则u(K)可表示成为：ActualSpeed=Kp<em>err+Ki</em>integral+Kd*(err-err_last)<br>用离散型数学表达即为：</p><p>这种表述形式称为位置型PID。<br>且由连续型易得Ki=Kp<em>T/Ti,Kd=Kp</em>Td/T，其中T为采样时间可知<br>Ti称为积分时间，Td称为积分时间。他们可以替代Ki，Kd，两者地位相同（参数变种）<br>从这个公式可以知道Ki，Kd均受到Kp的影响</p><p>另外一种表述方式为增量式PID：<br>incrementSpeed=Kp<em>(err-err_next)+Ki</em>err+Kd<em>(err-2</em>err_next+err_last);<br>ActualSpeed+=incrementSpeed<br>这就是离散化PID的增量式表示方式，增量式的表达结果和最近三次的偏差有关，这样就大大提高了系统的稳定性。需要注意最终的输出结果应该是增量式PID的累加。</p><p>PID的离散化过程基本思路就是这样，下面是将离散化的公式转换成为C语言。<br>PID控制算法的C语言实现三 位置型PID的C语言实现<br>第一步：定义PID变量结构体，代码如下：<br>struct _pid{<br>    float SetSpeed;            //定义设定值<br>    float ActualSpeed;        //定义实际值<br>    float err;                //定义偏差值<br>    float err_last;            //定义上一个偏差值<br>    float Kp,Ki,Kd;            //定义比例、积分、微分系数<br>    float voltage;          //定义电压值（控制执行器的变量）（有的地方也用电流）<br>    float integral;            //定义积分值<br>}pid;<br>控制算法中所需要用到的参数在一个结构体中统一定义，方便后面的使用。<br>  第二部：初始化变量，代码如下：<br>void PID_init(){<br>    printf(“PID_init begin \n”);<br>    pid.SetSpeed=0.0;<br>    pid.ActualSpeed=0.0;<br>    pid.err=0.0;<br>    pid.err_last=0.0;<br>    pid.voltage=0.0;<br>    pid.integral=0.0;<br>    pid.Kp=0.2;<br>    pid.Ki=0.015;<br>    pid.Kd=0.2;<br>    printf(“PID_init end \n”);<br>}<br>统一初始化变量，尤其是Kp,Ki,Kd三个参数，调试过程当中，对于要求的控制效果，可以通过调节这三个量直接进行调节。<br>第三步：编写控制算法，代码如下：<br>float PID_realize(float speed){    //传入的参数用作设定值<br>    pid.SetSpeed=speed;<br>    pid.err=pid.SetSpeed-pid.ActualSpeed;    //偏差值<br>    pid.integral+=pid.err;        //偏差值的积分累加，用作I<br>//通过PID算法得到pid下的电压，通过电压控制实际速度<br>//这里没有dt是因为dt由系统程序（时钟）决定，因为会把这段语句放入循环<br>    pid.voltage=pid.Kp<em>pid.err+pid.Ki</em>pid.integral+pid.Kd<em>(pid.err-pid.err_last);<br>    pid.err_last=pid.err;    //上次的偏差值，用作D运算<br>    pid.ActualSpeed=pid.voltage</em>1.0;    //电机电压与实际速度比例为1<br>    return pid.ActualSpeed;<br>}<br>注意：这里用了最基本的算法实现形式，没有考虑死区问题，没有设定上下限，只是对公式的一种直接的实现，后面的介绍当中还会逐渐的对此改进。</p><p>下面是测试代码：<br>int main(){<br>    printf(“System begin \n”);<br>    PID_init();<br>    int count=0;<br>    while(count&lt;1000)<br>    {<br>        float speed=PID_realize(200.0);    //循环PID逼近200<br>        printf(“%f\n”,speed);<br>        count++;<br>    }<br>return 0;<br>}</p><p>PID控制算法的C语言实现四 增量型PID的C语言实现<br>上一节中介绍了最简单的位置型PID的实现手段，这一节主要讲解增量式PID的实现方法，实现过程仍然是分为定义变量、初始化变量、实现控制算法函数、算法测试四个部分。#include<stdio.h></p><h1 id="include"><a href="#include" class="headerlink" title="include"></a>include<stdlib.h></h1><p>struct _pid{<br>    float SetSpeed;            //定义设定值<br>    float ActualSpeed;        //定义实际值<br>    float err;                //定义偏差值<br>    float err_next;            //定义上一个偏差值<br>    float err_last;            //定义上上个的偏差值<br>    float Kp,Ki,Kd;            //定义比例、积分、微分系数<br>}pid;</p><p>void PID_init(){<br>    pid.SetSpeed=0.0;<br>    pid.ActualSpeed=0.0;<br>    pid.err=0.0;<br>    pid.err_last=0.0;<br>    pid.err_next=0.0;<br>    pid.Kp=0.2;<br>    pid.Ki=0.015;<br>    pid.Kd=0.2;<br>}</p><p>float PID_realize(float speed){<br>    pid.SetSpeed=speed;<br>    pid.err=pid.SetSpeed-pid.ActualSpeed;</p><p>//这里与位置式不同的是，增量式得到的是一个delta而不是可以直接用的实际值<br>//最后需要将delta累加起来才能得到实际速度<br>float incrementSpeed=pid.Kp<em>(pid.err-pid.err_next)+pid.Ki</em>pid.err+pid.Kd<em>(pid.err-2</em>pid.err_next+pid.err_last);<br>pid.ActualSpeed+=incrementSpeed;        //累加delta得实际速度<br>    pid.err_last=pid.err_next;<br>    pid.err_next=pid.err;<br>    return pid.ActualSpeed;<br>}</p><p>int main(){<br>    PID_init();<br>    int count=0;<br>    while(count&lt;1000)<br>    {<br>        float speed=PID_realize(200.0);<br>        printf(“%f\n”,speed);<br>        count++;<br>    }<br>    return 0;<br>}</p><p>PID控制算法的C语言实现五 积分分离的PID控制算法C语言实现<br>通过三、四两篇文章，基本上已经弄清楚了PID控制算法的最常规的表达方法。在普通PID控制中，引入积分环节的目的，主要是为了消除静差，提高控制精度。但是在启动、结束或大幅度增减设定时，短时间内系统输出有很大的偏差（详见pid数据开头部分）会造成PID运算的积分积累，导致控制量超过执行机构可能允许的最大动作范围对应极限控制量，从而引起较大的超调，甚至是震荡，这是绝对不允许的。<br>为了克服这一问题，引入了积分分离的概念，基本思路是当被控量与设定值偏差较大时，取消积分作用; 当被控量接近给定值时，引入积分控制，以消除静差，提高精度。其具体实现代码如下：<br>    pid.Kp=0.2;<br>    pid.Ki=0.04;<br>    pid.Kd=0.2;  //初始化过程</p><p>if(abs(pid.err)&gt;200)    //200太极限了，总之就是当偏差值过大时不引入积分(index=0且不累计)<br>    index=0;<br>else<br>{<br>    index=1;<br>pid.integral+=pid.err;<br>}<br>pid.voltage=pid.Kp<em>pid.err+index</em>pid.Ki<em>pid.integral+pid.Kd</em>(pid.err-pid.err_last);<br>其他代码相同，不做赘述</p><p>PID控制算法的C语言实现六 抗积分饱和的PID控制算法C语言实现<br>   所谓的积分饱和现象是指如果系统存在一个方向的偏差，PID控制器的输出由于积分作用的不断累加而加大，从而导致执行机构达到极限位置，若控制器输出U(k)继续增大，执行器开度不可能再增大，此时计算机输出控制量超出了正常运行范围而进入饱和区。一旦系统出现反向偏差，u(k)逐渐从饱和区退出。进入饱和区越深则退出饱和区时间越长。在这段时间里，执行机构仍然停留在极限位置而不随偏差反向而立即做出相应的改变，这时系统就像失控一样，造成控制性能恶化，这种现象称为积分饱和现象或积分失控现象。<br>    防止积分饱和的方法之一就是抗积分饱和法，该方法的思路是在计算u(k)时，首先判断上一时刻的控制量u(k-1)是否已经超出了极限范围： 如果u(k-1)&gt;umax，则只累加负偏差; 如果u(k-1)&lt;umin，则只累加正偏差。从而避免控制量长时间停留在饱和区。直接贴出代码，不懂的看看前面几节的介绍。<br>struct _pid{<br>    float SetSpeed;            //定义设定值<br>    float ActualSpeed;        //定义实际值<br>    float err;                //定义偏差值<br>    float err_last;            //定义上一个偏差值<br>    float Kp,Ki,Kd;            //定义比例、积分、微分系数<br>    float voltage;            //定义电压值（控制执行器的变量）<br>    float integral;            //定义积分值<br>    float umax;<br>    float umin;<br>}pid;</p><p>void PID_init(){<br>    printf(“PID_init begin \n”);<br>    pid.SetSpeed=0.0;<br>    pid.ActualSpeed=0.0;<br>    pid.err=0.0;<br>    pid.err_last=0.0;<br>    pid.voltage=0.0;<br>    pid.integral=0.0;<br>    pid.Kp=0.2;<br>   pid.Ki=0.1;       //注意，和上几次相比，这里加大了积分环节的值<br>    pid.Kd=0.2;<br>    pid.umax=400;    //阈值[-200,400]<br>    pid.umin=-200;<br>    printf(“PID_init end \n”);<br>}<br>float PID_realize(float speed){<br>    int index;<br>    pid.SetSpeed=speed;<br>    pid.err=pid.SetSpeed-pid.ActualSpeed;<br>   if(pid.ActualSpeed&gt;pid.umax)    //超过正阈值<br>    {</p><pre><code>       if(abs(pid.err)&gt;200)         //积分分离        index=0;      else</code></pre><p>{<br>            index=1;<br>            if(pid.err<0) pid.integral+=pid.err;    //超过正阈值了，只累积负偏差          }    }else if(pid.ActualSpeed<pid.umin){    //超过负阈值        if(abs(pid.err)>200)<br>            index=0;<br>        else<br>{<br>            index=1;<br>            if(pid.err&gt;0)  pid.integral+=pid.err;        //超过负阈值了，只累积正偏差<br>}<br>    }<br>else{    //未超过阈值，正常计算<br>        if(abs(pid.err)&gt;200)                    //积分分离过程<br>            index=0;<br>else{<br>            index=1;<br>            pid.integral+=pid.err;    //正常累积<br>        }<br>    }</p><pre><code>pid.voltage=pid.Kp*pid.err+index*pid.Ki*pid.integral+pid.Kd*(pid.err-pid.err_last);pid.err_last=pid.err;pid.ActualSpeed=pid.voltage*1.0;return pid.ActualSpeed;</code></pre><p>}</p><p>PID控制算法的C语言实现七 梯形积分的PID控制算法C语言实现<br>先看一下梯形算法的积分环节公式（？）<br>作为PID控制律的积分项，其作用是消除余差，为了尽量减小余差，应提高积分项运算精度，为此可以将矩形积分改为梯形积分，具体实现的语句为：<br>pid.voltage=pid.Kp<em>pid.err+index</em>pid.Ki<em>pid.integral/2+pid.Kd</em>(pid.err-pid.err_last);<br>最后运算的稳定数据为：199.999878，较教程六中的199.9999390而言，精度进一步提高。</p><p>PID控制算法的C语言实现八 变积分的PID控制算法C语言实现<br>   变积分PID可以看成是积分分离的PID算法的更一般的形式。在普通的PID控制算法中，由于积分系数ki是常数，所以在整个控制过程中，积分增量是不变的。但是，系统对于积分项的要求是，系统偏差大时，积分作用应该减弱甚至是全无，而在偏差小时，则应该加强。积分系数取大了会产生超调，甚至积分饱和，取小了又不能短时间内消除静差。因此，根据系统的偏差大小改变积分速度是有必要的。<br>   变积分PID的基本思想是设法改变积分项的累加速度，使其与偏差大小相对应：偏差越大，积分越慢; 偏差越小，积分越快。</p><p>   这里给积分系数前加上一个比例值index：（相比于积分分离更加精确了）<br>   当abs(err)<180时，index=1;   当180<abs(err)<200时，index=（200-abs(err)）/20;   当abs(err)>200时，index=0;<br>   最终的比例环节的比例系数值为ki*index;    </p><p>   具体PID实现代码如下：<br>    pid.Kp=0.4;<br>    pid.Ki=0.2;    //增加了积分系数<br>    pid.Kd=0.2;</p><p>   float PID_realize(float speed){<br>    float index;<br>    pid.SetSpeed=speed;<br>    pid.err=pid.SetSpeed-pid.ActualSpeed;</p><pre><code>if(abs(pid.err)&gt;200)           //变积分过程，调整I在pid不同阶段中的重要性&#123;index=0.0;&#125;else if(abs(pid.err)&lt;180)&#123;index=1.0;pid.integral+=pid.err;&#125;else&#123;index=(200-abs(pid.err))/20;pid.integral+=pid.err;&#125;pid.voltage=pid.Kp*pid.err+index*pid.Ki*pid.integral+pid.Kd*(pid.err-pid.err_last);pid.err_last=pid.err;pid.ActualSpeed=pid.voltage*1.0;return pid.ActualSpeed;</code></pre><p>}</p><p> PID参数整定方法：<br>PID的整定方法很多，其效果在不同的系统里各有千秋，可以多尝试不同的方法整定，来达到最佳的整定结果。<br>1.知识储备：<br>比例增益Kp是指输出变化对偏差变化之比。而比例度δ则是指调节器的偏差值占输出值变化的百分比。这两种表示方法互为倒数关系，即：KP=1/δ。<br>Ki与Ti，Kd与Td的转化：Ki=Kp<em>T/Ti,Kd=Kp</em>Td/T<br>2.衰减曲线法：<br>本方法实际是临界比例度法一种变形，本方法操作简便，凑试时间较短。首先把Ki，Kd置零，用一个较大的Kp来纯比例作用系统，在比例度逐步减少的过程中，就会出现右图所示的过渡过程。<br>这时控制过程的比例度Kp称为n:1衰减比例度δs；两个波峰之间的距离称为n:1衰减周期Ts。而衰减曲线法就是在纯比例作用的控制系统中，求得衰减比例度δs和衰减周期Ts，并依据这两个数据和经验表格来得到PID的系数。具体地分为4:1和10:1衰减曲线法。<br>4:1衰减曲线法整定步骤：首先把Ki，Kd置零，Kp放至较大的适当值，使控制系统按纯比例作用的方式投入运行。然后慢慢地减少比例度，观察调节器的输出及控制过程的波动情况，直到找出4:1的衰减过程为止，并记下此时的δs（Kp）和Ts。<br>在部分调节系统中，由于采用4:1衰减比仍嫌振荡比较厉害，则可采用10：1的衰减过程。10:1衰减曲线法整定步骤：和4:1衰减曲线法在过程上完全一致，只是采用的整定参数和经验公式不同。此时所需的参数为衰减比例度δs和首次峰值加速时间Tr。<br>根据n:1选择衰减比例度s和衰减周期Ts、首次峰值加速时间Tr的经验表格计算<br>注意：网上给出了不同的经验表格，可以多次尝试选最优。表格3中的Ti，Td改成Ts。</p><p>3.临界比例度法</p><p>4.经验公式：<br>Kp调整为0.00100-0.01000之间<br>Ki调整在0.00050左右<br>Kd调整在0.00005-0.00020之间<br>RPM=15000：0.006 0.0001 0.00025<br>减小超调通过增大Kp，加快回落通过增大Ki，减少震荡通过增大Kd</p><p>④先将比例度放在一个比计算值大的数值上，然后加上积分时间Ti，再慢慢加上微分时间Td。操作时一定要按“PID序加参数”，即先P次I最后D，不要破坏了这个次序。<br>⑤把比例度降到计算值上，通过观察曲线，再作适当的调整各参数。即“观看运行细调整”，直到找出最佳值。</p><p>PID整定经验：<br>1.纯Kp情况下的曲线大致如此，此时可以看到所谓的衰减曲线法的衰减率。如果不是纯Kp下发生类似曲线，也可能是Kp过大或Kd过小</p><p>2.PID整定时出现这种状况（超调）通常是Ki过大导致的，此时可以调小Ki解决。此时也可以调大Kd，但可能对后续阶段产生影响。通常见于微小超调情况下，调小Ki有很好的效果。但由于Ki过小会导致静差，实在不行也可以调大Kp（因为Kp调大会间接增强Kd在上升段的影响，这是可以接受的。不要误以为Kp过大导致超调而调小Kp，实际上这是Kd来拒去留效果的表现）同理当反向超调时可以调大Ki等。</p><p>3.当长久情况下PID一直回不到预设值，此时是Ki过小无法控制静差导致的，应该调大Ki。此外，若是稳定后误差±过大，则应该调大Kd。</p><p>4.此时通常是因为Kp过小或是Kd过大导致的，体现在上升过程过慢且会有一个大而光滑的弧。此时需要调大Kp或调小Kd。</p><p>5.良好的PID曲线。快速上升，准确停止，稳态误差不大。</p>]]></content>
      
      
      <categories>
          
          <category> 控制理论 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PID </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习</title>
      <link href="/2022/08/09/DeepLearning/"/>
      <url>/2022/08/09/DeepLearning/</url>
      
        <content type="html"><![CDATA[<p>SNN(Standard Neural Network)：标准神经网络，房价预测可以使用这种神经网络。<br>CNN(Convolution Neural Network)：卷积神经网络，图像处理可以使用这种神经网络。<br>RNN(Recurrent Neural Network)：循环神经网络，语言翻译和音频处理等序列化数据可以使用这种神经网络。</p><p>非结构化（例如图片、文字、音频）的数据比结构化（例如表格）数据的学习要困难得多。</p><p>推动深度学习发展的有三大因素：数据、计算能力(GPU)和算法。</p><p>神经网络的前向传播与反向传播：<br>前向传播：是数据从输入层输入，经过一层层隐藏层计算得到中间变量，最后从输入层得到输出的过程。换句话说，前向传播计算出了神经网络对输入的预测输出。<br>反向传播：是根据前向传播计算的预测值与真实值的差距得到损失函数，并对损失函数利用梯度下降来更新参数w,b的过程。应用梯度下降的核心在于计算损失函数对各w,b的偏导数。而计算这些偏导数的过程是反向的，也就是从最后一层逐层向前去计算，去改变每一层的w和b，其原理是链式求导法则。<br>我们以一个有两层隐藏层的神经网络为例：</p><p>在这个例子中，我们使用前向传播依次得到x=&gt;z[1]=&gt;a[1]=&gt;z[2]=&gt;a[2]的值，使用反向传播结合链式法则依次得到：<br>dL/da[2]=&gt;dL/dz[2]=&gt;dL/dw[2]&amp;dL/db[2]=&gt;dL/da[1]=&gt;dL/dz[1]=&gt;dL/dw[1]&amp;dL/db[1]的值。<br>综上，前向传播是神经网络根据输入得到输出的过程(a[l-1]=&gt;a[l])，反向传播是神经网络根据损失函数得到参数偏导，从而利用梯度下降更新参数的过程<br>(dJ/da[l]=&gt;dJ/da[l-1],dW[l],dB[l])。<br>一个神经元从输入到输出的过程也可以用下面这张图表示，即x-&gt;z-&gt;a：</p><p>除了线性激活函数，sigmoid激活函数和ReLU激活函数外，再介绍两个激活函数：tanh激活函数和leaky ReLU激活函数。他们分别是sigmoid激活函数和ReLU激活函数的同位替补。</p><p>其中tanh激活函数的值处于[-1,1]之间，其具有基值为0的特点，在处理非二元分类问题时通常比sigmoid激活函数更有优势，因而除了二元分类问题，适合使用sigmoid激活函数的场合都可以使用tanh激活函数替代。<br>而leaky ReLU激活函数在负值区域（0.01可以修改为任意小值）具有斜率，可以避免ReLU激活函数在负值区域斜率为0的缺点，而在实际使用时使用ReLU还是leaky ReLU激活函数不会产生特别大的差别，故大部分场合使用ReLU激活函数就可以了。<br>使用ReLU或者leaky ReLU激活函数作为隐藏层激活函数会使神经网络的效率相比于使用sigmoid和tanh激活函数高出不少。</p><p>常见激活函数的导数如下：</p><p>神经网络的矢量化：对神经网络的矢量化既涉及不同的神经元，又涉及不同的训练数据。<br>1.前向传播的矢量化：<br>对于同一训练数据而言，当其经过一个有n个神经元（换句话说就是有n个输出）和m个输入（换句话说就是上一层有m个神经元）的网络层时，基于公式可知，该层的[w][l]是一个n<em>m的矩阵，而该层的[b][l]和输出aj[l]是一个n</em>1的向量。<br>而对于一组训练数据样本而言，我们可以用矩阵X表示数据样本集，其中X的每列代表一个数据样本，而每行代表一个数据样本的不同输入。假设样本个数为m，每个样本的输入个数为n，则X的规模为n*m：</p><p>由于单个样本时的X规模为(n*1)，因而[w]和[b]的规模都不需要修改，对X的矢量化会自动对Z和A矢量化，即Z和A的每列都会是不同样本的值，而横向则是不同的神经元。</p><p>2.反向传播的矢量化：假设每层神经元输入输出满足：z[l]=W[l]a[l-1]+B[l],a[l]=g<a href="z[l]">l</a><br>则按照反向传播规则，对于每个样本来说，有：<br>①dL/dW[l]=dL/dz[l]<em>dz[l]/dW[l]=dL/dz[l]</em>a[l-1]T<br>②dL/dB[l]=dL/dz[l]<br>③dL/dz[l-1]=dL/dz[l]<em>dz[l]/da[l-1]</em>da[l-1]/dz[l-1]=W[l]T<em>dL/dz[l]</em>g[l-1]’(z[l-1])<br>以此类推得到反向传播递推式，从而可以反向传播得到各偏导值，而最后一层的dL/dz[l]值可以由dL/da[l]<em>da[l]/dz[l]=dL/hat{y}</em>hat{y}/dz[l]直接得到。<br>如果要扩展为样本总集的矢量化，由于dJ=1/m<em>∑(dL)，则有：<br>Z[l]=W[l]A[l-1]+B[l],A[l]=g<a href="Z[l]">l</a><br>①dJ/dW[l]=1/m</em>dJ/dZ[l]<em>dZ[l]/dW[l]=1/m</em>dJ/dZ[l]<em>A[l-1]T<br>②dJ/dB[l]=dJ/dZ[l]<br>③dJ/dZ[l-1]=dJ/dZ[l]</em>dZ[l]/dA[l-1]<em>dA[l-1]/dZ[l-1]=W[l]T</em>dJ/dZ[l]*g[l-1]’(Z[l-1])</p><p>深度神经网络是指有很多隐藏层的神经网络，它的优势在于：它可以让前面的神经层学习一些级别较低的简单特征，而让后面更深的神经层汇聚前面所检测到的简单信息以便检测更复杂的事物。<br>我们把神经网络的层数、每层的神经元数量、每个神经元用到的激活函数、总迭代次数、学习率α称为神经网络的超参数，而把[W]和[B]称为参数。即超参数是可以认为设置的，而参数则是神经网络自己学习而来的。大量事实表明，神经网络超参数的可选性是很高的，且要找到一个最佳的超参数组是没有理论和系统方法的，对于不同的神经网络，超参数的最佳取值也会不同，因而在构建神经网络时应该大胆尝试超参数的选值，并利用交叉验证集以寻求一个不错的结果。<br>在机器学习中，我们了解了神经网络的正则化，事实上那种正则化方法被称为L2正则化，而正则化作为一个泛类，还包含了其他很多方法，但其目的都是为了解决过拟合问题，我们再介绍一个被称为随机失活的正则化方法：<br>随机失活(Dropout)：仿照L2正则化引入正则化项以整体减小w的目的，随机失活指出，我们遍历每层网络层的每个神经元，并为每层网络层设置一个留存率(keep-prob)，对该层上的每个神经元进行一次随机留弃，决定丢弃的各神经元会被切断所有的输入输出通路。随机失活的结果会带来一个比原有神经网络小得多的新神经网络，并对该神经网络进行前向和反向传播。其原理即把某些神经元的[W]和[B]参数完全置0，其效果类同于L2正则化减小w。换个角度思考，因为我们可能把任意的神经元失活，这会促使神经网络在学习参数时不过度依赖于某个输入特征，进而将w更均匀且更小的分配给每个输入特征。</p><p>对于每一层，由于随机失活消去了一部分的神经元，这会导致该层的输出期望改变为原来的输出期望乘以留存率；为了保持输出期望不变，我们最后还要对随机失活处理后的输出值除以留存率才能作为下层输入。</p><p>在新的一次迭代时，神经元的留弃会被重新确定。同时，正如L2正则化只在训练集中起作用一样，随机失活也只会针对训练集，而对于测试集数据，我们只会使用完整的神经网络而不进行随机失活。对于不同的网络层，我们可以使用不同的留存率，对于输入输出关系越复杂的网络层（上层和下层都有很多神经元），越有可能产生过拟合，就越可以采取较低的留存率，可见留存率也是一个可供选择的超参数。<br>随机失活的缺点在于，它让代价函数变得不够明确，因为每次的随机失活都会导致代价函数发生变化，当你想要去检验梯度下降算法表现时，你很难确认代价函数真的随着迭代减小了。<br>随机失活常常用于计算机视觉领域。<br>梯度消失与爆炸：<br>深层的神经网络会受制于梯度消失与爆炸的问题，具体表现为权值[W]随着层数产生指数级减小或增大的现象，这会导致训练神经网络时梯度的计算结果会过小或过大，进而影响训练效率和效果，而这个问题始终是训练深层神经网络的巨大壁垒。为了减弱梯度消失和爆炸的影响，我们可以在神经网路的权值[W]初始化中下功夫：<br>数学证明，对于ReLU类的激活函数和tanh类的激活函数，我们可以使用不同的权值初始化方法来达到减弱梯度消失和爆炸的效果。<br>对于ReLU类的激活函数，我们可以使用Xavier初始化(Xavier Initialization)，具体地：<br>让权重[W]满足均值为0，方差为sqrt(2/n)的正态分布，其中n为该层网络层的输入个数。<br>而对于tanh类的激活函数，我们可以使用Kaiming初始化(Kaiming Initialization)，具体地：<br>让权重[W]满足均值为0，方差为sqrt(1/n)的正态分布，其中n为该层网络层的输入个数。<br>此外，也有一些其他的权值初始化方法，例如让权重[W]满足均值为0，方差为sqrt(2/n+m)的正态分布，其中n为该层网络层的输入个数，m为该层网络层的输出个数。<br>如果你觉得有必要，也可以把权值初始化方法当作超参数经由交叉验证集检验。</p><p>梯度检验：<br>当我们算出一个函数的偏导公式时，如何检验这个公式真的准确无误又或是可能因为马虎写错了呢？此时就要使用我们的梯度检验，所谓的梯度检验事实上就是导数检验。<br>如果要得到一个函数对应导数的数值解，可以使用双边公式f’(x)=[f(x+ε)-f(x-ε)]/2ε，其中ε是一个很小的值，然后拿这个数值解与导数的解析解f’(x)=[f(x)]’做比较，就可以检验导数的解析解是否真的是对的了。对应到反向传播算法中，我们如何检验dJ/dW和dJ/dB的公式准确无误呢？我们只需要将[W]和[B]组合成一个大的矩阵[θ]，并根据代价函数得到J([θ])，然后对每一项θi都进行一次双边公式得到数值解并与解析解J’(θi)作比较即可。</p><p>比较的方法是，两值的欧氏距离与他们各自与原点的欧氏距离之和的比值：</p><p>如果结果介于10-7-10-5之间，说明梯度检验通过，导数并没有解析问题，反之则要好好检查。值得注意的是，如果J有L2正则化项，则求导数的解析解和数值解时都应该要带上该项；且梯度检验不适用于随机失活方法中，因为此时的J不具有参考价值。</p><p>神经网络的小批量(Mini-Batch)梯度下降法（称为随机梯度下降SGD）：在神经网络中同样也有小批量的概念用于处理大规模的样本集。将大规模的样本集平均分为相等的几部分，每部分分别记为X{t}和Y{t}，对于每个部分进行一次梯度下降的迭代，并在下一部分继承上一部分迭代得到的参数，故n部分的小批量梯度下降总共需要做n次梯度下降。由于只采用部分数据，因此它的每一步在接近全局最小值时可能不够可靠甚至有些嘈杂，有时甚至会背离最小值移动，但它整体仍沿着趋向全局最小值的方向运动。但其优势在于当训练集很大时，它仍然能以较快的速度完成每一步迭代，这也是为什么当训练集很大时我们总是去使用小批量梯度下降法。</p><p>其他的梯度下降算法：<br>梯度下降算法有很多更好的变体，例如之前学过的Adam算法，这里我们从理论上解释其优化原理。在此之前，我们先介绍指数加权平均的思想。<br>指数加权平均曾在软更新中得到过应用，其公式即：</p><p>其中vt是本次的加权平均结果，vt-1是上次的加权平均结果，θt是本次的原始结果，β是介于(0,1)之间的权重因子，通常取β=0.9。<br>上式是一个递推式，如果写成一般式，即：</p><p>可以看到，指数加权平均结合了所有的过去数据来得到最终结果，且当前的原始结果是最大参照项。利用指数加权平均，我们结合了过去数据和本次数据，从而得到了一个值得信赖的结果。且由于指数加权平均的递推公式，使得其在编程中非常容易实现，其中递推终点为v0，定义v0=0。这样进行指数加权平均有一个问题，由于v0=0，故在前几次迭代中平均值vn和原始值θt会相差很大，例如v1=0.1θ1，v2=0.09θ1+0.1θ2…为了解决这个问题，我们引入偏差修正的概念：我们发现，θ的各系数是一个等比数列，其和为(1-βt)，因而如果我们把最后的结果再除以(1-βt)就可以得到一个比较合理的归一化结果，且当t趋于无穷时(1-βt)趋于1，就和原来的指数加权平均公式类似了，偏差修正主要为了平和迭代次数较少时平均值和原始值的差距。例如v1=0.1/0.1θ1，v2=(0.09/0.19)θ1+(0.1/0.19)θ2<br>①动量梯度下降(Momentum Gradient Descent)：<br>在运行一般梯度下降时，我们可能会遇到下面的情况：</p><p>动量梯度下降希望加快横轴方向的学习速度，减缓纵轴方向的学习速度，此时就可以用指数加权平均的思想。在每次迭代计算出原始值dW和db后，利用指数加权平均得到计算值vdW和vdb，并使用指数加权平均后的计算值来更新W和b，其公式即：</p><p>由于我们要迭代多次且只取最后的迭代结果，因而没有必要进行偏差修正，且通常仍取β=0.9。<br>②均方根前向传播(Root Mean Square Prop=RMSprop)：<br>其公式与动量梯度下降类似，仍然是利用指数加权平均的思想。只是此时的原始值为dW和db的平方，记计算值为Sdw和Sdb，更新参数为dW/sqrt(Sdw)和db/sqrt(Sdb)。</p><p>通常取β=0.999。<br>当然，运用均方根前向传播时可能碰到的问题在于，Sdw和Sdb可能会非常小以至于dW/sqrt(Sdw)和db/sqrt(Sdb)趋于无穷，这不利于算法的稳定。解决办法是在分母加一个小量ε，通常取ε=10-8。即：</p><p>③Adam算法(Adaptive Moment Estimation)：<br>Adam算法结合了动量梯度下降和均方根前向传播，被认为是运行梯度下降的最佳权威算法。<br>记动量梯度下降的相关参数为：vdW，vdb，β1。<br>记均方根前向传播的相关参数为：SdW，Sdb，β2。<br>初始时，令vdW，vdb，SdW，Sdb均为0，在每次迭代时遵循以下规则：</p><p>即利用动态梯度下降的方法计算出vdW，vdb，利用均方根前向传播的方法计算出SdW，Sdb，然后对vdW，vdb，SdW，Sdb进行偏差修正，最后的更新量为vdW/(sqrt(Sdw)+ε)，vdb/(sqrt(Sdb)+ε)。<br>参数的选择一般直接取默认值β1=0.9，β2=0.999，ε=10-8。</p><p>学习率衰减(Learning Rate Decay)：<br>加快学习算法的另一个方法是随时间慢慢减少学习率α，这么做的话可以让开始时有一个较大的学习率，从而加快学习速度；同时快要结束时有一个较小的学习率，从而能够更加细致地探查局部最小值，从而达成收敛，避免耗费无意义的时间在低谷附近反复摆动。<br>衰减学习率的方法也有很多，下面简单介绍几种：<br>①：其中decay-rate为衰减率，是一个超参数；epoch-num为迭代次数，α0是初始学习率。</p><p>②：其中0.95可以是任意小于1的值</p><p>③：</p><p>利用上面三种方法，可以使学习率α随着迭代次数epoch-num增加而减小。</p><p>接下来让给我们看一下局部最优的问题：<br>曾经我们被教导，梯度下降算法可能会陷入局部最优中而无法找到全局最优。但事实上，对于大型神经网络组成的高位空间而言，其存在局部最优的可能性是很小的，其整体图形大概率不是左边的峰谷型而是右边的马鞍形。这是因为局部最优产生的条件是，对于每个维度而言都在该处取到极小值，如果我们认为各维度下导数为零的点是极小值或极大值的概率均等，则对于n维空间而言，导数为零的点会产生局部最小值的概率仅为0.5^n，这对于高维空间而言几乎是不可能出现的，而导数为零的点更有可能出现右边的马鞍形结构，称该点为鞍点(Saddle Point)。即部分维度在鞍点取到极小值，部分维度在鞍点取到极大值。</p><p>对于马鞍形结构，梯度下降算法是有能力破局的。假设起点如下图所示，依照梯度理论，损失函数将逐渐下降到鞍点，并在鞍点附近因为随机扰动离开鞍点，往某一边继续进行梯度下降，从而完成破局。当然，存在的问题在于鞍点附近的导数接近于0，这可能会导致梯度下降算法在鞍点附近花费较长的时间，而这也是Adam等算法脱颖而出的原因。</p><p>综上，在高维度的神经网络中，我们通常不用去担忧梯度下降算法可能会陷入局部最优的问题，但鞍点的存在同样会导致梯度下降算法在鞍点附近花费较长的时间，幸运的是，Adam等算法的问世有效的提高了梯度下降在鞍点附近的效率。</p><p>在之前的学习过程中，我们学习了很多的超参数。例如学习率α，Adam算法中的β1，β2和ε，神经网络的层数，每层神经网络神经元的数量，学习率衰减参数，小批量更新的规模等。这些参数的调整也存在一定的优先级，一般来说，学习率α总是最重要的，其次是每层神经网络神经元的数量和小批量更新的规模，再其次是神经网络的层数和学习率衰减参数，而Adam算法中的β1，β2和ε通常直接取默认值就可以，无需更改。现在的问题是，对于一个完全陌生的神经网络，我们如何为这些超参数选值呢？<br>一个很好的方法是对所有的超参数在给定的可能最优范围内随机取值并重复多次，找到这些取值里效果最好的一组或几组超参数集合，并缩小可能最优范围到这些超参数附近，再次重复上述步骤，直到认为找到了接近全局最优的超参数。即随机选取与逐级精细。</p><p>对于可能最优范围内的随机取值，需要根据范围选择使用自然坐标轴还是对数坐标轴。例如[50,100]内的随机取值用自然坐标轴更好，而[0.0001,0.1]或[0.9,0.999]内的随机取值用对数坐标轴更好。对数随机在Python中的实现可以参考以下代码（以[0.0001,0.1]为例）：<br>n=-3*np.random.rand()-1;<br>result=10^n;<br>return result;</p><p>补充知识：关于归一化、标准化和正则化<br>归一化（Normalization）：把数据变为（0，1）之间的小数，比如min-max归一化。主要是为了方便数据处理，因为将数据映射到0～1范围之内，可以使处理过程更加便捷、快速。<br>标准化（Standardization）：数据的标准化是将数据按比例缩放，使之落入一个小的特定区间。并不是为了方便与其他数据一同处理或比较，比如:z-score标准化，即零-均值标准化,数据经过零-均值标准化后，更利于使用标准正态分布的性质，进行处理；<br>正则化（Regularization）：用一组与原不适定问题相“邻近”的适定问题的解，去逼近原问题的解，这种方法称为正则化方法。利用先验知识，在处理过程中引入正则化因子(regulator)，增加引导约束的作用，比如在逻辑回归中使用正则化，可有效降低过拟合的现象。</p><p>Batch归一化(Batch Normalization)：<br>在之前的学习过程中，我们意识到对于神经网络和一般的线性或逻辑回归而言，对输入变量进行归一化或正则化可以有效的改善程序运行效率。事实上，我们对于隐藏层的各层结果也可以进行归一化，这被证明可以加快神经网络的学习速度。其基本过程如下：</p><p>首先需要注意的是，我们要进行Batch归一化的对象是各隐藏层的[z]，由z[l]=W[l]a[l-1]+B[l]，我们先接受上一层的输入，再经W和B得到z[l]，之后对z[l]进行Batch归一化（Batch归一化的过程在后面详述）得到tilde{z[l]}，最后对tilde{z[l]}进行激活得到a[l]=g<a href="tilde{z[l]}">l</a>作为下一层的输入。可见相比于一般的神经网络，Batch归一化在a=g(z)上额外加了一步算法。<br>现在让我们看看这步算法究竟干了什么，我们采用z-score标准化的逻辑：<br>首先，我们假设在逻辑层[l]上存在n组样本数据z(1)~z(n)，利用这些数据我们计算出该层z的均值和方差，从而利用z-score标准化变换得到均值为0，方差为1的数据集znorm（为了防止分母为零加了小量ε），但是我们不希望要求神经网络对z有一个明确的分布，因此tilde{z}是znorm线性化的结果，其中γ和β都是由神经网络通过梯度下降等方法训练更新迭代而来的参数，其性质和更新过程等同于w和b。</p><p>Batch归一化能奏效的原因是它限制了前层的参数更新影响数值分布的程度。<br>值得指出的一点是，Batch归一化下每层的学习参数似乎有四个w,b,γ和β，但由于要对z进行z-score标准化为均值为0，方差为1的数据集，因此参数b的取值是无意义的，可以不进行学习而固定为0，从而减少学习参数为三个w,γ和β。此外，实际应用时Batch归一化常与小批量更新mini-batch共用，故此时对于每个mini-batch而言，其均值和方差的计算均是基于该mini-batch对应的数据集得到的，即对于不同的mini-batch来说其均值和方差是不同的，和真正全局的均值和方差之间是存在噪声的，这也是mini-batch的一个特性。<br>而当模型训练完毕后使用测试集测试训练效果时，如何为测试样本选择均值和方差呢？<br>我们通常采用指数加权平均的方法，即不选择任一mini-batch的均值和方差作为最终测试用的均值和方差，而是使用指数加权平均将每个mini-batch的均值和方差综合纳入最终的考量。<br>机器学习策略：<br>1.正交化（解耦）：<br>所谓正交就是一个参数的调试只能影响一个结果，在调试过程中，我们应尽量避免一个参数的调试会同时改变多个结果，那么这个参数将会很难调整出一个多维都很完美的结果。就像调整电视屏幕一样，我们安排三个旋钮，其中一个只调整屏幕宽度，一个只调整屏幕高度，一个只调整屏幕角度，如此只需要对不同旋钮分别操作就可以得到一个很好的结果，反过来，如果一个旋钮可以同时控制屏幕宽度和屏幕角度，那么这个旋钮很难调出一个好结果。反映到深度学习领域，判断一个模型的好坏主要要参照四个参数：训练集的适配程度，交叉验证测试集（也叫开发集dev set）的适配程度，测试集的适配程度，在真实情况下的表现。为了分别调整这些参数，我们显然也要采用四个正交化的旋钮，保证在改变一个数据集适配程度时不影响其他数据集的适配程度。例如改变训练集的适配程度可以采取更大的神经网络或更好的梯度下降算法</p><p>2.单一数字评估指标：<br>有时候，我们判断一个模型的好坏可能会涉及多方面的参数，要一一比较这些参数的好坏是很困难的，最好的解决方法是给出一个由这些参数根据某个函数计算出的综合结果，也即所谓的单一数字，利用该数字做升序或降序排列便可以很好的评估不同模型的效果。典型的例子是精确率和召回率的矛盾，以及F1 Score的提出。<br>3.满足指标和优化指标：<br>有时单一数字评估指标并不是特别容易得到，应对这种多参数问题的有效方法是设置满足指标和优化指标。所谓满足指标是指一旦指标满足要求就被认为可行，而不在意该指标到底有多好；所谓优化指标是需要尽可能优化到最佳的指标，两者结合选择出最佳模型。例如下图是一个辨识猫的神经网络，我们设置满足指标为Running time&lt;100ms，优化指标为Accuracy。则符合满足指标的为A和B，取优化指标最佳的则最佳模型为B。</p><p>4.训练、开发、测试集的划分：<br>要求数据集中不同类型(Distribution)的数据被按比例均分到每个集中，而不是将某个类型全分到训练集中，而把另一类型全分到开发集中。开发集和测试集的数据量对于不同体量的神经网络差别不是很大，这意味着随着数据集的增大，训练&amp;开发&amp;测试集的占比不是一成不变的。一般开发和测试集数据量在1w左右，对于小型神经网络而言三集比例一般在60-20-20左右，而对于大型神经网络可以扩大到98-1-1。<br>5.优化神经网络：<br>调整评估指标：当原有的评估指标认为最佳的神经网络模型经人为检验存在问题时，就有必要调整评估指标。<br>改变开发-测试集：开发-测试集作为检验实际运行的样本，需要确保与实际过程的匹配。例如辨别猫的神经网络，人们拍出的照片往往模糊而构图不专业，此时若以一些高清而专业的照片作为开发-测试集，会因脱离实际情况而存在误差。<br>用人的表现衡量神经网络：在机器学习中提到过相应的概念，为了衡量神经网络的效果，通常需要有一个基准误差，这个基准误差应当是理论最低误差，也被称为贝叶斯最优错误率，但一般而言，选取人类在该问题上的误差就可以得到一个很好的基准了。利用训练集误差与基准误差的差值，交叉验证集误差与训练集误差的差值之间的关系可以判断神经网络目前存在高偏差（欠拟合）还是高方差（过拟合）问题，从而选择相应的方法解决问题。在人类擅长解决的领域中（比如自然语言处理），人类误差接近于贝叶斯最优错误率，训练集误差几乎难以超越人类误差，使用这个方法判断神经网络出现的问题是很不错的；而在人类不擅长解决的领域中（比如大数据分析），神经网络学习得到的训练集误差是可以超越人类误差的，当训练集误差超越人类误差时，对神经网络下一步改进的思路便会变得复杂，难以预料。</p><p>误差分析：所谓误差分析，即人类在系统判断错误的样本中抽取一部分来观察出错的原因，并取其中占比较大的优先解决。我们可以为样本集添加大量由最大原因导致的同类错误样本来集中训练神经网络在这方面的缺陷。误差分析适合该任务人类擅长时，可以作为指导方向的参考，避免花了大量精力解决了一个可能不是那么重要或者占比不是那么大的出错原因。<br>清除标注错误的数据：有时训练集中的数据标注可能有误，例如把一张明明是狗的图片标注为猫，如果在进行误差分析时认为标注错误的数据占比较大，则可以进行重新标注。但一般而言，随机性的标注错误并不会对高鲁棒性的神经网络造成很大的影响。<br>6.初始化神经网络原则：<br>在开始搭建神经网络时，一般不考虑任何可能会导致误差和干扰的因素，要求快速构建起神经网络并迭代，而后分析其结果，根据结果来决定下一步做什么，解决哪些关键的干扰和误差因素。</p><p>不匹配数据的神经网络：<br>仍以辨别猫的神经网络为例，人们拍出的照片往往模糊而构图不专业，此时若以一些高清而专业的照片作为训练集训练神经网络，会导致训练数据与实际数据的不匹配而难以得到很好的效果。例如有20w个高清照片和1w个人们拍的照片，我们不希望直接对人们拍的照片进行模型训练，因为训练样本太少了；我们也不提倡按之前讲的将不同类型的数据按比例均分到每个集中，因为我们真正希望模型分辨的是人们拍的照片，假设选取2500个开发集数据的话，如此均分则人们拍的照片只有119张，而开发集的目的在于告诉我们模型在真实数据下的表现，显然均分得到的开发集将会花费大量精力处理那些高清图片上，这不是我们想要的。一个合适的选择是，选取20w高清图片和5k张模糊图片组成训练集，再选取各2500张模糊图片组成开发集和测试集，这么做的好处在于开发集中的所有数据均来自于我们真正关心的图片分布，但这么做也会带来一个问题，那就是训练集中大部分数据仍是高清图片，如此训练得到的神经网络在实际模糊图片的输入下可能达不到一个很好的效果。<br>要解决这个问题，我们首先要知道怎么判断不匹配数据的神经网络的效果好坏：<br>我们假设基准误差为0，如果训练集误差为1%，开发集误差为10%，对于一般的神经网络我们可以认为其具有高方差的问题。但对于不匹配数据的神经网络，由于开发集与训练集的数据并非来自同一类别，开发集误差高究竟是因为模型训练的差还是两者数据不匹配程度高是很难有定论的，解决方法是将训练集拆出一部分作为训练-开发集(Training-dev Set)，训练-开发集不参与模型训练，而专门用于检测模型训练的结果。由于训练集和训练-开发集属于同一类型，故训练得到的模型经过训练-开发集的验证可以得到模型训练效果，也就是说训练-开发集承担了一般神经网络中开发集的作用。而训练-开发集与开发集的比较则可以看出数据的不匹配程度。</p><p>于是五者之间的关系如下：基准误差与训练集误差反映了偏差，训练集误差与训练-开发集反映了方差，训练-开发集误差与开发集误差反映了数据的不匹配程度，开发集误差与测试集误差反映了对开发集的过拟合程度。</p><p>如果出现高偏差或高方差的问题，可以参考之前的方法解决；而若发现数据的不匹配程度较高，一个很好的方法是进行人工数据合成，比如语言识别的训练集没有背景音，而实际应用时嘈杂的环境可能存在各种噪声，我们可以为原训练集增加背景噪声作为新训练集来训练神经网络，这被证明可以有效减小数据的不匹配程度，也就是提高了训练集与实际的接近程度。<br>端到端(end-to-end)的深度学习：<br>在了解端到端深度学习之前，我们先来看看一般的神经网络是怎么解决问题的。<br>以语音识别转文字模型为例，一般情况下它需要经过提取低层次特征，寻找音位，发现单词，最终得到文字这几个过程；以人脸识别系统为例，它需要经过提取画面中所有人脸，拿出人脸与数据库中的人脸进行比对的过程。相比于这种多阶段的流水线工程，端到端的强大之处在于它可以输入音频，并经过神经网络直接得到文字。端到端深度学习需要建立在庞大的数据库和神经网络的基础上，只有大量的数据集才能让神经网络尝试完成这种映射，真正的做到了让数据说话，减少了人类思维对神经网络过多的干预。端到端深度学习具有良好的发展前景，但在当下，让神经网络得到人类的干预会是更好的方法。</p><p>卷积神经网络：<br>基于深度学习的计算机视觉得到了巨大发展，可以承担诸如图片分类，目标检测等多种功能。但在应用计算机视觉时，有一个严峻的考验。对于大型高清的图片，它的输入变量规模约可以达到1000<em>1000(尺寸)</em>3(信道)=3m，这是很大的一个输入变量，如果放到一个有1000个神经元的输入层，其参数规模将会达到3m<em>1k=3b，这是不能承受的。而卷积神经网络为我们提供了一个解决办法。<br>相比于密集层可以得到上一层的所有激活作为输入，卷积层的每个神经元只能得到上一层的部分激活作为输入，换句话说，卷积层的每个神经元只能看到上一个网络层的一部分。<br>于是一个卷积层的基本架构包含四部分：上一层的输出（原始输入），过滤器(filter)，过滤后的输入，线性化和激活后的输出。其中过滤器是卷积层的核心，过滤器是一个f</em>f的矩阵，其中各矩阵元素可以给定，但在当下的深度学习框架下这些参数一般就是我们要利用反向传播算法学习的参数，基本原则仍然是代价函数和梯度下降，其地位等同于w和b，显然一个f<em>f的过滤器就有f</em>f个学习参数。它会按序遮罩输入层的各部分，并对原始输入和过滤器相同位置的元素进行标量相乘后相加，将结果放入过滤后输入矩阵的对应位置。值得注意的是，过滤器只有在完全包纳于上层输出时才会过滤元素，否则将会跳转到下一位置，跳转逻辑是从左至右，从上至下。<br>填充(Padding)：由卷积规则，对于n<em>n的输入矩阵和f</em>f的过滤器而言，得到过滤后的输入矩阵规模为(n-f+1)<em>(n-f+1)。这里要引出两个概念，分别是Valid卷积和Same卷积，其中Valid卷积是不经过填充的卷积，由上式可知对于任意f&gt;1的过滤器而言，经过逐层卷积后的矩阵规模必然会越来越小，这有时会导致深层数据的规模过小而不足以训练参数；而Same卷积则经过填充来使输出的过滤结果与输入矩阵规模相同。而填充就是将原始输入扩大几圈的操作，其中填充元素均取0，这么做的好处是能使位于原始输入边缘的元素也能被卷积多次，从而增强边缘元素对模型训练的作用，记填充圈数为p，则填充p圈后再过滤得到的矩阵规模为(n+2p-f+1)</em>(n+2p-f+1)。要做到Same卷积，则填充圈数应满足n+2p-f+1=n，即p=(f-1)/2。<br>为了方便实行Same卷积，以免p不是一个整数，故f通常取奇数；此外，f取奇数还有一个好处是是可以找到过滤器的中心点，方便在程序里表示出过滤器的位置。<br>步长(Stride):步长就是过滤器跳转到下一位置距离当前位置的长度。之前的讲解都是基于步长为1的情况，如果假设原始输入矩阵为n<em>n，过滤器为f</em>f，填充为p，步长为s，则过滤后的输入矩阵规模即为（其中符号⌊⌋为向下取整）：</p><p>以上的讨论均基于二维卷积，实际应用时三维卷积更加常见，即增加了信道的维度。对于三维卷积，则过滤器也是三维的，且过滤器的信道数与原始输入的信道数保持一致，卷积计算的规则仍是过滤器遮罩部分相乘再相加，只不过此时过滤器遮罩的是一个三维立体，用包裹会比遮罩更形象。由此，三维卷积过滤后的输入仍然是一个二维矩阵。如果要使过滤后的输入是一个三维张量，可以对原始输入同时使用多个过滤器，每个过滤器分别负责不同的功能，并将每个过滤器的结果叠起来以形成三维张量，可见对于一个p=0，s=1，输入为n<em>n</em>nc张量，过滤器为f<em>f</em>nc张量的卷积层而言，其过滤结果规模为(n-f+1)<em>(n-f+1)</em>nc。<br>补充：张量，即Tensor。在数学概念中，张量是一个多维数组，它是标量、向量、矩阵的高维拓展，几维数组就是一个几维张量，我们可以将标量视为零阶张量，矢量视为一阶张量，那么矩阵就是二阶张量，一张RGB图片的像素就是三维张量（高度，宽度，信道）。</p><p>于是一个卷积层就可以被描述为：</p><p>以上图为例，输入为一6<em>6</em>3的张量，过滤器为两个3<em>3</em>3的张量，则过滤后的输入为一4<em>4</em>2的张量，为该张量增加总数为nc=2的统一偏差b1，b2得到z，再对计算偏差后的输入z进行激活得到a=g(z)，本例中取g=ReLU，则最后的输出为一4<em>4</em>2的张量作为下一层的输入。该卷积层涉及的学习参数是：第一个过滤器的27个参数w1-w27，第二个过滤器的27个参数w28-w54，偏差b1和b2共计56个参数，相比一般的聚集层减少了很多。<br>最后对卷积层做个总结，如果一个层为卷积层，那么它包含了以下参数：<br>过滤器规模：f[l]        填充圈数：p[l]        步长：s[l]            过滤器数：nc[l]<br>输入张量：nH[l-1]<em>nW[l-1]</em>nC[l-1]                过滤器：f[l]<em>f[l]</em>nc[l-1]<em>nc[l]<br>过滤后输入张量：nH[l]</em>nW[l]<em>nC[l]        偏差：1</em>1<em>1</em>nC[l]        激活：nH[l]<em>nW[l]</em>nC[l]<br>输出张量：nH[l]<em>nW[l]</em>nC[l]<br>其中nH[l-1]和nH[l]，nW[l-1]和nW[l]的关系如下：</p><p>卷积神经网络中除卷积层(Convolution)外，还有池化层(Pool)和全连接层(Fully Connected/FC)。<br>池化层只有超参数f和s（通常取f=2，s=2，如此处理池化层的输出高度和宽度便是输入的一半），没有学习参数，神经网络不从中学习来更新参数；也几乎不进行padding，即p=0。<br>可见对于一个nH<em>nW</em>nC的原始输入而言，其池化层过滤结果为*nC<br>池化层分为最大池化和平均池化两种，最大池化相较于平均池化更加常见。<br>最大池化(Max Pooling)：取过滤器遮罩部分的最大值作为结果得到过滤后的输入。对于多信道原始输入的话，则是对每个信道的遮罩部分均取最大值。最大池化操作的功能在于只要在任何一次过滤内提取到某特征（比如说人脸识别中发现了人眼），它都会被保留在最大池化的输出中，如果没有提取到该特征，那么该次过滤的最大值就会比较小。</p><p>平均池化(Average Pooling)：取过滤器遮罩部分的平均值作为结果得到过滤后的输入。对于多信道原始输入的话，则是对每个信道的遮罩部分均取平均值，</p><p>全连接层：也就是一般的神经网络层，上一层的输入被全部映射到本层的所有神经元。</p><p>常见的卷积神经网络的架构通常同时包含卷积层，池化层和全连接层。单独的卷积层重复叠加是得不到一个很好的卷积神经网络的。根据LeNet-5规定的卷积神经网路架构，卷积层和池化层是共生的，在一个卷积层(CONV)后需要跟进一个池化层(POOL)，由于池化层不存在学习参数，故习惯上把一组卷积层和池化层的组合当做卷积神经网络的一层layer。在前期经历了若干层卷积+池化的组合后，随着卷积神经网络深度的加深，一个常见现象是a[l]的高度和宽度将会逐渐减小，而信道的数量会逐渐增大。在最后阶段，将卷积展开成为一维向量，经过若干层的全连接层（FC，即一般的神经网络层）后进入输出层得到输出。</p><p>该例对应每层的激活规模和学习参数为，可见激活规模正逐渐减小，且全连接层需要的参数数量远远大于卷积层需要的参数数量：</p><p>卷积有两个优势：参数共享和稀疏连接。参数共享表明一个特征检测器可以在输入的任何地方发挥作用，稀疏连接表明每个卷积层的输出均值取决于输入的一部分。</p><p>最后介绍两种特殊的过滤器，垂直边缘检测器与水平边缘检测器，两者分别用于检测图像的水平边缘和垂直边缘，分别定义为：</p><p>利用垂直边缘检测器与水平边缘检测器，我们会得到一个输出矩阵，矩阵各元素偏移零点的程度可以检测图像的水平边缘和垂直边缘，还可以根据值的正负来判断边缘由暗变亮或由亮变暗的趋势。假设输入为灰度图，则有：<br>垂直边缘检测：</p><p>水平边缘检测：</p><p>除了基本的边缘检测器之外，还有其他的边缘检测器：</p><p>当然，现今更流行的仍然是使用神经网络去自己学习边缘检测，这样子得到的边缘检测器不仅可以检测水平或垂直边缘，甚至可以检测各种角度和弧度的边缘。</p><p>对于RGB彩图而言，可以使用三维垂直边缘检测器与水平边缘检测器，即3<em>3</em>3的过滤器张量，每一层可以分别检测RGB某个信道下的垂直边缘与水平边缘，例如下例1检测红色信道边缘，下例2检测RGB各色组合的边缘。</p><p>从之前的讨论中我们可以发现，卷积神经网络中包含了极大量的超参数，这使得在自行构建卷积神经网络时往往无从下手。但好在由于卷积参数共享的优势，在计算机视觉任务中表现良好的神经网络框架往往也适用于其他任务，这使得我们可以参考前人提出的优秀网络架构来训练自己的模型，下面简单介绍几种：</p><p>LeNet-5可以识别图片中的手写数字，它是基于灰度图像训练的，输入为32<em>32</em>1。</p><p>它经过了两层卷积+池化层，两层全连接层。LeNet-5的学习参数大约有60000个。</p><p>AlexNet可以识别图像的基本构造模块，基于RGB彩色图训练，输入为227<em>227</em>3。</p><p>AlexNet的学习参数大约有六千万个。</p><p>VGG-16的功能与AlexNet类似，但它的优势在于其网络架构非常清晰，各超参数之间存在明显关联，而缺点在于其学习参数高达约1.38亿个。</p><p>残差网络(ResNets)：在之前我们讨论过，由于存在梯度消失和梯度爆炸的问题，非常深的神经网络是很难被实现的，而残差网络可以在一定程度上解决这个问题。在介绍残差网络之前，我们先介绍残差块(Residual Block)的概念：</p><p>上图是一个从a[l]到a[l+2]的神经网络，正常情况下a[l]会经历主路径(Main Path)的流程得到a[l+2]，此时我们可以让a[l]通过捷径(Shortcut)或远跳连接(Skip Connection)将信息不经过主路径直接传递到神经网络的更深层。即此时有a[l+2]=g(z[l+2]+a[l])，值得注意的是，远跳连接的介入时刻位于线性激活后ReLU函数前，且由于z[l+2]和a[l]相加的要求，需要z[l+2]和a[l]需要具有相同维度，这在残差网络里是由多个Same卷积实现的。<br>由这些残差块组成的网络就是残差网络：</p><p>残差网络被证明能够有效避免梯度消失与爆炸问题，从而能使人们构建起更深层的神经网络。可以看到，它的构成是多层的Same卷积层穿插少量的池化层，并在最后进行Softmax分类。其能建立更深层神经网络的原因大致在于，前层的输入可以更加容易的进入更深层神经网络，从而可以削弱梯度消失与爆炸的影响。</p><p>1<em>1卷积(1</em>1 Convolution)：<br>即f=1的过滤器，其主要作用是改变信道数量。之前讲到过池化层可以在保持信道不变的基础上改变张量的宽度和高度，而1*1卷积则可以在保持张量的宽度和高度不变的基础上改变信道数量。让我们来看两个例子：</p><p>在上例中，可以看到1<em>1卷积就是对原始输入在对应位置的切片相乘再相加，从而保持张量的宽度和高度不变，而由之前所学，过滤后输入的信道数量就是1</em>1卷积过滤器的个数。在下例中实现了32个1*1卷积过滤器来使原始输入的192个信道缩减为32个。</p><p>Inception网络：鉴于卷积神经网络中大量的超参数难以人工调整，Inception网络提供了一个方法来代替人工确定卷积层中的过滤器大小或是否需要创建卷积层或池化层，也就是让神经网络自己通过学习得到应该选用什么类型的过滤器，或是选择是否应用池化层。Inception网络的选择有四种，分别是应用卷积层1<em>1，应用卷积层3</em>3，应用卷积层5<em>5和应用池化层。以28</em>28<em>192的输入为例，选择应用卷积层1</em>1的规模是28<em>28</em>64，选择应用卷积层3<em>3的规模是28</em>28<em>128（需要进行Same卷积），选择应用卷积层5</em>5的规模是28<em>28</em>32（需要进行Same卷积），选择应用池化层的规模是28<em>28</em>32（需要进行Same池化，这点比较特殊），最后将这些选择全部叠在一起得到28<em>28</em>256的合成张量，让网络自己学习它需要什么样的参数。当然，这么做会碰到的问题是大量的计算成本。<br>例如计算5<em>5的参数时需要进行(28</em>28<em>32)</em>(5<em>5</em>192)=1.32亿次运算</p><p>为了降低计算成本，我们可以先进行一次1*1卷积计算：</p><p>此时计算次数为28<em>28</em>16<em>1</em>1<em>192+28</em>28<em>32</em>5<em>5</em>16=12.4m次，仅为前面的10%。<br>于是Inception网络的每层结构便如下图所示：</p><p>综上所述，在实际应用卷积网络时，我们有很多现成的模版可以套用，这大大较少了我们构建和训练网络的时间。也就是说当我们选定好网络架构后，便可以从github上寻找开源方案，这些网络已经被搭建完毕且经过了预训练，我们便可以使用该网络进行迁移学习。对于极小的训练集而言，可以保持非输出层参数不变而只训练输出层参数；对于稍微大一点的训练集而言，可以训练所有参数，其中非输出层参数的初值为已训练好的神经网络非输出层的参数。当训练集样本数量较少时，可以对图片进行旋转，放缩，扭曲，添加噪声等来对一个示例提出更多具有类似标签的新示例，实现在有限的样本集中添加数据。</p><p>目标定位(Object Location)：之前讲过了图像分类问题，即给出一张图片判断它属于什么类别，其基本思路是将图片喂到训练好的卷积神经网络中，经过卷积+池化层，全连接层和softmax输出层得到类别。</p><p>而目标定位问题是在图片中标记出对象的位置，既适用于单对象又适用于多对象问题。要标记出对象位置，我们需要定位一个矩形（称为边界框bounding box），为此我们补充四个参数bx,by,bh,bw，定义图片左上角坐标为(0,0)，右下角坐标为(1,1)，则bx和by是边界框的中心坐标，bh是边界框的高度，bw是边界框的宽度。<br>我们假设一个模型既要判断图中物体是行人、汽车、摩托车还是背景（三者都不是），又要标记出图中物体的位置，为此输出变量应该包含以下元素：是否存在物体pc，边界框坐标参数bx,by,bh,bw，是否为行人c1、汽车c2、摩托车c3。如果采用平方误差函数作为代价函数，则其函数如下图所示，注意当pc=0时除了pc其他元素的值均无意义，不作为参考。</p><p>特征点检测(Landmark Detection)：以人脸识别为例，相比于标记出人脸的边界框，我们可能更需要若干个标记人眼、鼻子、嘴巴的特征点来确认人脸，如此处理还可以做到判断人的表情等更高级的功能。为此，我们需要准备一个特征点训练集和对应的卷积网络，当输入人脸时输出一个包含各个特征点位置的高维向量。</p><p>目标检测(Object Detection)：<br>我们先介绍基于滑动窗口的目标检测算法(Sliding Windows Detection Algorithm)：<br>所谓的滑动窗口，就是在图片上按固定步长移动的小矩形视窗。我们每次只视察视窗内的物体，判断其中是否含有目标物体。以检测汽车为例，为此，我们先要创建一个标签训练集，其中x是视窗相同大小的图片，y是图片中是否包含汽车来训练一个卷积神经网络。而后，我们对原始图片应用滑动窗口，每滑动到一个地方，就把该窗口输入到训练好的卷积神经网络，判断其中是否含有汽车，如果有，则把此时的窗口作为边界框即可。其中步长和窗口大小可以自由确定。<br>这么做的问题在于计算成本，将原始图片分割成多个部分，再分别输入神经网络。更好的方法是将整张图片直接输入神经网络，而后利用过滤器来卷积出对应的窗口，最后在输出矩阵中反映每部分是否含有汽车。论文OverFeat提除了这种卷积滑动窗口的实现。<br>在此之前，我们先看看OverFeat怎么把全连接层转换成卷积层及其架构规定：</p><p>可以看到，一个n维的FC层可以用n个与上层输入维度相同的过滤器过滤后的结果表示。</p><p>对于任意大小的图片输入，OverFeat都会以这种卷积网络架构进行分析，其实际意义等效于进行大小为14<em>14，步长为2的滑动窗口，而每个滑动窗口的结果都会被保存在输出矩阵的对应位置，例如输出矩阵的第三行第二列的值表示滑动窗口右移两次，下移一次对应窗口是否有汽车。使用卷积来等效滑动窗口使得输入网络只需要一整张图片，大大减少了计算成本。但两者都存在的问题是，由于此时窗口大小是固定的正方形，而实际物体的边界可能是长或高的矩形，这么做可能会导致边界框的不准确，而YOLO算法可以解决这个问题。<br>YOLO算法(You Only Look Once)：<br>YOLO算法将一整张图片均分为19</em>19个小部分，然后对某一个小部分应用图像分类和目标检测算法，每个部分都会输出一个八维向量y，YOLO算法判定一个物体是否在对应部分的方法是查看该物体的中心是否位于该部分内，例如下图中左车位于左中部分，右车位于右中部分，而虽然中间部分含有两车的部分，但由于不存在中心，故认为中间部分pc=0。可见如此处理的网络输出规模为19<em>19</em>8，其局限性在于可能存在一个部分里存在多个物体中心的问题，此时仅凭一个八维输出无法解决，但由于19*19的细分，出现这种情况的概率很低。YOLO的优势在于相比滑动窗口以窗口和步长表示物体的模糊，YOLO的边界框可以具有任意的宽高比和更精确的坐标，且YOLO的均分也是基于卷积实现的，这意味着输入神经网络的仍然是一整张图片而不是某一部分，效率比较高，甚至可以做到实时识别。YOLO对于边界框的坐标规定如下：对于每个部分，认为左上角为(0,0)，右下角为(1,1)，单位长度为均分边。所以bx和by一定是小于1的，而bh和bw则可以大于1（跨部分）。</p><p>交并比(Intersection Over Union/IoU)：算法给出的边界框和实际的边界框之间的交集与并集之比，实际应用目标检测算法时认为当IoU&gt;0.5时，算法给出的边界框与实际的边界框匹配。IoU阈值设置的越高，则算法给出的边界框的匹配程度就越高。<br>非极大值抑制(Non-Max Suppression)：在YOLO算法的实现时，可能存在很多个居于同一物体中心的均分块，它们都有可能判断令pc=1，这时候就可能给出很多个边界框。为了避免这一现象，我们可以先舍去所有pc&lt;=0.6的低概率中心均分块，然后选取pc值最大的中心作为真正的中心，对应的边界框为真正的边界框，并舍去所有与最大可能边界框交并比IoU&gt;=0.5的其他可能边界框，最后重复上一步骤，直到所有的待选中心均分块都被选取或舍去。这么做的好处是它根据pc的最大值确定某个物体最有可能的中心，同时对于不同的物体中心，由于IoU&lt;=0.5，这些可能的物体中心不会被舍去，而是会在之后的循环中被找到。如果要同时判断多个不同类型的物体位置，需要对每个类型的物体判断均使用非极大值抑制。<br>Anchor Boxes：之前提到YOLO算法无法解决一个部分里存在多个物体中心的问题，Anchor Boxes可以解决这个问题，例如下面这个例子，车和人的中心都位于下方这个均分块，此时一个八维向量就无法表示了。需要用更高维的8*n向量，例如用16维向量，其中前八个量用于表示均分块内是否有车及其边界框，后八个量用于表示均分块内是否有人及其边界框。关键就在于怎么区分车和人，这就是Anchor Boxes的作用。Anchor Boxes规定了物体边界的样子，比如车一般是宽而矮的，而人一般是窄而高的。根据YOLO捕捉到物体边界框和规定的Anchor Boxes的交并比来判断捕捉到的物体是车还是人，然后确定向量对应位置的值。Anchor Boxes的选择既可以由人根据需要和训练集的分析预先确定，也可以由神经网络自行学习得到。</p><p>候选区域(Region Proposal)：<br>在常规的目标检测算法中，事实上有很多地方是基本不会检测出物体的，例如下图2中的左下角和右上角，我们可以对图片运行图像分割算法得到图片的色块分布，根据色块的大致形状预测其在对应位置的真实图片里可能存在物体，并同步在对应位置运行分类器来判断是否存在物体，这么做可以减少一些不必要区域的物体判断，且同样可以被卷积神经网络实现。这种算法也被称为R-CNN。</p><p>人脸识别：人脸识别的关键在于比较当前输入的人脸和数据库中的人脸的“相似度”，定义差异函数d(img1,img2)为两张图片的差异程度，显然，比对成功即d(img1,img2)小于等于某个阈值τ，比对失败则d(img1,img2)大于τ。当然，直接拿两张图片给计算机来得到d是很难的，我们可以先把图片输入到训练的卷积网络中，并把某个全连接层作为输出层得到一个图片对应的多维矢量，如果两个图片相似，则它们在同一卷积网络的同一输出层的多维矢量也类似。这个卷积网络被称为Siamese网络架构，输入称为x，映射的多维矢量为f(x)。</p><p>于是两张图片x(i)和x(j)的差异函数便可由两个多维矢量的差异函数表示，而两个多维矢量的差异函数就是两者的欧几里得范数，也就是两矢量对应位置的元素差值的平方和的开方。也就是：‖f(x(i))-f(x(j))‖2。于是如果x(i)和x(j)相似，则‖f(x(i))-f(x(j))‖2小于等于阈值τ；如果x(i)和x(j)不同，则‖f(x(i))-f(x(j))‖2大于阈值τ。</p><p>那么怎么训练能使神经网络实现上述效果呢？反向传播算法仍然可以使用梯度下降及其变体，问题的关键在于使用什么样的损失函数。在此之前，我们先介绍三元组(Triplet)的概念：人脸识别的训练集通常由若干个三元组组成，每个三元组记为(A,P,N)，其中A表示Anchor，是对应人脸的基准图片；P表示Positive，是对应人脸的匹配图片；N表示Negative，是对应人脸的不匹配图片。于是要使神经网络正常工作，差异函数应该满足d(A,P)&lt;=d(A,N)，也就是‖f(A)-f(P)‖2&lt;=‖f(A)-f(P)‖2。当然，为了让AP与AN之间差异函数的值差的足够大，通常会增加一个间隔(Margin)α，即d(A,P)+α&lt;=d(A,N)。</p><p>于是其损失函数可以定义为：L(A,P,N)=max{‖f(A)-f(P)‖2-‖f(A)-f(P)‖2+α,0}<br>如此定义的原因是当d(A,P)+α&lt;=d(A,N)时，认为神经网络正常工作，于是其损失为0；而当d(A,P)+α&gt;d(A,N)时，神经网络不够优秀，需要使用损失限制。<br>而代价函数则是训练集每个三元组的损失函数之和，即：</p><p>人脸识别的训练集通常不会太大，例如1k人只需要约1w张照片即可。但在构建三元组的时候A，P，N的选择通常不会随机，因为这通常会导致正常工作条件d(A,P)+α&lt;=d(A,N)非常容易满足，达不到训练神经网络的效果。于是我们需要选择一些比较由训练难度的APN组成三元组，也就是说选择那些d(A,P)和d(A,N)相差无几的组成三元组，这么做可以训练神经网络参数使d(A,P)变得尽可能小而d(A,N)变得尽可能大。<br>此外，也可以用二分类网络来进行相似度判断：<br>我们同样使用Siamese网络架构，即数据库中的图片和新输入的图片经过同一个网络架构得到输出矢量f(x(i))和f(x(j))，其中数据库图片对应的输出矢量可以进行预处理提前得到。我们通过比对数据库中的图片和新输入的图片对应的输出矢量并传递到Sigmoid单元，根据Sigmoid单元输出结果是0还是1来判断两张图片是否属于同一个人。</p><p>神经风格切换：即两张图片的整合，整合图片G的内容借鉴自内容图C，风格借鉴自风格图S。要判断生成图的结果好坏，可以用下图的代价函数J(G)表示：</p><p>其中J(G)由内容代价函数Jcontent(C,G)和风格代价函数Jstyle(S,G)组成，且有α+β=1。<br>内容代价函数Jcontent(C,G)体现了C和G内容的相似程度，所谓内容，可以直接和前文的“相似度”画等号。其定义仍然是欧几里得范数，其中a<a href="c">l</a>为输入内容图C时神经网络第l层对应的多维向量，a<a href="G">l</a>为输入整合图G时神经网络第l层对应的多维向量。具体地，其定义为：</p><p>风格代价函数Jstyle(S,G)体现了S和G风格的相似程度，风格被定义为同一位置不同信道的多维矢量的相关性。（原文：Define style as correlation between activation across channels）<br>那么相关性是如何决定图片风格的呢？我们可以举个简单的例子看看，假设某个信道可以检测图片中的垂直边缘，另一个信道可以检测图片中橙色的区域，于是这两个信道的相关性决定了这个图片垂直边缘为橙色的可能性，也就是感性理解中的风格。我们可以用两矢量对应元素的乘积来表示相关性。则对于信道数量为nc的输入张量，我们定义nc*nc的风格矩阵Gkk’<a href="S">l</a>为输入风格图S时神经网络第l层对应的信道k和信道k’的相关性，Gkk’<a href="G">l</a>为输入整合图G时神经网络第l层对应的信道k和信道k’的相关性。其具体公式如下：</p><p>对应的代价函数为（其中前面为归一化项）：</p><p>更进一步地，如果想要把每一层的代价函数整合在一起得到一个更加综合风格代价函数，有：</p><p>在得到代价函数后，我们只需对G先随机化后进行梯度下降算法就能学习到不错的结果了。</p><p>卷积的1D和3D推广：其原理和2D大体一致。<br>1D：对于n的输入向量和f的过滤器，假设步长为s，则过滤后的输入结果为floor((n-f)/s+1)</p><p>此外，如果输入有nc个信道，则过滤器也需要有nc个信道。如果有n个过滤器，则过滤后的输入结果规模为floor((n-f)/s+1)*n。心电图和各类信号是典型的1D数据。</p><p>3D：对于n<em>n</em>n的输入张量和f<em>f</em>f的过滤器，假设步长为s，则过滤后的输入结果规模为：<br>(floor((n-f)/s+1),floor((n-f)/s+1),floor((n-f)/s+1))。</p><p>此外，如果输入有nc个信道，则过滤器也需要有nc个信道。如果有n个过滤器，则过滤后的输入结果规模为floor((n-f)/s+1)<em>floor((n-f)/s+1)</em>floor((n-f)/s+1))*n。CT图和视频是典型的3D数据。</p><p>序列模型(Sequence Model)：可以用于训练语音识别，文本处理，机器翻译等问题。序列模型大多为1D模型，即一串时序数据或文本数据。序列模型利用循环神经网络在整个社会的深度学习发展中掀起了极大变革。<br>我们以一串文本数据为例介绍序列数据及循环神经网络的数学符号表示：<br>比如说有以下一段文字数据输入：Harry Potter and Hermione Granger invented a new spell.<br>我们要做的是判断这段文字中可能是人名的单词，即：1 1 0 1 1 0 0 0 0<br>各单词为一个基本输入单元，记为x<t>；判断某单词是否为人名是基本输出单元，记为y<t>。<br>序列x的长度记为Tx，序列y的长度记为Ty，本例中Tx=Ty，但很多时候Tx不等于Ty。<br>如果有多组输入样本，则需要加上样本序号i，即：x(i)<t>，y(i)<t>，Tx(i)，Ty(i)。<br>对于文本这种非数字输入来说，基本思路是要把它先转换成数字输入，为此我们需要引入一张词表(Vocabulary)，其中收录了按序排列的大部分常见单词（推荐选取10000个），这样子就能用单词在词表中的序号代表对应单词了，当然序号作为标量不是很适合，我们可以把它转换成之前学过的独热编码的形式，即x(i)<t>为一个10000维向量，在对应序号的位置的值为1，而其他的值均为0。对于那些不在词表里的单词，可以用<UNK>Unknown统一标识。</p><p>经过上面的讨论我们思考一个问题，为什么序列模型不适用于标准的神经网络？</p><p>可以看到，如果序列数据需要被标准神经网络处理，那么就要构建成上述形式。问题在于，序列数据的输入和输出长度并不是固定的，而且标准神经网络不能做到参数共享，而序列数据作为一种模式相似的学习，很多参数在某个位置的学习是可以反映到其他位置从而加快学习进程的。于是引入循环神经网络的架构：<br>一个标准的多对多单层循环神经网络的架构如下图所示。</p><p>可以看到，循环神经网络最大的特点在于它一层就具有标准神经网络多层的神经元，且每个输入仅占其中的一个标准神经网络层，而每个标准神经网络层都会进行一次输出，同时前一个标准神经网络层的激活和输入会被同时传递到后一个标准神经网络层作为激活。可见某个标准神经网络层的激活a<t>由上层的激活a<t-1>和本层的输入x<t>决定，而某个标准神经网络层的输出y<i>由本层的激活a<t>决定。记a<t-1>影响a<t>的系数为waa，x<t>影响a<t>的系数为wax，影响a<t>的偏移系数为ba；a<t>影响hat{y<t>}的系数为wya，影响hat{y<t>}的偏移系数为by。<br>于是循环神经网络的前向传播关系便可以由下式表述：</p><p>其中激活函数g1通常采用tanh或ReLU，而g2是输出层函数，通常根据输出的要求选择采用二分类的sigmoid或多分类的softmax等。一般规定a<0>=0。<br>在实际应用中，通常将式1的Waa和Wax合并写作矩阵形式，即：<br>a<t>=g1(Wa[a<t-1>;x<t>]+ba)，其中Wa=[Waa,Wax]。假设a是100维列向量，x是10000维列向量，则Waa是100<em>100的矩阵，Wax是100</em>10000的矩阵，ba是100维向量。于是Wa是100*10100的矩阵，[a<t-1>;x<t>]是10100维列向量。<br>学习完了前向传播后，接下来看看循环神经网络的反向传播：<br>循环神经网络的代价函数取决于各输出层对应的损失函数，以判断单词是否为名字的循环神经网络为例，此时的输出显然需要使用二分类的sigmoid函数，故单个输出的损失函数也就是逻辑回归的损失函数，即：</p><p>而最终的代价函数就是每个输出层损失函数之和，也就是：</p><p>由于循环神经网络的反向传播是t从后往前进行的，故也被称为穿越时间的反向传播(Back Propagation Through Time)。</p><p>当然除了上面所说的标准的多对多单层循环神经网络的架构，我们还有一对一单层循环神经网络的架构，一对多单层循环神经网络的架构，多对一单层循环神经网络的架构以及多对多而数量不等的单层循环神经网络的架构，如下图所示：</p><p>比如我们输入一段评价文字，要让网络得到这段文字可能代表的评分，这就是一个多对一的网络，RNN需要在所有输入均接收完毕时才能给出一个输出判断；又或者我们输入一个主题，要让网络输出一段相关的文章，就是一个一对多的网络；又或者机器翻译，我们输入一种语言要求网络翻译成另一种语言，就是一个多对多而数量不等的网络，前半段称为编码层Encoder，后半段称为译码层Decoder。</p><p>语言模型(Language Model)：语言模型的作用是，输入一组文本序列y<1>,y<2>…y<Ty>，然后语言模型会估计该文本序列中各单词出现的可能性P(y<1>,y<2>…y<Ty>)。语言模型常常用于语音转文字和自然语言处理中，比如说我说一句话，模型转文字是如何确定是应该转化成”The apple and pair salad”还是”The apple and pear salad”呢？我们可以调用语言模型发现前者的概率为3.2<em>10-13，而后者的概率为5.7</em>10-10，两者相差近千倍，显然应该选择后者。<br>要想训练这样的语言模型RNN，需要找到对应语言的语料库(Corpus)作为训练集，语料库中包含了大量规范的语言句式，通过学习语料库，可以让语言模型具备理解句式和词汇构成的能力，从而对输入的文本序列进行检验。对于语料库中的句子，仍然是先使用词表和独热编码进行预处理，同时句尾可以用结束符<EOS>标记，如果有需要，也可以把标点加入词表。以这些句子作为训练集训练网络，我们应该怎么做呢？<br>首先我们来看看语言模型RNN是怎么工作的：语言模型RNN的特殊结构是x<t>=y<t-1>，并规定x<1>=0。RNN的每个输出都会利用softmax层预测词典中的任意单词处于句子中t这个位置的可能性，然后将可能性最大的当做hat{y<t>}；从第二层开始，每层的输入x<t>都是上一层实际的单词y<t-1>，也就是在前一个单词为给定的单词时，再让softmax层预测词典中的任意单词处于句子中这个位置的可能性；随着网络的深入，之前所有的输入，也就是前面的所有的单词都会被保留。语言模型RNN每层的工作也就是在给定前面的所有单词时，给出当前位置的单词为词表中的哪个单词的可能性。假设我们输入一段文字”Cats average 15 hours of sleep a day.<EOS>”，第三层的工作也就是得到P(Words in Vocabulary|”Cats average”)的值。而模型的输出也就是P(y<1>,y<2>…y<Ty>)=P(y<1>)<em>P(y<2>|y<1>)</em>…*P(y<Ty>|y<1>…y<Ty-1>)，其中右边的各项均可以从语言模型RNN的各层输出中得到。</p><p>语言模型RNN各层的损失函数即softmax的损失函数：</p><p>对应的代价函数即各层损失函数之和：</p><p>反向传播的训练方法仍然是梯度下降及其变体。<br>当我们训练好一个语言模型后，如果想要检验它的效果，可以使用新序列采样的方法：<br>我们运行一遍训练好的模型，根据模型给出的概率进行采样（比如说模型认为第一个单词为the的概率为90%，为a的概率为10%。那么第一个单词就进行90%为the，10%为a的采样）<br>从第二层开始，每一层都使用上一层的采样结果hat{y<t>}作为输入再进行预测采样（注意不是模型训练过程中的实际结果y<t>），直到采样输出的结果为<EOS>为止就可以得到语句了。<br>除了可以建立基于词汇的RNN模型，还可以建立基于字符的RNN模型。基于字符的RNN模型的词表由大小写字符和各类标点符号组成，其好处是不会存在<UNK>，而缺点在于训练成本高，且序列过长会使得模型难以捕捉句子前后的依赖关系。</p><p>对于较深的循环神经网络，靠后的输出对靠前的输入的捕获能力将会不断减弱，梯度消失的问题仍然会出现。为了让循环神经网络应对这个问题，可以使用GRU单元或LSTM解决，GRU和LSTM可以再循环神经网络中建立起非常深的连接，让我来看看：<br>GRU(Gated Recurrent Unit)门控循环单元：<br>引入几个重要概念：<br>1.记忆单元c<t>(Memory Cell)：提供了记忆能力，当c<t>持续等于某个值时，其对应的特征会被神经网络记忆，比如我们要用语言模型生成一段很长的文本the cat,which…,was full.由于英文语法要求单数cat用was而复数cats用were，我们怎么让网络有能力穿越cat到was这一长段的定语从句呢？这时候就需要记忆单元帮忙，具体地在之后会详细讨论。<br>2.相关门Γr：表示c<t>和c<t-1>的相关性，使用sigmoid函数让其介于[0,1]之间，公式为：</p><p>3.候选值tilde{c<t>}：其公式由c<t-1>递推而来，辅以相关门系数，其公式为：</p><p>由于c<t>和c<t-1>的递推关系与a<t>和a<t-1>的递推关系相同，所以在GRU中，a<t>=c<t><br>4.更新门Γu：表示新旧参数的更新程度，也就是将候选值更新为真实值的程度，使用sigmoid函数让其介于[0,1]之间，公式为：</p><p>5.候选值tilde{c<t>}，记忆单元c<t>和c<t-1>，更新门Γu之间的更新关系满足：</p><p>可见更新门参数Γu越接近1，当前记忆单元c<t>的值由候选值tilde{c<t>}决定；反过来，更新门参数Γu越接近0，当前记忆单元c<t>的值由前一时刻的值c<t-1>决定。<br>综上，GRU单元的前向传播由以下五个公式决定，而其中的W和b均由学习得到：</p><p>于是对于给的例子，GRU要做和学习的就是在发现主语the cat时，让c<t>=1记忆该特征，随后在之后的网络深入中令更新门Γu保持为0，即c<t>=1，该特征被始终记忆，最后在找到谓语时根据记忆的结果输出was，同时记忆结果将可以被遗忘，故可以令Γu=1，即c<t>=0。</p><p>长短期记忆(LSTM)：<br>记忆细胞c<t>的概念仍然不变，相比于GRU由两个门Γr和Γu组成，LSTM由三个门组成：<br>1.更新门Γu：沿用GRU单元的概念<br>2.遗忘门Γf：相比于GRU用1-Γu表示对之前记忆参数的遗忘程度，在LSTM中使用专门的遗忘门参数Γf来表示对之前记忆参数的遗忘程度，即：</p><p>3.输出门Γo：相比于GRU直接令a<t>=c<t>，LSTM中的a<t>和c<t>之间存在比例函数关系，即：</p><p>综上，LSTM的前向传播由以下六个公式决定，而其中的W和b均由学习得到：</p><p>有时，在学习参数Γu，Γf和Γo时，除了a<t-1>和x<t>外还会加入c<t-1>，这样的LSTM变体也被称为窥视孔连接(Peephole Connection)。观察LSTM的网络架构可以看到，浅层的输入c<0>可以比较容易的通过一条直线深入到网络内部，这也是为什么LSTM可以解决梯度消失。</p><p>比较GRU和LSTM，由于GRU只由两个门组成，因此它在架构上更加简单，运行速度也更快；而LSTM则更加强大也更加灵活，在大型RNN中更加喜好LSTM架构。</p><p>双向循环神经网络(Bidirectional RNN/BRNN)：<br>我们仍以判断文字是否为人名的RNN为例，我们看以下两句话：<br>He said:”Teddy bears are on sale.”<br>He said:”Teddy Roosevelt was a great president.”<br>如果使用单向循环神经网络，我们只能依赖之前的单词做出判断，而这两句话的前三个单词完全一致，由此判断Teddy是否为名字显然是不可能的。故我们要使用双向循环神经网络BRNN，使神经网络可以同时依赖前方和后方的单词做出判断。</p><p>一个典型的BRNN结构如上图所示，其中每层的激活都包含由左至右和由右至左两个部分。<br>其中由左至右的激活从a-&gt;<1>开始前向传播到a-&gt;<4>，而由右至左的激活从a&lt;-<4>开始前向传播到a&lt;-<1>。此时激活的递推公式不变，只是存在了两个方向而已。而同一个输出由于存在两个激活，故递推公式修改为：</p><p>利用BRNN，在预测一个输出时，我们既可以参考之前的数据，也可以参考之后的数据。例如求解hat{y<3>}时，过去的数据x<1>和x<2>可以从由左至右的激活通道进入，未来的数据x<4>可以从由右至左的激活通道进入。<br>在实际应用时，往往使用BRNN和LSTM、GRU的综合结构。BRNN的缺点在于它必须事先知道整条输入信息，这使得其在进行实时语音识别等任务时不是很有效。</p><p>深层循环神经网络(Deep RNN)：<br>我们之前学习的RNN都是单层的RNN，可以看到所有的x只经过了一层神经层就得到了y。可见一层RNN在横向上由若干个标准神经网络层组成，而要得到多层的RNN，需要对单层的RNN进行纵向上的延伸。下图就是一个三层的循环神经网络：</p><p>可以看到与单层的RNN相比，所有参数都多了描述层级关系的[l]符号，比如说a[2]<3>表示第二层第三时刻的激活，且上一层的输出成为了下一层的激活，而不是直接作为整个神经网络的输出。同时，每个激活也都改为了由前一层的激活和前一时刻的激活共同影响决定，例如：</p><p>此时要学习的参数也拓展到了不同层级，例如Wa[2]和ba[2]。<br>由于时间尺度较长的原因，深层循环神经网络通常无法做到很深，但可以改进的点在于可以将DRNN的若干个输出单独拉出来作为输入再分别构建一个比较深的标准神经网络，这倒是很常见的。此外，DRNN的各单元也可以结合使用BRNN、LSTM、GRU等构架起一个综合的循环神经网络。</p><p>之前用词表+独热编码表示一个单词的缺点在于，它把每个单词都孤立起来看了，这使得算法对相关词的泛化能力不够强。例如算法已经学会构成语言模型I wanna a glass of orange juice，如果此时让算法学习I wanna a glass of apple juice，可能仍需要花费一定时间。但事实上，由于如果能够关注算法对相关词的泛化能力，这两句话应该能利用同一个模型快速得到。<br>为了表征单词之间的关联性，我们引入词嵌入(Word Embedding)向量作为表示某个单词的新方法：<br>词嵌入向量的每个维度都表示了对应单词的某种特征，例如下图将特征分为了型别、尊贵、年龄和食物等维度，然后得到该单词对应于每个特征维度的相关程度，词嵌入向量就是一个由多维度相关程度组成的多维向量。词嵌入向量的维度远小于独热编码的维度，一般在50-1000之间，记位于词表n位置的独热编码为on，词嵌入向量为en。于是网络判断两单词的相关性就可以参考它们的词嵌入向量，比如Apple和Orange是一对近义词，两者在大部分维度上的值相似；Man和Woman是一对反义词，两者除了性别这一维度相反外。在其他维度上的值相似，然后对相关性高的单词做出类似的学习结果。</p><p>需要注意的是，虽然我们这里用一个直观的类别概念去区分词嵌入向量的不同维度，在实际学习过程中，你无法保证词嵌入向量的各维度有明确的意义，学习算法能做的只有保持相关词之间的词嵌入向量也存在某种相关性。</p><p>我们来看词嵌入模型的一个应用，就是进行类比推理(Analogy Reasoning)：<br>类比推理是人类思维的一个体现，例如我们给出Man对应King，那么Woman对应什么呢？显然Woman对应的是Queen，那么词嵌入模型怎么学习到这个对应关系呢？<br>我们可以看到，利用词嵌入向量，我们可以得到eman-ewoman≈eking-equeen≈[-2,0,0,0]。词嵌入模型就是使用词嵌入向量的相似性学习类比推理的，也就是找到一个单词w，使ew和eking-eman+ewoman的相似程度最高，写作数学表达式就是：</p><p>其中argmax函数返回数据结构取到最大值时的索引，sim函数是一种度量两个向量之间相似性的函数，在这里我们使用余弦相似度。所谓余弦相似度，就是两个向量之间的余弦夹角，可以知道，当两个向量相同时，余弦相似度=1；当两个向量正交时，余弦相似度=0；当两个向量相反时，余弦相似度=-1，这是一个比较好的判断相似度的性质。<br>经过这个表达式，我们发现w=Queen，便完成了一次类比推理。如果在词嵌入向量所在的多维空间里观察man和woman，king和queen之间的向量距离，可以发现两者是近似的。</p><p>那么我们怎么得到词嵌入向量的这些参数呢？一个方法是训练自己的词嵌入矩阵E，为此，我们需要一个极大量的语料库作为训练集。所谓词嵌入矩阵E，是词表中每个单词的词嵌入向量按序横向排列得到的一个矩阵，而我们训练的目标不是某个单词的词嵌入向量，而是整个词嵌入矩阵E的所有参数，假设词表有10000个单词，每个单词的词嵌入向量为300维，那么词嵌入矩阵E的规模就是300<em>10000。从词嵌入矩阵E中得到某单词的词嵌入向量en也很简单，就是用E乘以对应n的独热编码，即en=E</em>on，故得到了E也就得到了所有的en。<br>接下来我们具体看看怎么学习E中的各参数，历史上曾经出现过很多种学习词嵌入的方法：<br>1.建立一个语言模型是学习词嵌入矩阵的一个好方法。首先随机生成一个词嵌入矩阵E，将语料库作为训练集，根据输入单词的独热编码得到各输入的词嵌入向量，然后把这些词嵌入编码组合成一个组合向量输入神经网络，最后在一个softmax输出层输出预测结果。这个模型要学习的模型参数为E，w[1]，b[1]，w[2]和b[2]，把预测结果和语料库的实际结果的差值作为代价函数，由此训练出的神经网络可以得到词嵌入向量与softmax输出的关系。</p><p>这被认为是早期训练词嵌入矩阵比较成功的案例，究其原因在于语料库中存在了大量有关apple juice和orange juice的描述，于是训练好的语言模型对于I want a glass of apple <strong>和I want a glass of orange </strong>都有较大概率预测同一个输出juice，故如果观察包含词嵌入向量的隐藏层，apple和orange对应的词嵌入向量应该也大概率近似才会得到这样的结果。<br>基于这个模型，我们引入几个概念，我们把要预测的目标单词称为Target，把目标单词附近的其他已知单词称为Context。如果你的目的是得到一个语言模型，那么通常选取Context为Target的前k个单词（k是超参数，若如果不限制Context，则使用这个模型的输入长度将会无法确定，就会碰到之前在RNN中所说的问题了）；事实证明，如果你的目的仅仅是学习一个词嵌入矩阵，那么Context可以选取很多其他的模型：<br>1&gt;在Target前后各取k个单词<br>2&gt;取Target前的一个单词<br>3&gt;取Target附近的一个单词，这个方法会在之后重点讲解，被称为Skip-Gram。</p><p>2.Skip-Gram模型(Word2Vec)：<br>抽取Context-Target对来构造一个监督学习问题：我们要做的是从语料库的各个句子中随机选取一个词作为Context，然后随机在Context一定词距以内选择另一个词作为Target构成Context-Target对，将Context-Target对作为模型的训练集。于是监督学习的目标就是给定Context，然后要求网络预测在Context一定词距以内的某个Target值。<br>显然，这并不是一个非常简单的学习问题，因为在Context附近可能存在各种各样的单词，但我们构造这个监督学习问题的目标并不是解决这个监督学习问题本身，而是借助这个问题去得到一个良好的词嵌入模型。<br>Skip-Gram的网络模型非常简单，输入的是Context的词嵌入向量，经过一层softmax输出Target为各单词的可能性。如下图所示：</p><p>此时的softmax单元我们舍弃偏移b，并把w用θ表示，则zt=wt<em>x+bt=θtT</em>ec。<br>于是在输入Context为c时，输出Target为t的概率就是：</p><p>对应的损失函数为：</p><p>如果能得到一个不错的Skip-Gram模型，我们就可以得到一个不错的词嵌入矩阵E了。因为如果输入apple和orange都能得到输出juice，那么两者对应的词嵌入向量也将是类似的。<br>如此处理会碰到的一个问题是计算成本，指数相加是很耗费算力的。故因此，我们通常不会直接采用10000级的softmax函数，而是改为采用分级(Hierarchical)结构，也就是所谓的哈夫曼树，把出现频率更高的单词放在高层，每经过一个节点，将总集进行二分，直到找到目标单词，经过如此处理，低效的softmax就变为了多层的逻辑回归，可以加快程序运行速度。<br>此外，如何随机抽取c也是一个值得探讨的问题，如果按照出现概率进行随机抽取的话，网络可能会大量抽取诸如the，a等高频但无意义多关联的词汇，这会导致网络致力于训练这些不是很有用的词汇，而忽略真正想让网络训练的apple和orange等词汇。</p><p>3.负采样(Negative Sampling)：<br>负采样的每组训练数据由一个正样本和k个负样本组成，对于一组训练数据而言，其Context对应的单词是固定的，而Target则只有一个选取自Context附近文本，而其他都由词表中随机选取，于是数据中的的x是选取的Context和Target，y是两者是否真的能成为Context-Target对，显然选取自Context附近的Target对应的y是1，而随机选取的Target对应的y是0。</p><p>负采样对应的神经网络如下图所示，输入仍然是Context对应的词嵌入向量，而输出则是10000个逻辑单元，其中每个逻辑单元代表输入为Context时对应的输出为Target的概率。</p><p>由于我们每组训练数据只包含一个正样本和k个负样本，故每次反向传播学习参数并不需要更新所有的10000个逻辑单元，而只需要更新这些样本对应单词所代表的k+1个逻辑单元即可。对于小的训练集，一般选取k=5-20；对于大的训练集，一般选取k=2-5。可见每次更新并不会更新大量参数，加快了学习时间。<br>同样在逻辑回归单元我们舍弃偏移b，并把w用θ表示，则zt=wt<em>x+bt=θtT</em>ec。<br>于是在输入Context为c时，Target为t时，两者能组成Context-Target对的概率就是：</p><p>同样的，负采样也会碰到如何在词典中选取负样本的问题，前面提到如果随机选取会出现大量无意义的高频单词，而负采样的发明者提出了以下的经验公式。选取单词wi的概率是wi在语料库中出现的词频f(wi)的3/4方除以所有词表中单词出现词频的3/4方，即：</p><p>负采样将skip-gram中的softmax单元拆解成了若干个逻辑单元，且每次只需要更新其中的几个逻辑单元即可，这样的做法大大减轻了算法的计算成本。</p><p>4.GloVe(Global Vectors For Word Representation)词向量：<br>定义Xij为i出现在Context j附近的次数，这里i的地位就等同于Target，于是i和j可以用t和c代替。通过遍历训练集可以得到Xij的取值，如果将附近定义Context的左右若干个单词，则Xij和Xji的取值大致相等。可见Xij表示i和j之间的关联程度。GloVe也有对应的高频惩罚函数f(Xij)：当Xij=0时，f(Xij)=0；当Xij过于高频时，限制其权重；当Xij比较低频时，提高其权重。于是其代价函数为：</p><p>其中θiT为i的权重向量，ej为j的词嵌入向量，bi和bj分别为i和j的偏移向量，这些就是神经网络的学习参数。GloVe的目标就是，学习θi，ej，bi和bj使得线性函数θiTej+bi-bj与Xij的差距尽可能小，一旦实现了这个目标的话，由于apple juice和orange juice出现的概率差不多，故j=apple或orange，i取juice时的Xij值是相似的，故此时eapple和ejuice的值也应当是相似的。此外，相比于Skip-Gram和负采样来说，GloVe下的θi和ej的地位是相等的，因为i可以变成j，j也可以变成i。所以每个单词w最终的词嵌入向量可以取θw和ew的平均值。<br>可以看到，GloVe方法的函数非常简单，且效果不错。</p><p>说了那么多学习词嵌入矩阵E的方法，可能你会觉得非常难。但幸运的是，网络上已经有人上传了已经经过预训练的大量单词的词嵌入向量。我们也可以直接下载这些模型进行迁移学习，将这些词嵌入向量用在自己的小规模数据集中的每个单词上即可。</p><p>seq2seq模型：<br>seq2seq（序列到序列）模型是机器翻译和语音识别过程中的基础模型，实际上seq2seq模型就是一个多对多而数量不等的单层循环神经网络架构的变体。</p><p>它包含了绿色部分的编码网络和紫色部分的译码网络，编码网络将输入向量训练并整合成一组综合向量输入进译码网络，然后译码网络对这个综合向量进行处理得到最终输出。seq2seq模型的特点是译码网络的每个输出hat{y}会作为RNN的下一层输入，这点与语言模型相似，语言模型是随机输出一组语句的概率，而可以把seq2seq模型看作是条件语言模型，即根据限定的输入条件输出一组语句的概率，即P(y<1>,y<2>…y<Ty>)和P(y<1>,y<2>…y<Ty>|x<1>,x<2>…x<Tx>)的区别。比如说机器翻译在输入法语语句时输出英语语句，语音识别在输入语音时输出文字，都是存在条件而不是随机输出的。如果对seq2seq模型的结果进行随机采样，得到的结果可能不是最优的，而机器翻译和语音识别的输出结果总是希望是最优的，所以我们需要构建一个算法找出在特定输入x的时候，概率最大也即效果最优的输出y。即：</p><p>而P(y<1>,y<2>…y<Ty>|x<1>,x<2>…x<Tx>)=P(y<1>|x)<em>P(y<2>|x,y<1>)</em>…*P(y<Ty>|x,y<1>,…,y<Ty-1>)。<br>所以上式也可以写作：</p><p>要实现这个效果，我们通常使用集束搜索(Beam Search)。集束搜索是一种近似搜索算法，以机器翻译和规模为10000的词表为例，假设我们要得到一个长度为10的翻译结果，如果要搜索出概率最高即效果最优的结果，需要比较1000010次，这个计算成本是不能接受的。集束搜索的思路是，对译码网络的每层输出概率进行排序，即对P(y<n>|x,y<1>,…,y<n-1>)进行排序（n为层数），挑选出其中前k个作为本层最有可能的k个输出，这个k被称为束宽。而后，将这k个结果记录作为下层的输入，再挑选出在上一层结果为这k个时的最有可能的k个输出，再以此类推直到输出结束符，最终输出最后k个输出中概率最高的那个。可见第一层需要在10000个词中挑选k个，从第二层起每层需要在k*10000种组合中挑选k个，最后在k个最终结果中挑选1个。当束宽等于1时，集束搜索等效于贪心搜索，即每层只挑选概率最高的进行输出，这被认为不利于输出整体最优的语句。如果选择束宽B较长，则算法可以考虑更多的可能；如果选择束宽B较窄，则算法具有更低的计算成本。<br>值得注意的是，由于集束搜索是一种近似搜索算法，因此它只能输出相对较优的结果而不保证一定是全局最优，但是低廉的时间成本和足够优秀的输出结果使它脱颖而出。<br>进一步优化目标函数，将概率的乘积转换为对数的相加：</p><p>如此处理可以避免一堆小于1的数相乘导致数据下溢失去精度。但它还存在的一个问题是，这个目标函数可能不自然地倾向于简短的翻译结果，因为短句子的概率是由更少数量的小于1的数字乘积或小于0的对数求和得到的，这样的结果通常比长句子要大。<br>为此，可以在对数目标函数前加一个简短惩罚(Brevity Penalty/BP)，其中α是取值为0-1之间的柔和因子，α越趋近于0，简短惩罚就越没有效果。简短惩罚使短句承受了更低的结果。</p><p>接下来我们看看seq2seq模型的误差分析：<br>seq2seq模型的误差可能同时来源于编译码网络RNN和集束搜索算法，首先编译码网络RNN可能会训练的不够好以至于无法输出不错的结果，而集束搜索算法作为一种近似搜索算法，可能会因为束宽长度的选择无法搜索到比较好的输出。要想区分seq2seq模型的误差究竟是来源于RNN还是集束搜索算法，可以采取以下方法：</p><p>我们还是以机器翻译为例，我们让人和seq2seq模型同时翻译一个语句，记人翻译的结果为y<em>，模型翻译的结果为hat{y}，显然人翻译的是比较精确的，且模型相比于人翻译的不够好。于是进行误差分析，我们可以直接将y</em>和hat{y}喂给RNN模型，让模型判断P(y<em>|x)和P(hat{y}|x)的好坏。如果P(y</em>|x)&gt;P(hat{y}|x)，则RNN模型本身没有问题，因为人翻译的结果确实比模型好，那就可能是集束搜索算法没有找到这个比较好的结果，于是要从集束搜索算法的优化入手；反过来，如果P(y<em>|x)&lt;=P(hat{y}|x)，则RNN模型本身就有问题，因为它埋没了一个本应比较好的翻译。于是，当模型出现问题时，我们可以人为列出几句话对应的翻译，并让模型也翻译一遍，根据P(y</em>|x)和P(hat{y}|x)的大小关系判断是RNN的问题还是集束搜索算法的问题，列出表格看看两者谁占主要方面，并着重解决这一主要问题。</p><p>Bleu(Bilingual Evaluation Understudy 双语评估替补)得分：<br>Bleu得分是seq2seq模型中一个比较不错的单一实数评估指标，可以用于评估seq2seq模型的结果。仍以机器翻译模型为例，我们会遇到的一个问题是，由于翻译结果可能同时存在多个正确答案，我们如何从这么多答案中评估模型的结果呢？我们假设机器翻译给出了两个参考结果，这两个参考结果都足够优秀。</p><p>当模型的翻译结果hat{y}输出后，我们把整个句子拆分为若干个n个连续的词组，每个词组称为n-grams，则定义pn如下，其中Count是整句n-gram的数量，Countclip是整句n-gram与参考结果中的某个n-gram相同的数量，但每个Countclip(n-gram)不能超过单个参考例句中n-gram的最大值。</p><p>例如输出为The cat the cat on the mat，则分母为6，分子为4，p2=2/3，计算过程如下：</p><p>Bleu得分中也存在简短惩罚，如果模型MT输出的长度大于参考输出长度，那么就不进行简短惩罚，否则就要进行指数级的简短惩罚。</p><p>Bleu得分的公式为：Bleu Score=BP<em>exp(1/n</em>∑pi)，一般取n=4，即exp内计算p1-p4的均值。</p><p>注意力(Attention)模型：在翻译一个长句时，我们不希望神经网络去具备记忆一个长句子的能力，而是希望它更像人类一样，一次去翻译一个句子的一部分。这就是所谓的注意力，即在翻译某一个词语时，让神经网络只注意到句子的一部分，对应的模型就是注意力模型。<br>注意力模型在一般双向RNN的基础上，将多个输出hat{y}经过注意力参数整合为一个上下文变量c再次输入一个新的RNN中，新的RNN中每层会接收上个输出的词和经过注意力参数整合的语句向量作为输入，输出在新位置上的词。将新RNN中的激活命名为s<t>以示区分，于是注意力模型就可以表示为：</p><p>为了表示神经网络在翻译某个词语时对句中其他词语的重视程度（注意力），我们引入注意力参数α<t,t’>，代表在翻译词语t时对句中词语t’的注意力。为了让α<t,t’>之和为1，我们使用softmax模型的公式：</p><p>其中e<t,t’>可以看作是原始注意力参数，而经过softmax得到归一化后的注意力参数α<t,t’>。<br>那么怎么得到e<t,t’>呢？直观地想，作为注意力参数，e<t,t’>应该与前一个输出单词和各输入单词有关，而其对应的参数可以是上层输出激活s<t-1>和各输入激活a<t’>。现在的问题是，我们不知道e<t,t’>和s<t-1>，a<t’>之间究竟存在怎样的函数关系，于是我们可以训练一个小的神经网络，专门用来得到e<t,t’>和s<t-1>，a<t’>之间的函数关系。得到了e<t,t’>后，我们也就得到了α<t,t’>，那么c和各输入激活a<t’>的关系就可以表示为：c<t>=∑α<t,t’>*a<t’>。<br>然后训练整个注意力模型即可。</p><p>语音识别：当下语音识别的一个有效模型就是注意力模型，通过输入一段音频来转换为文字，由于音频的输入量（取样总数）往往远大于文字的输出量，所以注意力模型显得尤为重要。<br>假设输入一段10s，100Hz的采样音频以得到文字”The quick brown fox”，则注意力模型为：</p><p>还有一种常见的训练方法是CTC(Connectionist Temporal Classification)损失函数，CTC损失函数对应的训练网络是一个输入和输出数目相等的双向LSTM循环神经网络架构（这里简单用单向RNN表示）。与注意力模型不同，CTC损失函数将每个采样的输入都得到一个输出字母，这意味着有很多字母都会重复，也会有部分采样不存在字母（定义这种情况输出为空blank，不要和空格space混淆），最后得到1000个输出，对于这个输出，将空白符blank之间重复的字符折叠起来作为一个输出，同时不输出blank，以此类推得到最终输出。</p><p>触发字检测：可以训练一个RNN，当某人说完触发字之后，就把输出拉高为1一段时间，而其他时候输出始终为零，以此训练一个触发字检测系统。</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习</title>
      <link href="/2022/08/09/MachineLearning/"/>
      <url>/2022/08/09/MachineLearning/</url>
      
        <content type="html"><![CDATA[<p>机器学习的两种主要类型是监督学习和无监督学习<br>监督学习给出了一组训练集，给定了样本输入和其对应的输出，机器在学习后得出一个函数，使之在之后给定任意输入时，都能自主预测一个合理的输出值。<br>监督学习的目的有两种：回归与分类。回归是预测给定输入对应的输出值，它是连续的、无限的，例如给定房屋面积预测房屋价格；分类是预测给定输入对应的种类，它是离散的、有限的，例如给定肿瘤大小预测肿瘤是否为良性。当然，监督学习也可能是多输入多输出系统。</p><p>线性回归：<br>一个最佳的拟合函数fw,b(x)，其对应的代价函数J(w,b)应当是(预测的结果-真实的结果)^2的均值的最小值，这说明拟合的效果足够好，足够接近真实值了。其中预测的结果-真实的结果代表了误差，平方是为了得到绝对正的误差累计，系数1/2是为了使得func不会随着训练样本的增大而急剧增大，同时方便后面梯度下降求导时把2约去使式子看起来更简洁。<br>这个形式的代价函数也被称为平方误差成本函数(square error cost function)。平方误差成本函数的特点是：它只存在一个局部最小值，且该局部最小值就是全局最小值。</p><p>以一个满足y=x的样本集为例，同时固定b=0。我们发现w的值对J(w)的影响如下图。</p><p>我们的目标就是得到一个w，使J(w)的值最小，在本例中即w=1。</p><p>综上，线性回归的基本内容就是：确定模型，根据代价函数得到最小值。</p><p>如果把b考虑进来，那么代价函数J(w,b)的图像应该就是一个二元函数在三维视图的图像：</p><p>同理，这个二元函数也会有一个最小值，我们的目标仍然是求解这个最小值时对应的w和b。<br>更进一步的，如果x是一个多变量的矩阵，那么此时的w也就是一个矩阵[w1,w2…wn]。<br>则此时的J(w,b)就可以写成J(w1,w2…wn,b)，对应的图像也会向更高的维度拓展。<br>接下来我们的目标就是，如何借助算法找到这个最小值，这个算法就是著名的梯度下降法。<br>梯度下降法的适用目标不仅仅在线性回归中，它可以用来尝试最小化任何函数。<br>梯度下降法的步骤如下：</p><p>梯度下降法的目的在于尝试找到任意函数的最小值。它的基本思路是，站在某点环视四方，找到该点下降率最大的方向（即梯度方向）前进一小步，再多次重复上一步骤，如此便有可能找到一个极小值。因此，我们需要开始时为梯度下降法确定一个起点w0,b0（可以任意确定，但可能影响结果），然后让w,b沿各自的梯度方向下降从而降低J(w,b)的值，如此循环直到我们找到或接近一个极小值。为什么要说是极小值而非最小值呢？因为这是梯度下降法的一个特性，当一个函数J(w,b)存在多个极小值时，梯度下降法往往会陷入其中一个极小值，而这个极小值不能被确保是最小值，具体陷入哪个极小值由往往起点和学习率决定。</p><p>梯度下降法的梯度更新过程如下所示：<br>分别对当前的J(w,b)求关于w和关于b的偏导，然后用偏导值乘以一个系数α后作为减数减小当前的w和b，这个系数α也被称为学习率，它的取值是[0,1]。它反映了梯度下降的速率，即梯度对w和b更新的影响程度。而后借助下述公式更新w和b，注意：w和b需要同步更新，即先求出更新后的w，b值再统一赋值给原来的w，b，这意味着在计算更新的w，b值时用的永远都是原来的w，b。下面给出了关于同步更新的正确与错误两种形式。</p><p>为什么这个公式能帮助我们找到局部最小值呢？我们来看下面只有w的例子：</p><p>可以看到，不论是位于局部最小值的哪端，梯度下降法总能帮助我们逼近局部最小值。</p><p>学习率α对梯度下降有很大影响，当α取值过小时，会导致梯度下降过程缓慢；当α取值过大时，梯度下降可能过冲，永远无法到达最小值，甚至可能无法收敛导致发散。</p><p>对于线性回归和平方误差成本函数而言，其偏导可以写作如下形式：</p><p>其推导过程如下所示：</p><p>事实上，对于任意凸函数J(w1,w2…wn,b)而言，其局部最优解是全局最优解，因而梯度下降法很适合求解凸函数的全局最小值问题。<br>补充一下关于如何判断一个函数是凸函数(convex function)：<br>　对于一元函数f(x)，可以通过其二阶导数f′′(x)的符号来判断。如果函数的二阶导数总是非负，即f′′(x)≥0，则f(x)是凸函数。我们可以从几何上直观地理解一元凸函数的特点，如下图所示：即凸函数的割线在函数曲线的上方。</p><p>　对于多元函数f(X)，可以通过其Hessian矩阵（Hessian矩阵是由多元函数的二阶导数组成的方阵）的正定性来判断。如果Hessian矩阵是半正定矩阵，则是f(X)凸函数。<br>对于非凸函数而言，梯度下降法可能会陷入其中某个极小值而非全局最小值，以下图为例：当函数进入局部最小值时，此时梯度为0，w和b将不再更新。</p><p>此外，梯度下降还分为批量梯度下降(batch gradient descent)和部分/小批量梯度下降(Mini-Batch)，批量梯度下降的每一步使用所有的训练集数据，而部分梯度下降的每一步只使用部分的训练集数据（通常是顺序选取一组完全不同的部分）。批量梯度下降寻找w,b的过程会比较准确，但当样本集m过大时求和过程会非常慢，导致批量梯度下降的时间成本很高；而部分梯度下降由于只采用部分数据，因此它的每一步在接近全局最小值时可能不够可靠甚至有些嘈杂，有时甚至会背离最小值移动，但它整体仍沿着趋向全局最小值的方向运动，部分梯度下降的优势在于当训练集m很大时，它仍然能以较快的速度完成每一步迭代（例如m=1亿而我每次只取m’=1000）</p><p>我们之前谈论的x只有一个，这也被称为单元线性回归；现在我们把它拓展为多元线性回归，直观上来看，就是一个结果取决于多个变量输入，而w则是各变量对于结果的权重。<br>仍以房屋价格为例，此时的模型可以写作：</p><p>我们可以发现，此时的w和x均为一个由各变量组成的向量：</p><p>于是我们就可以得到用向量表示的线性回归普遍公式：</p><p>对于多变量的表达式而言，我们通常对其进行矢量化(vectorization)：在python中我们利用numpy下的函数np.array和np.dot对其进行矢量化及运算，这不仅使得整个代码看起来更简洁，且由于numpy对于硬件的并行调用，整个代码的运行速度也会得到提升。</p><p>以一个不含b的多元线性回归J(w)为例，其中d表示w的偏导，学习率α取0.1：</p><p>我们可以发现，有没有进行矢量化的代码风格与效率之间相去甚远。<br>利用矢量化，则多元线性回归的表达式就可以改写为：</p><p>同理，我们把偏导公式在线性回归的转化加进来，记住对于wi的求解就是求出J对于各个wi的偏导，故各偏导的差别即为末尾对应的xi的差别：</p><p>事实上，解决线性回归还有一个方法被称为正规方程法(Normal Equation)，他可以不通过迭代就可以直接算出w和b的值，但它对于除线性回归以外的问题而言没有推广性，且当w的规模很大时计算会非常慢，因而正规方程法往往只会出现在机器学习库中用于实现线性回归，梯度下降法仍是寻找代价函数J最小值和对应的w和b的推荐算法。</p><p>接下来介绍一些小技巧，这可以帮助你更快更好的完成梯度下降过程：<br>1.特征缩放Feature Scaling：<br>重组规模RESCALE：当你有不同的变量x时，如果这些变量的取值范围相去甚远时，可能会导致梯度下降运行缓慢。首先我们要了解一个常识，当某个变量xi的取值都很大时，其对应的权重wi一般都会偏小，这会导致梯度下降过程中较难逼近这个wi，可能会反复横跳。<br>例如下面这个例子：假设房屋的面积x1通常取值在300-2000，而房屋卧室的数量x2通常取值在0-5，这就会导致w1非常小，难以完成梯度逼近。</p><p>解决方法也有很多，首先介绍的就是标准化方法，它将各变量的值除以它们的最大值从而得到一组取值范围均在[0,1]之间的变量向量，对应的RESCALE图如下所示，可以看到此时的梯度下降效果较好</p><p>其次要介绍的是mean normalization均值归一化，它先得到各变量xi的均值μi，而后对每个xi减去均值μi后除以他们最大值与最小值之差，得到的结果就是均值归一化的结果，这个值位于[-1,1]之间</p><p>最后要介绍的是Z-score标准化，它先得到各变量xi的均值μi和标准差σi，而后对每个xi减去均值μi后除以σi，得到的结果就是一个均值为0，方差为1的标准分布，也会比较小且均匀。</p><p>下面给出了一些适合与无需特征缩放的变量取值：</p><p>2.观察梯度下降过程是否收敛（梯度下降是否在帮你找到J的最小值）：<br>也介绍两种方法，一种被称为学习曲线J-k，它的纵轴是成本函数J的值，横轴是迭代次数k，如果我们发现随着k的增大，J不断减小且趋于平稳，则认为梯度下降过程收敛。</p><p>另一种方法是自动收敛测试，设定一个小量ε（比如0.001，实际上可以任意设置），当单次迭代J的变化小于这个小量时，认为梯度下降趋于收敛，但它的缺点在于如何选取ε以及结果不够直观，因而更加推荐使用学习曲线法。<br>当我们发现学习曲线随着迭代次数呈现往复摆动甚至快速上升的情况，这很有可能是学习率α过大导致的，此时我们应该减小学习率。</p><p>至于如何选择一个合适的学习率，可以采取以下方法：先取一个比较小的学习率，此时J的下降会非常缓慢；再取一个比较大的学习率，此时J会随着迭代往复摆动。则一个合适的学习率便介于[small,big]之间，且通常从big侧往小取可以得到一个不错的效果。</p><p>之前讲的都是线性回归，现实生活中的很多情况变量之间可能并不满足线性特征，这会导致使用线性回归无法得到一个好的效果，例如下面这组训练集：</p><p>这时候就要引入多项式回归(Polynomial regression)了，但在此之前，我们先来介绍一下特征工程(Feature Engineering)的概念，特征工程是将原特征变量进行数学变化或组合得到新特征变量的过程，特征工程的目的在于使特征方程更加符合数据集的拟合要求，而所谓的多项式回归，实际上是特征工程的一个特例，当线性回归fw,b(x)=wx+b效果不好时，我们通过对原变量x进行平方，立方，开放等特征工程操作，尽量使新方程更加符合数据集的拟合要求，而这种线性回归的特征工程结果就是多项式回归，典型结果如下：</p><p>值得注意的是，当使用多项式回归或特征工程产生次方项时，特征缩放就显得尤为重要了，因为假设原变量的取值为1-103，那么它的立方取值就要1-109了，这是不能被接受的。</p><p>逻辑回归：虽然它有回归regression二字，但它实际上用于解决分类classification问题，且专用于解决二元分类，所谓二元分类，即分类的结果只有两种，通常定义为0和1。对于二元分类，线性回归不是一个好的方法，我们介绍逻辑回归：<br>仍以肿瘤是否为阳性举例，我们期望的回归函数应当类似于下图：</p><p>如何利用这个连续的回归函数判断离散的结果呢？思路也很直白，就是当对应x的回归函数结果<0.5时返回0，>0.5时则返回1。这种类型的回归函数有一个名字被称为Sigmoid函数，它的函数表达式为：g(z)=1/(1+e^-z)，它的函数图像如下图所示：</p><p>可以看到，Sigmoid函数的一个重要特点在于不论z的取值如何，其结果总约束在[0,1]之间，<br>利用这个特点，我们可以把原先线性规划中的函数f(x)=[w][x]+b作为z代入到g(z)中，从而将一个无限变化的值限制在[0,1]之间，再利用四舍五入得到二元结果。需要指出的是，逻辑回归在四舍五入前的输出代表的意义就是二元结果取1的概率，而正是因此我们选择0.5作为结果变化的区分点。我们也把这个输出写作概率的形式：</p><p>由于这个预测结果仍是一个猜测值，故仍表示为hat{y}。<br>以Sigmoid函数作逻辑回归为例，当z=0时g(z)=0.5，而z=[w][x]+b，因而区分结果取0还是取1的关键就是[w][x]+b是小于零还是大于零。</p><p>由此我们引入决策边界(Decision boundary)的概念，所谓决策边界，就是g(z)=0.5，也就是Sigmoid函数下z=0时的各变量可能取值形成的边界线，整体的样本集被决策边界大致的一分为二，且可以认为在决策边界附近时，结果的取值是最不可信的而摇摆的。以线性回归的函数z为例，此时z=w1x1+w2x2+b=x1+x2-3，则决策边界为如下的一条直线，它将y=0和y=1明显的区分成了两部分。</p><p>当然，线性回归的直线边界有时候无法取得很好的效果，我们仍可以借助特征工程的理论来得到其他边界形式。对于多项式回归和非线性回归而言，决策边界也会变为曲线的形式。如下例中z=w1x1^2+w2x2^2+b=x1^2+x2^2-1，则决策边界为一个以原点为圆心，1为半径的圆。</p><p>同理，对于更复杂的多项式和非线性式，决策边界也会变得复杂，从而适配更加复杂的逻辑回归问题。</p><p>接下来梳理一下逻辑回归要实现的目标，作为监督学习中分类的一种，同样在给定一系列变量x和其对应的离散二元结果y作为训练集后，我们要确定w和b取何值时代价函数J最小。<br>借助Sigmoid函数定义的逻辑回归方程是：</p><p>这个方程的意义就像线性回归中的fw,b(x)=wx+b，是逻辑回归得到的用于拟合数据的曲线，只不过其结果还要与0.5做比较来得到最终结果究竟是取0还是取1。<br>同理，逻辑回归也会有它相应的成本函数，可以发现平方误差函数不适合在逻辑回归中承担成本函数的责任，因为它在逻辑回归中非凸，会出现很多局部最小值，不利于梯度下降算法。<br>逻辑回归的代价函数如下，它是由最大似然估计法(Maximum Likelihood)证明的，其中L(f,y)是单个样本的损失函数(Loss Function)：<br>注意：这里的log是数学意义上的ln。</p><p>我们来分析一下这个函数，首先看看单个样本损失L的定义。它在坐标图L-f下的形状如下图所示，由于f的取值范围在[0,1]之间，所以只取[0,1]部分绘制：</p><pre><code>          if y=1                              if y=0</code></pre><p>可以看到，当样本结果为1时，函数fw,b(x)越接近于1损失L就越小；同理当样本结果为0时，函数fw,b(x)越接近于0损失L就越小。由于fw,b(x)即预测结果的函数，如果预测的结果越接近于实际的样本结果，那么其损失自然就越小，将所有的损失L取均值得到代价J，那么J的最小值就是样本集的各样本损失L总和的最小值，损失总和越小代表着总体的预测结果越接近于总体的真实结果，通过这种方法调整w和b使J趋向于最小值，从而得到一条最佳的预测曲线fw,b(x)。<br>由于y只能取0或1两个值，我们可以利用变换将L从条件式变为复合式如下：</p><p>则代价函数便可以写作：</p><p>数学上可以证明，这个代价函数J仍然是一个凸函数。要得到这个代价函数的最小值，方法仍然是梯度下降法：</p><p>偏导值的详细推导如下：</p><p>我们有一个发现，逻辑回归的梯度下降公式竟然与线性回归一模一样！这意味着在计算梯度下降时，可以使用同一套公式和代码进行迭代求解。<br>在进行逻辑回归的时候，观察学习曲线判断梯度下降收敛、向量化、特征缩放等方法仍然是通用的，可以借鉴线性回归的相关理论。</p><p>以上便是线性回归和逻辑回归的大致内容了。回顾一下，线性回归用于解决回归问题，而逻辑回归用于解决分类问题，二者同属于监督学习的范畴，那么两者也会出现很多类似的问题。<br>一个问题就是预测曲线的欠拟合(underfit，也被称为高偏差high bias)和过拟合(overfit，也被成为高方差high variance)问题：所谓欠拟合，一般是特征变量的个数或维数过低，导致特征方程（拟合曲线或是决策边界）为一条直线，难以拟合一些复杂的非线性变化；所谓过拟合，一般是特征变量的个数或维数过高，导致特征方程极力的想去完美适配样本集的所有样本，此时虽然对于样本集内的数据特征方程适配的很好，但当它预测新的例子时就变得很难推广。因此，一个合理的拟合应该既不错的适配样本集的数据，当新的例子引入时，又要能够很好的预测该例子对应的输出结果。</p><p>解决过拟合通常有以下几种方法：获取更多的样本数据，减少特征变量的个数或阶数（这也被称为特征选择Feature Selection），还有一种比较好的方法称为正则化(Regularization)，对于一个高阶的特征方程产生的过拟合而言，通常是由于高次项占比过大导致的，减少特征变量的个数或阶数事实上就是将原特征方程的高次项系数置0了，事实上，我们可以将这个过程变得更温和一点，即通过减小高次项的系数，在保留高次项作用的同时又让高次项不会过分影响特征方程的形状产生过拟合，这项技术就被称为正则化。正则化实际上就是改变系数权重w1-wn的过程，而b是否要发生改变则无关紧要，故多数情况下不选择改变。<br>下图是采用正则化后线性回归拟合效果的改变，可以看到过拟合现象得到了很好的缓解：</p><p>正则化作为一个通用方法，也可以作用于解决欠拟合问题，增加特征变量的个数和阶数的过程可以看做是正则化增加高次项系数的结果。在之前的讨论中我们知道了，如果要防止出现欠拟合和过拟合的现象，对于高次项的系数设置应该不能过小(0)也不能过大(1000)，而对于给定特征变量个数与阶数的特征方程而言，系数的设置不会过小而只会过大，且对于复杂的特征方程，难以找到影响拟合结果的重要特征，因此，实现正则化时，我们通常考虑整体缩减（也叫惩罚）所有的权重wj，这通常会使曲线变得更加平滑而不易过度拟合。<br>那么如何用数学语言描述正则化方法的这个惩罚过程呢？其实也很简单，那就是在代价函数J中加一项惩罚项即可，惩罚项由各权重wj的平方和乘以系数组成，有了惩罚</p><p>项，J在梯度下降过程中如果尝试增大w来降低J，那么就会受到惩罚项惩罚使J增大，从而限制算法在使J下降时不要过度增加w。其中λ是惩罚系数，它和学习率α一样由人为设置，决定了代价函数对正则化的重视程度，λ越大，代价函数就越重视正则化。<br>于是，正则化线性回归问题的代价函数就是下式：其中m是样本数量，n是特征变量数量</p><p>而要找到这个代价函数的最小值，其方法仍然是梯度下降，且公式基本不变，只是在求解w的偏导时，需要额外对惩罚项求偏导，因而其迭代公式如下：</p><p>同理，我们也可以得到逻辑回归问题的代价函数：</p><p>而由于线性回归和逻辑回归的代价函数梯度下降算法一样，因而正则化后的线性回归和逻辑回归的代价函数梯度下降算法也是一样的，请参考正则化线性回归的梯度下降公式。</p><p>接下来要讲的就是机器学习中最重要的知识——神经网络（也叫多层感知器）了：<br>神经网络最初是一个生物学的概念，一般是指大脑神经元、触点、细胞等组成的网络，用于产生意识，帮助生物思考和行动，后来人工智能受神经网络的启发，发展出了人工神经网络。<br>人工神经网络（Artificial Neural Networks，简写为ANNs）是一种模仿动物神经网络行为特征进行分布式并行信息处理的算法数学模型。这种网络依靠系统的复杂程度，通过调整内部大量节点之间相互连接的关系，从而达到处理信息的目的。神经网络的分支和演进算法很多种，从著名的卷积神经网络CNN，循环神经网络RNN，再到对抗神经网络GAN等等。<br>无论是在学习机器学习还是深度学习时，我们都会频繁接触神经网络这个词，人工智能、机器学习、深度学习、神经网络这几个概念之间的关系图如下图所示。</p><p>随着要处理数据和变量的增大，传统的人工智能学习算法（线性回归和逻辑回归）的表现将远远弱于神经网络，而在当前这个大数据时代且随着GPU的发展，神经网络正大展宏图。</p><p>神经网络模型建立在很多神经元之上，每一个神经元又是一个个学习模型。这些神经元（也叫激活单元，activation unit）采纳多个特征作为输入，并且根据本身的模型提供一个输出。事实上，神经元相比于大脑的神经元而言是一个极其简化的模型，但它确实能让神经网络发挥的足够出色。神经元的数学模型如下，可以把它理解为一个多输入单输出的函数单元。</p><p>这个函数具体的选择有很多，例如我们之前学过的sigmoid就可以作为单个神经元的函数，之后也会再介绍几种，但函数的自变量通常都是由输入变量与权重的矢量相乘[z]=[w][x]+[b]。通常，我们也把神经元的输出成为激活(activation)。<br>而神经网络就是由一系列不同功能/函数的神经元以一定的结构层次排列组合而成的网络。<br>我们把一组在功能上相同或是输入相似特征的神经元聚合在一起称为神经网络的层(layer)，将接受输入的层称为输入层，输出结果的层称为输出层，中间各类转换和处理的层称为隐藏层。我们一般把输入层作为layer0，而之后的层则依序递增。上层神经元的输出（或是激活）会成为下层神经元的输入。神经网络的层数计算不包括输入值和输出值。</p><p>我们以一个判断一件T恤是否会成为爆款的神经网络为例来看看其基本组成，图中的各神经元函数均为sigmoid函数，至于为什么这样选之后会介绍：<br>可以看到，作为一件T恤，决定它是否会成为爆款的直观输入可能包含价格、运输成本、市场营销和材质四个方面，而输出则是它成为爆款的概率。我们发现，输入与输出之间并没有直接联系，因而我们可以引入中间变量可负担能力，知名度和质量来作为一层隐藏层。可负担能力接收价格和运输成本经过sigmoid函数输出可负担能力造就爆款的概率，知名度接收市场营销经过sigmoid函数输出知名度造就爆款的概率，质量接收价格和材质经过sigmoid函数输出质量造就爆款的概率，而后这三个激活再作为输出层的输入经过sigmoid函数得到综合造就爆款的概率。<br>如果我们把左边的输入遮住，只看可负担能力，知名度和质量就可以发现，其实这个神经网络的右边部分就是这三个变量的逻辑回归。其实这个神经网络就像是逻辑回归，只不过我们把逻辑回归中的输入向量x变成了中间层的a，我们可以把a看成由x进化而来的更为高级的特征值。由于梯度下降会将a是变得越来越厉害而精确，这些更高级的特征值远比仅仅将x次方（做特征工程）厉害，也能更好的预测新数据。这就是神经网络相比于逻辑回归和线性回归的优势。神经网络的本质仍然是根据输入预测输出，而中间层产生的各变量（也就是可负担能力，知名度和质量），事实上完全由神经网络自身进行分析与处理，不劳我们费心。</p><p>在实际的神经网络中，由于我们一般难以判断隐藏层的各神经元需要的输入具体与哪个原始输入变量有关，故事实上我们会让神经元与每个原始输入量挂钩，而将具体的取舍判断交由神经网络自身决定，这也是为什么每层的如下图所示：</p><p>进一步地，写作向量形式如下：</p><p>将神经网络各层的输入输出矢量化后，我们引入更多的表示概念：</p><p>把layer l的输入记为矢量a[l-1]，输出记为矢量a[l]，输入的权重矢量记为w[l]，偏差矢量记为b[l]，每层神经元的函数记为g。如果要表示矢量里的某个值，即一层中某个神经元的输入输出结果，则用下标表示该神经元位置，上标表示该神经元所在的层，即aj[l]等。则任意某个神经元的函数表达即为下式：</p><p>接下来我们来介绍一下神经网络前向传播(Forward Propagation)的概念： 所谓神经网络的前向传播，即从神经网络的第一层开始正向一层一层进行计算，直到最后一层。利用输入x依次得到a[1],a[2]一直到输出a[k]，这通常是为了利用输入计算神经网络的预测结果和手动构建神经网络。对于一般的神经网络而言，每层神经元的数量通常是逐层递减的。</p><p>如何在代码中构建神经网络呢？我们将按照普通-&gt;矢量-&gt;函数的方法循序渐进的介绍：<br>普通：如下图所示，假设神经元函数均为sigmoid函数，为了搞清楚前向传播的流程，我们这里直接给定每层每个神经元的[w]和[b]而不通过学习得到，同时我们给定输入层变量[x]，从而得到该神经元的[z]和激活[a]，最后将该层所有神经元的[a]组合得到该层的[a]，将这个[a]作为下层的输入重复这个过程。</p><p>矢量化：在之前的学习中我们知道了，利用矢量运算能大大加快代码的运行速度，在普通的代码中，我们处理的内容都是一维向量，而事实上，我们可以把每一层的参数都组合成一个矩阵形式，如下图的[W],<a href="也就是[X]">A</a>和[B]，其中[W]的每列都表示该层一个神经元的权重[w]，[B]的每列都表示该层一个神经元的偏差[b]，则该层所有的激活输入[Z]=[AT][W]+[B]，其中矩阵乘法在Python中使用matmul实现，该层所有的激活就是[A]=g([Z])。利用矢量化，原来复杂的代码就变得既简洁又高效了。</p><p>函数：以上两个构建方法只是为了熟悉神经网络的构成，同时了解矢量化的优点。实际构建神经网络时，我们不可能一开始就知道[W]和[B]的具体取值，而是需要通过学习得到。事实上，PyTorch和TensorFlow已经为我们提供了一系列成熟的机器学习所需函数，真正使用时只需要调用它们提供的函数就可以了。得到一个神经网络的基本过程有以下三步：<br>1.构建架构：Dense规定了一层神经元的数量和该层神经元使用的激活函数（一般同一层的神经元都使用同一种激活函数），Sequential规定了哪些层会被顺序连接成一张神经网络。<br>2.定义代价函数和损失函数： 将得到的神经网络model利用方法compile(…)定义损失函数，格式是loss=损失函数，例如loss=BinaryCrossentropy()表示使用逻辑回归的损失函数（二元交叉熵），或是loss=MeanSquaredError()表示使用线性回归的损失函数（平方误差函数）。损失函数针对的目标即神经网络前向传播得到的输出y与输入x之间的关系式。<br>3.确定样本集：将输入x和输出y以np.array的形式赋值<br>4.训练神经网络：利用函数fit(x,y,epochs)来训练，其中x是输入，y是输出，通过训练可以确定神经网络各层的[W],[B]参数，而神经网络就是通过其各层各神经元的w和b来构建起一个庞大的预测模型的，可选参数epochs=K限制最大迭代次数为K次。初始化[W],[B]参数的方法一般是令[B]=0，[W]为一个很小的随机值（如0.01），而一般的训练或学习方法依然是对代价函数使用梯度下降法（事实上，是采用梯度下降法的变体Adam算法），而计算梯度下降法中的偏导项使用了神经网络反向传播算法(Back Propagation)，如何在神经网络中使用梯度下降法（Adam算法）将会马上说明。<br>5.进行模型预测：训练完毕后，当传入新的输入x_new时，就可以使用方法predict得到该输入的预测输出。</p><p>我们对比逻辑回归和神经网络，事实上两者都有经历根据输入计算输出的建模过程，确定损失函数和代价函数的过程，以及确定参数w和b使损失最小的过程。</p><p>到目前为止，我们一直在隐藏层和输出层的所有节点中使用sigmoid激活函数。事实上，我们还有很多其他激活函数可用，这些激活函数适合不同的使用场合。<br>三大主流的激活函数如下，分别是线性激活函数，sigmoid激活函数和ReLU激活函数：</p><p>1.线性激活函数：a=g(z)=z，线性激活函数也可以看作是不使用任何激活函数<br>2.sigmoid激活函数：g(z)=1/(1+e^-z)，值介于(0,1)之间<br>3.ReLU激活函数：g(z)=max(0,z)，值介于(0,+∞)之间<br>在后面我们还会学到一个叫softmax的激活函数，它通常用于多元分类问题。<br>那么如何进行激活函数的选择呢？我们分别对输出层和隐藏层探讨：<br>输出层选择：</p><p>输出层的激活函数选择其实非常有规则性，由于输出结果与其输入之间必然蕴含着一个规划问题。于是当输出y是一个二元分类问题时，输出层的激活函数显然要选择sigmoid激活函数；当输出y可以取正或取负时（股票的涨跌），输出层的激活函数显然要选择线性激活函数；当输出y只能取正数时，输出层的激活函数显然要选择ReLU激活函数。<br>隐藏层选择：<br>事实证明，隐藏层的激活函数几乎都会选择ReLU激活函数，为什么呢？<br>对比ReLU和sigmoid激活函数，首先ReLU的函数形式比sigmoid更简单，这意味着计算会更快；此外，由于sigmoid在首尾斜率几乎为0，这会导致代价函数J在多处比较平，这意味着有很多偏导很小的段，这会导致在使用梯度下降法寻找最小值时，会迭代很多次而下降的非常慢。因此，ReLU比sigmoid激活函数更适合做隐藏层的激活函数。</p><p>而由于线性激活函数表示不使用任何激活函数，故如果我们对所有的神经元都使用线性激活函数，整个大型的神经网络就会变成一个普通的线性回归问题。以下面这个例子说明，可以看到，输出a[2]和输入x之间就是一个线性关系a[2]=[w][x]+[b]。这就破坏了构建神经网络的全部目的，这也是为什么激活函数对神经网络这么重要的原因。</p><p>故综上，在隐藏层我们通常选择ReLU激活函数，少部分选择sigmoid激活函数，而几乎不在隐藏层中使用线性激活函数。<br>于是我们如果要构建一个二元分类问题的三层神经网络，一个典型的构架如下程序所示：</p><p>多元分类问题：即现在的输出y可以取多个离散的值，例如识别手写数字0-9。<br>多元分类是二元分类逻辑回归的推广，输出层使用Softmax函数作为激活函数。<br>Softmax激活函数的公式为如下：</p><p>也就是：</p><p>可以看到它是把要计算概率对应的e的z次方除以所有e的z次方得到结果。<br>易得有结果：a1+a2+…+an=1，符合概率分布。<br>以四元分类为例，此时的输出[a]=[a1,a2,a3,a4]分别是y=1,2,3,4的概率：</p><p>Softmax对应的损失函数是（log对应数学里的ln）：</p><p>由于aj表示了预测y=j的概率，故当y的真实值就是j时，就可以使用-log(aj)表示预测的损失，当aj越大时预测认为y=j的概率就越大，而当y真的为j时，损失就会越小；当aj越小时预测认为y=j的概率就较小，而结果说明y真的为j，那么损失就会较大。这就是Softmax如此规定损失函数的原因。<br>这个损失函数在TensorFlow里称为SparseCategoricalCrossentropy，于是构架代码如下：</p><p>为了提高精度，实际构建代码时我们可以使能可选参数from_logits，这个参数的功能在于它将输出层的激活函数与损失函数合二为一了，假设输出层的输入为z，输出为a，则原来的流程是利用激活函数得到a=g(z)，再对a求损失函数。利用from_logits=true，此时TensorFlow会直接把z作为损失函数的输入，没有了中间变量a运算会变得更精确，如下图所示：</p><p>于是此时的代码框架如下所示，注意由于激活函数与损失函数合二为一了，因此输出层的激活函数直接用线性激活函数起传递作用即可，代码会自行根据使用的损失函数判断输出层会使用什么函数激活z从而代入损失函数中。此外，由于此时的输出值本质上是z而非a，因此之后在预测得到输出后还应该对其做一次输出层激活（例如下图中的softmax函数）</p><p>之前介绍了多元分类问题(Multi-Class Classification)，这里再介绍多输出分类问题(Multi-Label Classification)。多输出分类问题解决针对同一输入而有多个输出的情况，例如给出一张图片，我们要判断里面是否有小轿车，是否有公交车，是否有行人。注意：这三个是非判断相互独立，也就是说这张图片里可能同时有小轿车、公交车和行人。针对这个问题，我们当然可以分为三个独立的二元分类神经网络分别判断，但多输出神经网络给了我们一个集成的机会，此时我们只需将输出层变为三个神经元即可，输出层输出的是一个含有三个特征的矢量。而后对输出层的每个神经元都使用sigmoid函数激活，其效果就等同于三个独立的二元分类神经网络了，而效率显然比三个独立的二元分类神经网络高。</p><p>对应于多输出分类问题的代价函数为（L为损失函数，m为样本数，以四输出分类问题为例）：</p><p>多输出分类问题适用于不同输出之间可以共用低层级特征的神经网络，例如共用图像识别。</p><p>在神经网络的早期实现中，人们仍然使用梯度下降法来最小化成本函数，但随着时代的发展，人们发现了一种被称为Adam(自适应矩估计Adaptive Moment Estimation)的优化算法来最小化成本函数，而其效果会比梯度下降法快很多，而因此成为训练神经网络的优异算法。<br>Adam算法通过随着优化进行自动改变学习率α入手来优化梯度下降法：</p><p>Adam算法发现，当wj和b在优化过程中始终沿着近似同一方向改变时，这意味着我们走的每一小步都朝着相似的方向迈出，这可能是α比较小的结果，既然如此，我们把学习率α变大就可以更快的达成目的了；反过来，当wj和b可能在优化过程中在谷底附近左右振荡无法收敛时，可能是α比较大，既然如此，我们把学习率α变小就可以完成收敛了。这就是Adam算法自适应改变学习率α的基本思路，实际算法比较复杂，在这不作说明。由于Adam算法的自适应性，我们可以预见，对于不同的wj和b，Adam算法给出的学习率α也就不是同一个值了，也就是α并不是一个全局的单一值而是随j变化的αj。<br>接下来给出Adam算法的代码实现，在compile方法里，除了指出损失函数loss外，还要给出优化算法optimizer并规定为Adam(learning_rate=…)，其中learning_rate是学习率的初值。</p><p>我们之前应用的神经网络层都是一种被称为密集层(Dense Layer)的网络层，密集层中的每个神经元都能得到它上一层所有的激活作为本层的输入，但事实上，网络层还有很多其他类型。卷积层是另一种比较常用的网络层，相比于密集层可以得到上一层的所有激活作为输入，卷积层的每个神经元只能上一层的部分激活作为输入，换句话说，卷积层的每个神经元只能看到上一个网络层的一部分，这会导致神经网络具有更快的运行速度且只需更少的训练数据。<br>下图可视化了一个卷积层，其中每个神经元只能看到上个网络层中对应色块的数据。</p><p>由卷积层组成的神经网络被称为卷积神经网络，以下图为例，我们给出一百个输入数据传入第一个有9个神经元的卷积层，其中每个神经元只看得到20个数据，而后第一层输出一个9列的列向量到第二个有3个神经元的卷积层，其中每个神经元只看得到5个数据，而后第二层输出一个3列的列向量到输出层做sigmoid函数得到输出。</p><p>卷积层相比密集层而言多了一个架构选择，即每个神经元窗口开的大小。<br>接下来我们看看如何评估你建立的模型的好坏。对于二维和三维模型，可以直接通过绘图来直观的判断模型效果，但对于更高维度的系统而言，我们就必须提出一个更加数学化的公式来定量的判断模型的好坏。为了在应用模型预测新输入前判断模型的好坏，我们可以把原训练集拆分为训练集(Training Set)和测试集(Test Set)两部分，比例一般为70%-30%。其中训练集专门用来训练神经网络得到[w],[b]，测试集专门用来测试得到的神经网络在预测新输入时的效果。</p><p>于是此时计算代价函数J(w,b)时，其求和项便是训练集总数mtrain。<br>对于线性回归而言，其代价函数如下：<br>同时我们定义测试集误差Jtest(w,b)和训练集误差Jtrain(w,b)分别代表训练的神经网络对新输入的适应程度和对训练样本的适应程度，在线性回归下的公式分别如下，均为对应集合的预测值减去实际值的平方均值：</p><p>同理，我们也可以得到逻辑回归的代价函数，以及其测试集误差和训练集误差如下：</p><p>一般而言，由训练集得到的模型，其训练集误差Jtrain(w,b)会比未来输入的预测结果误差小。而未来输入的预测结果误差通常可以由测试集误差Jtest(w,b)来表示，因为Jtest(w,b)不参与模型训练，因而其值可以用来当作未来输入进行预测。<br>更进一步地，如果我们想要系统自动选择一个好的模型来进行机器学习，例如我们在拟合点的时候，到底应该选择几阶多项式呢？一个选择是根据不同阶的多项式利用训练集拟合，并查看测试集误差Jtest(w,b)，选择最小的测试集误差对应阶数的多项式认为是最好的模型。但这样子我们就失去了测试集误差测试模型的作用，事实上，我们不应该让测试集参与任何形式的模型建立以确保测试集的完全中立。而要实现这个效果，我们可以将样本总集额外再多分一个部分，变为训练集、测试集和交叉验证测试集(cross-validation set)三部分，比例一般为(60%-20%-20%)。其中训练集专门用来训练神经网络得到[w],[b]，交叉验证集专门用来决定用什么模型来进行机器学习，测试集专门用来测试得到的神经网络在预测新输入时的效果。<br>此时除了定义测试集误差Jtest(w,b)和训练集误差Jtrain(w,b)外，还要定义交叉验证误差Jcv(w,b)</p><p>把待选模型按照训练集均训练一遍，取之中交叉验证误差最小的认为是最好的模型，采用此模型下训练集的训练结果作为最后的应用模型，并使用测试集来观测其对新输入的适应程度。<br>这里的模型是一个宽泛概念，既可以用于选择拟合多项式，又可以在待选的神经网络中选择最佳的一个等。</p><p>利用测试集误差Jtest(w,b)，训练集误差Jtrain(w,b)和交叉验证误差Jcv(w,b)，我们可以判断一个系统是否存在过拟合和欠拟合的问题，对于欠拟合的系统，训练集误差Jtrain(w,b)和交叉验证误差Jcv(w,b)都会非常高；对于过拟合的系统，训练集误差Jtrain(w,b)会非常低，但交叉验证误差Jcv(w,b)会非常高；对于良好的系统，训练集误差Jtrain(w,b)和交叉验证误差Jcv(w,b)都会非常低。</p><p>随着拟合多项式阶数的提高，训练集误差Jtrain(w,b)和交叉验证误差Jcv(w,b)会呈现以下趋势，在Jcv(w,b)取最小值认为系统有最佳效果：</p><p>同理，交叉验证误差Jcv(w,b)也可以被用于判断正则化项系数λ的选择，其基本流程仍然是把参数λ的待选集合按照训练集均训练一遍，取之中交叉验证误差最小的认为是最好的模型，采用此模型下训练集的训练结果作为最后的应用模型，并使用测试集来观测其对新输入的适应程度。随着λ的提高，训练集误差Jtrain(w,b)和交叉验证误差Jcv(w,b)会呈现以下趋势，因为λ的增大会导致w的减小，从而从过拟合问题过渡到欠拟合问题，这会导致Jtrain(w,b)的增大，以及Jcv(w,b)会先减小后增大，这代表着拟合效果会先变好再变差（过拟合-&gt;良好-&gt;欠拟合），在Jcv(w,b)取最小值认为系统有最佳效果：</p><p>那么如何判断测试集误差Jtest(w,b)，训练集误差Jtrain(w,b)和交叉验证误差Jcv(w,b)是高还是低，我们通常会制定一个用于性能评估的基准，例如人类完成该任务的能力，或是同类算法的表现，或是根据经验猜测。则此时的高低是基于基准的相对值，如下图所示：</p><p>判断一个系统性能是否良好也可以使用学习曲线，学习曲线是训练集误差Jtrain(w,b)和交叉验证误差Jcv(w,b)关于训练集规模mtrain的函数。<br>一个良好的模型，其学习曲线呈现如下趋势：随着m的增大训练集误差Jtrain(w,b)会上升，交叉验证误差Jcv(w,b)会下降，且两者会随着m的增大趋近于比较基准。</p><p>欠拟合：如果学习曲线随着m的增大训练集误差Jtrain(w,b)上升不大，交叉验证误差Jcv(w,b)下降不大，且两者都远高于比较基准，则此时算法可能存在欠拟合问题。因为欠拟合时可以调整的变量有限，故训练集的增大并不能让结果更好的拟合数据。</p><p>过拟合：如果学习曲线随着m的增大训练集误差Jtrain(w,b)会上升，交叉验证误差Jcv(w,b)会下降，且训练集误差Jtrain(w,b)远低于比较基准，交叉验证误差Jcv(w,b)远高于比较基准，则此时算法可能存在过拟合问题。因为过拟合会导致训练集误差很低，但对于其余数据适配度不高。同时可以发现，随着m的增大，过拟合有所缓解，这是因为训练集样本比较大时可以纠正算法过于执着于拟合经过几个点的情况。</p><p>学习曲线需要不断的选取训练集子集进行绘制，因而存在运行速率慢的特点。</p><p>修正过拟合可以采取以下方法：                修正欠拟合可以采取以下方法：<br>1.给予算法更多的训练集数据                    1.增加特征的维度和数量<br>2.降低特征的维度和数量                        2.尝试降低正则化系数λ<br>3.尝试提高正则化系数λ</p><p>故训练一个算法或神经网络的一般步骤如下，当训练集误差Jtrain(w,b)较大时，系统可能存在欠拟合问题，于是可以扩大神经网络解决欠拟合问题；当交叉验证误差Jcv(w,b)较大时，系统可能存在过拟合问题，于是可以给予算法更多的训练集数据解决过拟合问题。</p><p>事实证明，一个良好正则化的大型神经网络，其效果一般都会比小型神经网络效果好，故不必过于担心扩大神经网络可能导致的过拟合问题。<br>用代码为神经网络层添加正则化项的方法是在Dense中增加一项kernel_regularizer=λ即可。</p><p>机器学习的开发迭代满足以下逻辑闭环：Loop(选择模型和数据，训练模型，利用性能指标的判断方法诊断模型性能)</p><p>当训练出的模型效果不佳时，此时可以启用误差分析。所谓误差分析，即人类在系统判断错误的样本中抽取一部分来观察出错的原因，并取其中占比较大的优先解决。我们可以为样本集添加大量由最大原因导致的同类错误样本来集中训练神经网络在这方面的缺陷。误差分析适合该任务人类擅长时，可以作为指导方向的参考，避免花了大量精力解决了一个可能不是那么重要或者占比不是那么大的出错原因。</p><p>接下来我们来看看如何在有限的样本集中添加数据的方法：<br>对于视觉识别或语音识别等神经网络，我们可以对图片进行旋转，放缩，扭曲，添加噪声等来对一个示例提出更多具有类似标签的新示例。同理我们也可以对语音识别的原始语音添加背景噪声来提出新示例。</p><p>但是有一个要注意的事项，如果你只是为神经网络添加一些完全随机而无意义的样本，这并不会让神经网络表现得更好，即利用这种方法添加样本时必须基于原有样本。<br>事实上，现代的神经网络反而更看重训练数据而非算法和模型了。<br>迁移学习：对于数据很难获得、变换或添加而没有那么多数据的神经网络，迁移学习可以帮助你使用来自不同任务的数据来完善你的神经网络。例如我想识别手写数字0-9，但我没那么多样本，但我有一组很大的关于猫、狗、汽车、人等的样本集，比如说100万张具有1000个不同类别图像的样本集，此时我可以直接使用这个样本集先训练一个分辨这1000个种类的神经网络得到一组[w],[b]数据，而后将这个神经网络整体迁移到我的训练集中，而只需改变神经网络的输出层（从1000个输出变为10个输出），则非输出层的[w]和[b]的初值就是已训练好的神经网络非输出层的参数，而输出层的[w]和[b]需要用自己的训练集重新训练。对于极小的训练集而言，可以保持非输出层参数不变而只训练输出层参数；对于稍微大一点的训练集而言，可以训练所有参数，其中非输出层参数的初值为已训练好的神经网络非输出层的参数。</p><p>于是迁移学习的步骤一般为：先利用大型训练集进行神经网络的预训练，再使用自己的训练集对参数进行微调，微调方法无异于梯度下降法或Adam算法。<br>迁移学习的原理在于，对于输入类型相同的样本集来说，每一层神经网络（尤其是底层）做的事情会被训练的几近相同，例如图像识别中的第一层往往会识别物体的边，第二层识别物体的角，第三层识别曲线和基本图形，而这些不论在数字还是物体中都是非常通用的图像特征，正是因此我们可以使用图片来预训练神经网络用于识别数字，而只需要进行部分微调就能实现一个很好的效果。不过这也告诉了我们，迁移学习的输入种类必须相同，例如图像识别要用图片集，语音识别要用音频集，但两者不能混用，这是因为只有相同类别的神经网络才具有相似性和可转移性。</p><p>接下来介绍一下精确率和召回率(Precision and Recall)的概念，对于存在极为罕见情况或二元可能差别极大的二元分类而言（例如监测患者是否患有某种罕见病），对于这样的系统而言，判断系统的好坏就不能用一个简单的“准确率”来概括了，事实上，如果我们把所有输入的患者都标记为没病，则系统的“准确率”依旧很高，但这不能说明这是一个好的预测系统。<br>对于这种系统而言，我们一般将其分为四种类型，把hat{y}=1且y=1的称为True Positive类（即正确预测阳性），把hat{y}=1但y=0的称为False Positive类（即错误预测阳性），把hat{y}=0但y=1的称为False Negative类（即错误预测阴性），把hat{y}=0且y=0的称为True Negative类（即正确预测阴性），同时我们假设y=1为罕见类。以阳性为例，预测结果的精确率被定义为正确预测阳性的数量/预测阳性的总量，预测结果的召回率被定义为正确预测阳性的数量/实际阳性的总量。一个良好的模型应该同时具有不错的精确率和召回率，而像我们之前说的那个系统，虽然预测y=0时具有良好的精确率和召回率，但y=1时由于正确预测阳性的数量=0，故精确率和召回率都为0（定义0/0=0），模型自身的问题便暴露无遗了。</p><p>事实说明，精确率和召回率两者不能兼得，又或者说两者侧重于系统的不同方面。仍拿罕见病作为例子，如果我们希望具有十足把握时系统才预测y=1，此时我们可以将逻辑回归的阈值从0.5上调到0.8甚至0.9，即只有系统认为有80%-90%概率该患者患有罕见病时才预测其有罕见病，这种情形一般出现在治疗需要花大量金钱且保守治疗效果不差时，此时系统的精确率会提高，因为预测阳性的条件更为苛刻了，但系统的召回率会降低，因为会有很多系统认为概率不那么高但实际为阳性的病例被忽略掉了。反之，如果我们希望系统宁可杀错，不可放过的话，此时我们可以将逻辑回归的阈值从0.5下调到0.3或0.2，即只要系统认为有20%-30%概率该患者患有罕见病时就预测其有罕见病，这种情形一般出现在如果患病则可能危及生命时，此时系统的精确率会下降，因为会预测错误很多实际上没患病的患者，但系统的召回率会提高，因为预测阳性的条件比较宽松，大部分患病的患者都会被检测出来。<br>事实上，精确率和召回率之间的关系随阈值的改变呈现如下趋势，阈值较高必然带来预测率的提高和召回率的下降，阈值较低必然带来预测率的下降和召回率的提高，而要想确定这个阈值究竟取何值，既可以手动根据精确率-召回率曲线结合实际需求观察，也可以自动确定：</p><p>如果想要自动确定阈值，一般是取精确率和召回率的调和平均数(F1 score)最高者。记精确率为P，召回率为R，则F1 score的公式如下图所示，调和平均数会避免P和R之中某个值过小，即对应精确率或召回率过小的系统，这样的系统不是一个好系统。</p><p>决策树(Division Tree)：接下来我们将学习另一种高级机器学习算法称为决策树，同样我们也要给定一组包含输入与输出的样本集，而决策树的各个非叶节点就是样本集的每种输入变量，这个输入变量既可以是离散的，也可以是连续的，决策树根据这个输入变量的某种区别将整个样本集分为左右两个子树，而这两个子树的根节点就是该输入变量，再对每一个子树也做如上递归，以此类推，直到满足终止条件（关于终止条件会在之后讨论）时，将仍在一起的一群样本归为一类放到叶子结点，并成为未来可能输入的预测输出。<br>我们以一个给出动物的耳型、面部和是否有胡须判断该动物是否为猫的决策树为例，由样本集训练得到的决策树如下所示，未来预测新输入是否为猫时也按照下述决策树的步骤一步步从根节点走到叶子结点，直到判断完成：</p><p>决策树学习算法：在所有可能的决策树里，尝试选择一个在训练集中表现良好，且具有推广性的最优决策树。<br>那么如何得到一棵最优决策树呢？<br>我们先来引入纯度(Purity)和熵(Entropy)的概念：纯度是一个子集同属某种类型（叶子结点）的程度，熵是一个子集分属不同类型的程度，可以认为纯度和熵是一对相反的概念。一棵最佳决策树的每一次节点分裂，不是任取某个特征就进行分裂，应当是选取能将所有的样本分割成两部分熵较小，纯度较大的样本子集的特征进行分裂。而当一个节点中的所有样本同属某种类型时（纯度为1，熵为0）时，我们就找到一个叶子结点，于是停止分裂这一节点。由于实现一个节点中的所有样本同属某种类型比较困难，当分裂会决策树超出最大深度（规定最大深度主要是为了防止决策树过拟合，即设置的特征辨别过多），或是每次分裂导致纯度的提高或熵的下降低于阈值（即将饱和），或是一个节点中样本的数量小于阈值时（即将饱和），我们也会停止分裂。<br>每个节点纯度的计算公式是：p=同属同一叶子结点的样本数量/总的样本数量</p><p>每个节点熵的计算公式由熵函数(Entropy Function)H(p)定义：</p><p>由于熵包含了纯度的概念，故通常我们就用熵来替代纯度。从熵函数可以看出，当一个节点的样本中由给定特征分出的两个子集分别各占一半时(p1=p2=0.5)，熵的结果最大为1；当一个节点的样本中由给定特征分类只有一种结果时(p1=1,p2=0/p1=0,p2=1)，熵的结果最小为0。使用Log2来定义熵函数主要是为了使当使p1=p2=0.5时，熵的结果为1，定义0log(0)=0。<br>有了熵函数，我们就定量的知晓了拆分特征时最大程度减小熵，最大化纯度的方法。每次拆分特征时熵的减小量称为信息增益(Information Gain)。我们还是以判断一个动物是否为猫为例，在确定其根节点特征时，我们将三个特征分别求解出对应的熵函数（注意：由于每次拆分时左右两个子集的数量会有所区别，在分别计算左右两部分子集的熵函数要乘以权重来得到最终的熵函数）并与拆分前的熵函数进行比较得到信息增益，信息增益最大的拆分规则即为最理想的拆分规则，每次都是最理想的拆分得到的结果也就一定是最优决策树。</p><p>信息增益的计算公式如下所示：即根节点的熵与左右子节点熵的加权平均值的差值</p><p>确定了最佳的拆分特征后，具体将训练数据发送到左分支或右分支，则取决于该实例的该特征的值。<br>于是，得到最优决策树的过程如下所示：<br>1.开始时所有的样本均在根节点<br>2.对所有可能的特征计算信息增益，选取信息增益最大的特征为实际拆分特征<br>3.根据实际拆分特征拆分样本集为左右两个样本子集<br>4.对左右子树重复过程2（一般先左再右），直到满足终止条件则设置一个叶子结点。<br>可以看到得到最优决策树是一个递归过程。如果左右子树在选择可能的特征时选择与父节点一样的特征，会发现H(p1root)=1，wleft=1，H(wleft)=1，故而信息增益为0，因此新的分类必然不可能是与父节点一样的特征。但是同一父节点的左右子节点之间是可以取用相同的特征的。<br>上面判断一个动物是否为猫的例子中，我们把所有的特征都定义为只能取两个值的特征，那么如果一个特征可以取多个离散值时应该怎么处理呢？我们引入独热编码(one-hot encoding)的概念，所谓独热编码，即如果一个特征可以取k个值时，就把它变为k个只能取两个值的二元变量。例如Ear Shape可以分为Pointy,Oval和Floppy三种时，我们就把Ear Shape变为是否是Pointy ears，是否是Floppy ears，是否是Oval Ears三个变量，这三个变量都是二元变量，且同时只有一个可以取1，其他都是0。则此时又可以用一般的决策树算法了，只是变量的数量有所增加。</p><p>此外，如果特征变量是连续的话，决策树又该如何确定该变量的节点呢？例如我们给定动物的体重，如何判断该动物是不是猫呢？对于二元特征而言，我们容易把它分为左右两个子树，而对于连续特征而言，分为两类的思想也是理所应当的，即将小于某个阈值的分为一类，而将大于该阈值的分为另一类，那么关键就在于如何确定这个阈值了。其方法是：我们先画出是否为猫与重量关系的图表，而后选择某个值作为阈值将样本分为两个子集，仍然按照离散的规则计算对应的信息增益即可。而确定所谓“某个值”的方法是取相邻两个连续特征的中点作为分界线做一次阈值尝试，故n个样本点需要做n-1次阈值尝试，最后取信息增益最高时对应的值作为实际阈值即可。</p><p>进一步地，之前的例子都是判断一个动物是否为猫，即输出的结果是离散的，那我们可不可以用决策树判断连续的结果呢？答案是可以的。此时输入的变量仍然是离散的，而输出结果是连续的。我们把这种用于预测回归问题的决策树称为回归树(Regression Tree)。在回归树中，我们预测的结果是一个连续变量的可能取值。例如，我们给定动物的耳型、面部和是否有胡须判断该动物的体重，此时分类的衡量标准便由熵变为了方差。具体地，我们对所有可能的特征计算分类后方差的加权平均数并与分类前的方差作差值得到方差增量，同理选择方差增量最高的作为实际特征并重复循环。</p><p>当只有一个决策树时，决策对样本的敏感度会非常高，样本集的轻微变化就可能导致决策树的剧烈变化。为了降低算法对样本的敏感度，通常我们会选择同时使用多个决策树做预测，并根据多数原则给出最终判断。把多个决策树构成的决策算法称为随机森林(random forest)。如果要生成多个决策树，光有一个样本集是不够的，我们要做的是利用原样本集得到多个样本集，且新训练集需要与原训练集类似而又有不同，采取的方法有以下几种：<br>1.有放回抽样：将含有n个样本的原样本集进行n次有放回抽样，把得到的结果组成一个新的样本集，这样就能保证新训练集与原训练集类似而又有不同，而后对新训练集也重复做决策树学习算法得到一棵新的决策树，重复这一过程B次便可以得到一片有B棵决策树的随机森林。<br>2.选择部分特征：有放回抽样得到随机森林的方法可能会导致每棵决策树在根节点及其附近类似或相同，不利于森林的多样性。选择部分特征的方法指出，在选择每个节点的特征时，只允许算法选择特征总量n的一部分特征k作为可选特征，一般选取k=sqrt(n)。<br>3.刻意学习：是有放回抽样的进阶版本，它把上一个决策树没有做好的地方在构建下一个决策树时更加关注。刻意学习的方法指出，当按照有放回抽样的思路得到一棵新的决策树后，把该决策树与原训练集对比，查看该决策树对原训练集的预测，在下一次抽样时，不完全随机的抽取训练集数据，而更有可能去抽取上一次决策树预测错误的样本。这个算法也被称为Boost算法，而Boost算法里最为出色的是一种被称为XGBoost（Extreme Gradient Boosting）的算法，在代码里调用XGBoost的函数如下，XFBClassifier()解决分类决策树，XFBRegressor()解决回归树问题：</p><p>最后对比一下决策树和神经网络各自的优缺点，以作出正确的选择：<br>决策树：适合作用于有结构的数据（表格），不适合作用于无结构的数据（例如图片、文本和音视频）；学习时间通常比神经网络快。<br>神经网络：既适合作用于有结构的数据，也适合作用于无结构的数据；学习时间通常比决策树慢；可以使用迁移学习进行预训练；可以串联构建更大型的神经网络</p><p>接下来我们就要学习无监督学习的相关知识了：</p><p>与监督学习不同，无监督学习给出的训练集中仅仅给定了样本输入，而没有给出其对应的输出，机器本身需要利用算法找到这些数据的某种结构以预测未来输入的结果。<br>聚类(clustering)：获取没有标签的数据并尝试将它们自动分组到不同集群中。最常用的聚类算法是一种被称为K-means的聚类算法，它采用集群中心的思想完成聚类。首先，我们根据规定的集群数k随机在工作空间初始化k个集群中心记为μ1-μk，将数据总数记为m，每个数据记为x(i)(i=1 to m)，每个数据x(i)离得最近的集群中心对应的序号记为c(i)，每个数据x(i)离得最近的集群中心记为μc(i)。K-means算法重复如下步骤：遍历每个数据，得到每个x(i)对应的c(i)；遍历每个集群中心，取属于对应集群中心的所有数据的均值更新集群中心。直到某次重复后，集群中心的值不再发生改变，即算法收敛，则此时同属于一个集群中心的所有数据便被归为同一类。<br>整个算法的思想是非常合乎逻辑的，我们从理论上验证一下，K-means的代价函数被称为失真函数(Distortion Function)，其公式如下，即每个数据到其对应的集群中心距离的平方均值：</p><p>事实证明，K-means聚类算法既适合用于分离良好的集群的聚类，又适合用于分离不是很好的集群的聚类。例如要根据人的身高和体重分配衣服的尺码SML，此时虽然数据是比较集中的，但K-means算法仍能较为清晰地分离数据组成聚类。</p><p>现在的问题是，我们如何进行集群中心的随机初始化呢？事实上，任意的随机初始化可能会出现平均值为0的集群中心，此时的解决办法一般式消除该集群中心，或者重新初始化该中心。避免这个问题的更好方法是在初始化集群中心时，只选取已知训练集中的训练点作为初始集群中心。</p><p>当然，在初始化时还会碰到的问题是算法可能会陷入局部最优情况：</p><p>为了解决这个问题，我们可以重复K-means算法多次，每次都重新在训练集中随机选择训练点作为初始集群中心运行K-means算法得到最优解，重复次数一般在50-1000之间。最后选择一个代价函数J结果最低的作为真正的全局最优解。此时得到的结果一般就是最佳的了。</p><p>最后一个问题，我们在做聚类问题时应该如何选择K的值呢？一种方法被称为肘法(Elbow Method)，一般而言，随着K的增长代价函数J会逐步减小，画出J-K曲线后选取曲线的肘部（函数二阶导最大的地方）对应的K作为聚类的数量，此时的K被认为是最佳的K。</p><p>但是，这种方法在肘部不明显的函数里将会难以使用；且事实上，我们选取聚类数量K的时候通常是带有目的的，例如我们在选择T恤尺寸分类时通常在一开始就确定了是要分三类(SML)还是五类(SMLXLXXL)，故我们其实可以直接进行K值的选择而不需要采用肘法。</p><p>异常检测(Anomaly Detection)：异常检测算法查看未标记的正常数据集，而学会检测异常数据并发出危险信号，异常检测常常用于制造缺陷和金融欺诈等问题。要实现这个功能需要使用密度估计(Density Estimation)，一般而言，异常检测中正常的样本会占绝大部分，于是我们判断一个样本是否异常的方法是设定一个阈值ε，当测试样本xtest的出现概率p小于ε时，则认为该样本有异常，否则则认为该样本正常。</p><p>由于现实生活的大部分变量符合正态分布：</p><p>于是异常检测算法的基本流程如下：<br>1.选择n个可能导致异常样本的特征xi<br>2.计算n维正态分布的所有期望和方差参数：</p><p>3.得到n维正态分布公式后，给定新的输入样例，判断p(x)与ε的大小关系：</p><p>上述p(x)公式成立的前提条件是各特征之间相互独立，但实际上各个特征可能相关，但事实证明，就算各个特征不独立该算法也能正常工作。而且由于p(x)是各特征变量的相乘，故当一个特征过小就会导致整体结果偏小，这也说明异常检测在任何维度检测到异常就会被鉴定为整体异常，这也符合异常检测的基本要求。</p><p>在异常检测中，为了选择合适的ε以及评估系统的性能，我们也会采取训练集、交叉验证集、测试集分立的方法。而且通常，我们会对异常检测的样本集进行正常或异常的标记，这可以提高异常检测的效果，尽管这有点像监督学习，但它实际上只是为了方便测试结果。例如我们有一个飞机引擎的样本集，其中有10000个被标记为正常的和20个被标记为异常的数据，此时我们一般不在训练集中使用异常数据（这就是为什么它并不是监督学习），而在交叉验证集和测试集判断系统性能时加入异常数据来看看系统检测异常的效果。例如在训练集中放入6000个正常样本，在交叉验证集和测试集中各放入2000个正常样本和10个异常样本。<br>此时选择ε的值就比较直白了，我们只需要在交叉验证集中选择把所有10个异常样本均排除在外的ε即可。当然，实际应用时我们会像罕见病的那个例子一样，综合精确率和召回率来得到一个最合理的ε值。</p><p>对比异常检测和二元监督学习，异常检测通常具有极少的阳性例子和大量的阴性例子，而监督学习的二元分布通常较为平均；此外，由于异常检测基于正常数据，因而它可以处理与原来出现的异常类型或原因完全不同的异常，凡是任何偏离正常数据的结果都会被标记为异常，而不论它是如何产生的，而监督学习检测二元分布时是基于已有的二元训练集的，因而它只能处理在训练集里见到过或近似的异常。例如金融诈骗花样百出，故采用异常检测；而垃圾邮件通常都带有推销的字样，故采用二元监督学习。</p><p>在异常检测中选择合适的监测特征也是很重要的，有的监测特征可能并不符合正态分布，此时再使用正态分布概率预测时误差就会比较大。当然，对于这种特征，我们有办法能让他变得更加符合正态分布，常见的方法是对原变量取对数log(x+c)或取小于1的幂x1/n。如果想要定量判断一个分布与正态分布的相似程度，可以查阅相关资料。</p><p>如何判断是否要为异常检测提供新的检测特征呢？一个常用的规则是如果异常和正常的样本在当前数量的特征下混在了一起无法区分，此时就要添加额外的检测特征，如下图将一维特征扩展为二维特征：</p><p>还有一种方法是根据已有特征来扩展新特征，例如在维护网站时，已有的特征是用户的CPU负载和网络流量，一般CPU负载和网络流量成正比，也许一个用户的CPU负载和网络流量都处在正常范围内，但CPU负载比网络流量相差很大，这仍然是不正常的。此时可添加新特征为CPU负载/网络流量，以此检测这种问题的出现。</p><p>推荐系统(Recommendation System)：推荐系统也是一个非常受关注的机器学习算法，现在你每在一个网站上浏览数据，网站都会向你推荐他们认为你可能想要关注或感兴趣的内容，实现这个功能就需要借助的机器学习算法就是推荐系统。<br>我们以一个根据用户对已看过电影的评分来推荐他们未来可能喜欢的电影的推荐系统为例：</p><p>在这个例子中，我们用nu表示用户的数量，nm表示电影的数量，r(i,j)表示用户j是否对电影i进行了评价，m(j)表示用户j评分电影的数量，y(i,j)表示用户j对电影i的评级（只有在r(i,j)=1时被定义）。而推荐系统的目标就在于，当给出用户对于不同电影的评价后，推荐系统要查看用户未评分（没有看过）的电影，并尝试预测用户如何评价这些电影，从而向用户推荐他们更有可能评价为5星的电影。要实现这个功能的算法比较复杂，我们循序渐进的来介绍。<br>我们先假设我们额外知道一些描述电影类型的特征，例如我们知道对应电影隶属于浪漫片和动作片的程度，同时我们用n来表示描述电影类型的特征个数，x(i)来表示电影i对应的特征向量x，则预测用户j对电影i的评分可以使用特征方程：hat{y(i,j)}=<a href="j">w</a><a href="i">x</a>+<a href="j">b</a>来实现，这个公式其实就是线性回归的公式，其中<a href="j">w</a>和<a href="j">b</a>都是用户j的预测参数矢量，<a href="j">w</a>矢量里的每个值对应了用户对每个电影的喜好程度，<a href="j">b</a>是偏差量，和线性回归一样由梯度下降法得到w和b的最优值。</p><p>和线性回归一样，当我们得到了特征方程后，下一步就是写出代价函数了，对于已知描述电影类型特征的情况，每个用户j的代价函数和线性回归代价函数一致，只是需要注意的是，求和符号的下标是用户j已经预测的电影集合（相当于已知的训练集），<a href="j">w</a><a href="i">x</a>+<a href="j">b</a>-y(i,j)即为用户j对电影i的预测值与实际值的差，我们对其做平方均值并加上正则化项即为下式：</p><p>但事实证明，我们把分母中的m(j)项去掉对于得到代价函数的最小值没有任何影响，故用户j的代价函数可以简化为：</p><p>进一步地，我们可以得到所有用户总和的代价函数：</p><p>利用这个代价函数求梯度下降，我们就可以得到每个用户的预测参数矢量<a href="1">w</a>-<a href="nu">w</a>和b(1)-b(nu)了。举个例子，对于用户1，我们利用样本集（即用户1对电影1,2,4,5的评分）优化代价函数得到了w(1)=[5,0],b(1)=0，则我们可以预测用户1对电影3的评分为w(1)x(3),b(1)=4.95接近于5分，故算法会向用户1推荐电影3。可以看到，此时的样本集即不同用户对不同电影的评分，而预测则是那些用户对还没有打分的电影的可能评分，从而决定是否向对应用户推荐对应电影。<br>同样的，我们再假设我们知道用户的参数矢量<a href="j">w</a>和<a href="j">b</a>，而学习目标是得到每个电影的特征矢量<a href="i">x</a>。</p><p>则此时代价函数的目标就应该是<a href="i">x</a>，则代价函数应该是预测值与实际值的差的平方均值并加上<a href="i">x</a>的正则化项，且此时由于主体是电影的特征向量，故求和的目标是那些为电影i打分的用户j，即为下式：</p><p>进一步地，我们可以得到所有电影总和的代价函数：</p><p>利用这个代价函数求梯度下降，我们就可以得到每个电影的特征向量<a href="i">x</a>。举个例子，我们假设w(1)=[5,0],b(1)=0，w(2)=[5,0],b(2)=0，w(3)=[0,5],b(3)=0，w(4)=[0,5],b(1)=0，则我们可以预测电影1的特征向量，即w(1)x(1)=5，w(2)x(1)=5，w(3)x(1)=0，w(1)x(1)=0，结合这四个式子可得x(1)=[1,0]可以看到，此时的样本集即不同用户对不同电影的评分，而预测则是电影的特征向量。<br>综上，当我们给出电影的特征向量和评分表后，算法可以预测用户的参数矢量<a href="j">w</a>和<a href="j">b</a>；反过来，当我们给出用户的参数矢量和评分表后，算法可以预测电影的特征向量<a href="i">x</a>。</p><p>但是实际上，我们可能既不知道描述电影的特征向量，又不知道用户的参数矢量，也就是说<a href="j">w</a>,<a href="i">x</a>,<a href="j">b</a>都是我们需要去预测的量。这时候就要使用协同过滤算法(Collaborative Filtering Algorithm)来解决问题了：协同过滤算法指出，既然已知<a href="i">x</a>学习<a href="j">w</a>,<a href="j">b</a>的代价函数和已知<a href="j">w</a>,<a href="j">b</a>学习<a href="i">x</a>的代价函数都知道了，那么当w,b,x都未知时，只需要将三者都当作优化量，而代价函数则是两者优化函数之和。注意求和项合并后即为所有已评分的项目(i,j):r(i,j)=1。</p><p>要求解这个代价函数的最小值，应用的方法仍然是梯度下降，只不过由于此时x(i)也是优化目标之一，因而求偏导时还要对x(i)求偏导</p><p>最后我们便可以利用协同过滤算法得到w,b,x的最优值。协同过滤算法通过分析多个用户的合作评价（对应打分表），可以让我们了解各变量的特征向量取值（对应一部电影可能是什么类型的），反过来，利用特征向量，我们可以得到用户的参数矢量（对应用户对不同类型电影的喜好程度），从而预测用户对于还未评价的变量会做出如何反应（对应用户对还没看过的电影可能打出的分数），从而决定是否向用户推荐该变量（对应是否要推荐这部电影给目标用户）。<br>此外，推荐系统除了有像电影评分这种0-5星的多变量/连续系统，还有一些二进制标签(Binary Labels)，例如对一个视频点赞或不点赞，收藏或不收藏等。<br>我们用数字1表示用户看到某个项目后参与了该项目（例如刷到视频后点赞投币收藏），用数字0表示用户看到某个项目后没有参与该项目（例如刷到后就划走了），用?表述用户还没看到过该项目（例如还没刷到这个视频）。则此时的样本集应该长这样：</p><p>正如之前从线性回归走向逻辑回归，我们预测用户对二进制标签的结果也应该是0或1的二元值，也就是预测用户取1的概率，这点和逻辑回归如出一辙。故类似的，在预测概率时，我们也像线性回归走向逻辑回归时一样，为<a href="j">w</a><a href="i">x</a>+<a href="j">b</a>外套上一个g(z)=sigmoid函数即可。</p><p>于是此时的预测函数就是关于w,b,x的三元sigmoid函数：</p><p>对应单个变量的损失函数是逻辑回归中的二元交叉熵函数：</p><p>而代价函数则是单个变量损失函数之和：</p><p>现在有一个问题摆在眼前，如果存在一个用户他没有评价过任何电影，事实上这也是很常见的现象，那我们向他推荐电影时应该遵循什么原则呢？（如下图的Eve）</p><p>事实说明，如果一个用户未评价任何电影的话，系统对该用户的预测参数矢量[w]和[b]应该均为0，那么由[w][x]+[b]则系统预测用户对任何电影的评分都将是0，也就不会推荐任何电影给这位用户了，这显然是不合理的。为了避免这个问题，我们通常会对样本集进行均值归一化(Mean Normalization)，我们将样本集抽象为矩阵形式，行代表不同用户对同一电影的打分，列代表同一用户对不同电影的打分，此时若对每个元素减去其对应行评分的均值μ，我们便可以得到一个每行元素之和均为0的矩阵，这就是均值归一化的结果。</p><p>由于此时减去了评分均值μ，因而在计算最后分数时还要加上μ，故公式即为<a href="j">w</a><a href="i">x</a>+<a href="j">b</a>+μi。如此这般，对于已评价用户而言其分数并不会发生变化，而对于没有评价过任何电影的用户而言，由于[w]和[b]均为0，则系统的推荐便取决于其他人评分的均值μ，这比预测用户对任何电影的评分都是0合理不少。<br>同理，如果一部电影没有任何用户评价，对应矩阵行全是？，则此时我们对列取均值μ（未评价过的用户不计入在内）重复上述步骤。则此时对于没有人评分的电影，系统认为用户对该电影的评分为每个用户评价其他电影的均值，也显得比较合理。<br>这类问题也被称为冷启动问题(Cold Start Problem)，协同过滤算法本身并不适合解决冷启动问题，我们必须对它进行均值归一化后才能得到一个比较合理的结果。<br>协同过滤算法在TensorFlow下的实现如下：<br>关键步骤在于TensorFlow的自动微分(Auto Diff)过程求解偏导项，重点公式为：<br>tf.Variable(init)，tf.GradientTape()和tape.gradient(y,x)</p><p>同理，多变量偏导的过程也类似：</p><p>推荐系统还有一个作用是，那就是寻找相关特征推荐。例如我们在视频网站上看一部电影，其下方的推荐栏总是会推荐很多类似的电影。它的实现也很简单，只要我们在协同过滤算法中算出[w],[b]和[x]后，寻找其他电影的[x(l)]与本电影[x(i)]类似的即可。类似在数学上的定义即为欧几里得范数之最小，即：</p><p>综上我们也可以看出，协同过滤算法存在一个问题就是，它只能得到一组特征向量[x]，却没办法说明这个特征向量的具体意义，基于比较的推荐也只能做到特征向量的近似。在实际的推荐系统中，我们往往可以得到用户和对象的某些信息来判断是否值得推荐，例如用户是中国人而对象是一部国风电影，那么推荐系统便可以根据这些已知的标签去进行推荐，而协同过滤算法本身不具备这种觉察性，这便引出我们接下来要讲的基于内容的过滤算法(Content-based Filtering Algorithm)。协同过滤算法基于用户的评分表来推荐你可能给高分的电影，而基于内容的过滤算法基于用户特征与电影特征的匹配程度推荐你可能喜欢的电影。</p><p>仍以用户与电影的例子说明，在基于内容的过滤算法中，我们通常知道关于用户和电影的一系列标签，我们把用户j的标签向量记为xu(j)（例如年龄、性别、国家、看过的电影与评分等），把电影i的标签向量记为xm(i)（例如上映时间、类型、平均得分等）。此时预测用户j与电影i匹配程度的函数可以参照<a href="j">w</a><a href="i">x</a>+<a href="j">b</a>，只不过此时我们通常把<a href="j">b</a>定义为0，把<a href="j">w</a>和<a href="i">x</a>分别记为vu(j)和vm(i)，其中vu(j)和vm(i)由xu(j)和xm(i)计算而来。由于vu(j)和vm(i)需要执行点乘，因而xu(j)和xm(i)向量长度可能不同，但vu(j)和vm(i)的长度必须相同。故判断电影和用户是否匹配即判断vu(j)和vm(i)的点乘值是否够大，例如vu(j)可以是用户对不同类型电影的喜好程度，vm(i)可以是一部电影分属不同类型的比例程度，两者通过点乘便可以寻找良好匹配。<br>那么如何通过xu(j)和xm(i)得到vu(j)和vm(i)的值呢？<br>我们仍然可以使用神经网络，通过输入xu和xm得到输出vu和vm，再对vu和vm做点乘得到预测结果，需要注意的是用户神经网络和电影神经网络是共用一个神经网络而不是分开训练的，输出层的结果是vu和vm的点乘。</p><p>对应的代价函数也就是预测值vu和vm的点乘减去真实值的平方误差和正则化项</p><p>同理，也考科一利用基于内容的过滤算法来寻找相关特征推荐。只需要将对应的欧几里得范数公式更改为：</p><p>基于内容的过滤算法在TensorFlow下的实现如下：</p><p>主成分分析(Principal Component Analysis)：<br>为了可视化特征数量较多的系统，我们会使用一种称为主成分分析的无监督学习算法，简称PCA。PCA可以把大量的特征（例如50个）简化为2到3个，从而可以绘制于可视图表中。基于这个特性，它偶尔也会用于简化样本集或训练过程中。<br>PCA算法缩减特征数量的关键在于寻找一个能最大化每个样本所有特征的轴。<br>以二维样本简化为一维样本为例，要找到一个能最大化每个样本所有特征的轴，也就是要找到一个各样本点在该轴上的投影方差最大的轴。根据这个要求，我们便可以利用算法得到结果了，这个轴也被称为主成分轴。下图是两种主轴的选择：可以看到第一张图中主轴的选择导致各投影的方差不大，故不是一个能明显凸出各样本区别的选择，而第二张图中主轴的选择就显得合理多了（图中黑线是最优选择，蓝线是当前选择，X是而样本点，·是投影点）：</p><p>当我们得到主轴上的投影点时，也可以近似的估计原始数据各特征的值，方法是对主轴上的点对各个初始轴做投影，注意其结果只是一个近似值，因为在做主轴投影点时部分特征值被忽略了。<br>以上都是将所有特征缩减到1个特征的情况，如果要缩减到2个特征，可以做一个与主轴垂直的轴作为第二特征轴；如果要缩减到3个特征，可以做一个与主轴和第二特征轴都垂直的轴作为第三特征轴。</p><p>此外，需要说明的是，PCA与线性回归并不是一个概念，具体区别在于差值和投影的区别，且PCA要得到最大方差，而线性回归要得到最小差值，具体可以参考下图的对比：</p><p>PCA在TensorFlow中的代码实现如下：<br>PCA函数确定要缩减为几个变量，fit函数根据原特征变量计算主轴，explained_variance_ratio打印每个轴分别体现了多大比例的原特征变量，transform得到将原特征变量的值投影到主轴（如果有的话：第二特征轴、第三特征轴）后的结果，inverse_transform得到将主轴值投影回原初始轴的原始数据近似真实值，以二维样本简化为一维样本为例：</p><p>强化学习(Reinforcement Learning)：强化学习的目的在于，我们通过给予激励和惩罚希望系统学会要做什么而不是让我们教他具体怎么去做。例如做无人机和机器狗时，如果要让我们根据其当前状态随时教育它应该怎么做，这是不可能的，因为现实的工况过于复杂。反之，我们通过激励函数来对这个系统做出的正确行为给予奖励，而对这个系统做出的错误行为给予惩罚，从而教会系统在每个状态都依据最大奖励的行为运行，这被证明能用于优化系统。</p><p>以一个简单的离散系统为例，一个火星车在任意时刻都处于如下六种状态的一种，假设初始时刻它位于状态4，我们希望它前往状态1或状态6去观测地表，但时间只允许它前往状态1或状态6之一，且状态1比状态6更远但更值得勘察，那么我们应该怎么设置激励函数来让火星车根据激励来运动？假设我们在状态1上设置激励为100，在状态6上设置激励为40，同时我们设置前往下一个状态的时间成本为0.9。于是，我们从状态4前往状态1的激励便是0+0.9<em>0+0.9</em>0.9<em>0+0.9</em>0.9<em>0.9</em>100=72.9；同理，我们从状态4前往状态6的激励便是0+0.9<em>0+0.9</em>0.9*40=32.4，则系统便在激励函数的作用下选择前往状态1。</p><p>同理，如果我们把时间成本改为0.5，则系统在不同初始状态前往不同终点的激励便是如下：</p><p>故系统在不同初始状态选择前往的目标和对应的激励也不同：</p><p>根据这个例子，我们引出强化学习的一些概念：<br>1.状态(Status)：系统当前各状态变量的集合，一般把当前状态定义为s，下一状态定义为s’。<br>2.行动(Action)：系统从当前状态前往下一个状态可以采取的动作，一般把当前状态的行动定义为a，下一状态的行动定义为a’。<br>3.决策(Policy)：系统在当前状态的行为，是s到a的映射，也用函数π(s)=a表示。<br>4.激励(Reward)：系统处于当前状态可以获得或增加的分数，也用函数R(s)表示。<br>5.折扣因子(Discount Factor)：系统前往下一状态的惩罚，其现实意义是时间成本，取值为0-1，事实说明，折扣因子对正激励和负激励同时有效：对于正激励而言，我们总是希望早点得到；对于负激励而言，我们总是希望晚点被惩罚。<br>6.返回值(Return)：系统完成整个过程后得到的总分，由奖励和折扣因子决定。其公式有一般式和递推式两种形式。一般式的形式即为：Return=R1+γR2+γ2R3+…+γn-1Rn，其中R1为起点，Rn为中点，其余为中途路径点。递推式会在之后说明。<br>对于上面这个例子，状态1-6是状态，向左走和向右走是行动，在状态2下向右走是决策，状态1和状态6的分数是激励R(1)=100/R(6)=40/R(else)=0，时间成本0.9/0.5是折扣因子，72.9和32.4是返回值。<br>而强化学习的目标就是：在每个状态s下，找到一个决策π，告诉系统在该状态下做出行为a前往下一状态s’，从而使返回值return最大。事实上，这种过程也被称为马尔可夫决策过程(Markov Decision Process)，马尔可夫决策过程的特点是系统未来的输出只取决于当前的状态和行为，而与过去的状态与行为无关。</p><p>接下来介绍状态-动作价值函数(State-Action Value Function/Q-Function)，一般记作Q(s,a)，它的值由当前的状态和要采取的行动决定。它的定义是，如果在当前状态s下采取行动a，则我们可得到的最佳最终返回值Return是多少。以火星车为例，我们给出了在每个状态下向左走或向右走的最佳返回值，也就是Q(s,a)的值。以γ=0.5，Q(2,Right)为例，如果火星车要前往状态1，则路径为2-&gt;3-&gt;2-&gt;1，值为12.5；如果火星车要前往状态2，则路径为2-&gt;3-&gt;4-&gt;5-&gt;6，值为2.5，故Q(2,Right)=12.5。</p><p>总结一下，如果我们得知了每个状态采取每个行动的Q(s,a)，这就为我们提供了一种在任意状态得到最佳返回值的方法，也就是在任意状态都能找到最佳策略和行为的方法。<br>返回值的递推式被称为贝尔曼方程(Bellman Equation)，他可以用来计算状态-动作价值函数。<br>贝尔曼方程的格式为：</p><p>也就是说在当前状态s下采取行动a得到的最佳最终返回值等于当前状态s下的激励加上折扣因子乘以下一状态s’下采取最佳行动a’得到的最佳最终返回值。<br>例如Q(2,Right)=R(2)+0.5<em>max(a’){Q(3,a’)}=R(2)+0.5</em>max(Left){Q(3,Left)}=0+0.5<em>25=12.5<br>Q(4,Left)=R(4)+0.5</em>max(Left){Q(3,Left)}=R(4)+0.5<em>max(Left){Q(3,Left)}=0+0.5</em>25=12.5</p><p>在某些情况下，当我们采取行动时，结果并不总是完全可以确定的。例如我们要求火星车往左走，它可能会因为车轮打滑等因素反而往右走，在这种随机性环境下的强化学习被称为随机强化学习问题(Stochastic Reinforcement Learning)。对于这类问题，我们感兴趣的应该是采取每一行为后的预期结果的最大值，也就是期望的最大值，因为具体会得到的值是不确定的。<br>例如s=3，a=Left，此时得到的s’可能为2也可能为4，只是2的可能会更大而已。<br>于是此时的贝尔曼方程修改为：</p><p>之前谈论的火星车的例子，它实际上还是一个离散概念。现实世界中的应用往往是连续的状态空间，则此时的状态s应该是状态变量的合集，激励应该是在每一时刻动作的回馈。且对于连续状态空间系统而言，计算返回值时使用一般式是不现实的，只能使用贝尔曼方程计算，但关键在于我们怎么得到Q函数呢？这些疑问我们在之后会阐述。<br>我们以一个登月器的例子说明，我们定义它的状态变量为位置、角度、速度、角速度、左脚着地、右脚着地的集合，定义它每一时刻的激励如下：例如平稳着陆加分，坠毁减分，打开引擎减分（节能）等。</p><p>现在来解答怎么得到Q函数的疑惑，事实上，关键思想是我们需要训练一个神经网络去逼近最佳的状态动作值函数Q，而这反过来又可以让系统自行选择一个好的行动。在搭建神经网络时，输入一般是状态变量，而输出则是在该状态下可采取的所有行为，我们对这些所有可采取的行为进行比较，选择其中Q最大的作为真实的输出，也就是该状态下最优的行为。</p><p>现在的问题是我们怎么得到关于x,y的训练集从而训练这个神经网络。我们把目光投向贝尔曼方程，观察贝尔曼方程可知，当前的状态s和行为a组合在一起成为一个输入x，而R(s)+γmax(a’)Q(s’,a’)就是一个输出y。我们在每个时刻都可以观测到以下量：当前的状态s，当前的行为a，当前可以获得的激励R(s)，下一时刻的状态s’。利用这个元组(s,a,R(s),s’)，我们就可以完全已知这个时刻的输入x=[s,a]和输出y=R(s)+γmax(a’)Q(s’,a’)（其中Q就是一个关于a’的函数，max(a’)Q(s’,a’)求解这个函数的最大值，也是一个已知量）关系。如果我们随机在一个状态s下随机采取一个动作a，重复一万次，就可以得到一个含有一万个样本的样本集了，这个样本集中x是当前的状态和采取的行为，y是获得的分数，训练目标是得到一个好的Q使Q(s,a)=Q(x)=fw,b(x)≈y。利用这个样本集训练神经网络，就可以让它学会在什么状态采取什么行为才能得到一个好的激励，从而得到一个不错的运行结果了。<br>这个算法也被称为DQN(Deep Q-Network)算法，现在让我们总结一下整个流程：<br>1.构建神经网络，其中输入是状态s，输出是Q(s,all possible action for s)<br>2.随机初始化Q函数，此时Q函数的结果可能不是最优的<br>3.重复多次的随机在一个状态s下随机采取一个动作a，根据贝尔曼方程得到样本集[x,y]<br>4.利用得到的样本集训练神经网络得到新的Q函数（实际上是修改神经网络的w，b值），从而使得Q(s,a)=Q(x)的值更加接近于输出y。<br>5.更新Q函数并重复步骤4-5直到Q(x)≈y</p><p>上述算法存在一个小问题在于，当我们在构建样本集时，如果我们在某个状态任意的选取动作a，这可能会导致算法难以收敛，因为随机选取得到的a通常是一个坏动作。于是一个自然的选择是，尽管此时的Q不是最优的Q，但我们仍然去选择能使Q(s,a)最大的a来填充样本，也就是尽力而为。事实证明，这么做能给系统一个选择的参照，但可能会陷入局部最优，例如一个动作在当前的Q下收益高就一直去尝试这个动作，而不去考虑其他动作了。但由于这个Q并不是最佳的Q，这么做一定会使算法误入歧途。解决的办法也很自然，就是选取一个概率ε，算法有(1-ε)的可能性选择能使Q(s,a)最大的a来填充样本，也有ε的可能性任意选择a完成动作，这么做的好处在于既给了算法一个优化方向，又能让算法可以尝试不同的可能性，这种算法改进也称为ε-贪婪策略(Epsilon-greedy policy)。<br>此外，ε的取值往往也不是一成不变的。在算法的开始，由于Q的随机性，我们更应该鼓励算法尝试多种的可能，故一开始的ε会给的比较大；随着算法的进行，Q会越来越趋向于合理化，此时我们就要逐步减小ε的取值，来让算法跟着最优路径去走，以此得到良好的样本。</p><p>在强化学习中，还有两个优化方法可以使用：<br>小批量(Mini-Batches)，就像在监督学习中当样本集过大时，我们改批量梯度下降为部分梯度下降一样，在训练Q的样本集过大时，我们也可以采用选取部分训练集训练的方法来加快速度，例如我们可以把上面总量为10000的样本集每次使用其中1000个来训练神经网络。<br>软更新(Soft Updates)：之前神经网络的每次迭代，我们都会将Q更新为神经网络新得到的Q，如果这个新的Q偶然比原来的Q效果还要差，会导致神经网络的倒退，从而产生较大的噪声，使收敛不够可靠。软更新的方法可以避免我们只是因为一次不幸的调整式神经网络变得更糟。它的实现方法是，相比于每次都更新Q为一个与过去的Q完全无关的函数，我们可以选择一个系数k，使Q的更新既参考过去的Q又参考新得到的Q，也就是Q=kQnew+(1-k)Qlast<br>对应于神经网络参数即w=kwnew+(1-k)wlast，b=kbnew+(1-k)blast，k通常会取到0.01。利用软更新，可以有效的减少神经网络训练过程中的振荡和转向，从而实现更加可靠的收敛。</p>]]></content>
      
      
      <categories>
          
          <category> 人工智能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
    
    
    <entry>
      <title>屋主的随笔札记</title>
      <link href="/about/index.html"/>
      <url>/about/index.html</url>
      
        <content type="html"><![CDATA[<h1 id="1-你好！世界！"><a href="#1-你好！世界！" class="headerlink" title="1.你好！世界！"></a>1.你好！世界！</h1><p>&emsp;&emsp;嗨亲爱的朋友，欢迎光临寒舍！这里是屋主随风，在此携神秘小屋的全体职工对贵客的到来表示热烈欢迎！</p><hr><h1 id="2-关于我"><a href="#2-关于我" class="headerlink" title="2.关于我"></a>2.关于我</h1><ul><li><strong>称谓</strong>：随风</li><li><strong>性别</strong>：男</li><li><strong>生日</strong>：2003.05.16</li><li><strong>籍贯</strong>：浙江嘉兴</li><li><strong>身份</strong>：武汉大学电气与自动化学院2021级卓越工程师班在读本科生</li><li><strong>擅长&amp;喜欢</strong>：机器人、嵌入式、人工智能、控制理论等</li><li><strong>编程语言与工具</strong>：C、C#、C++、Keil、STM32F4、Python、ROS、PyTorch、Linux、OpenCV、yolo、Solidworks、嘉立创EDA等<br><br></li><li><strong>Hello,world!Programmed to work and not to feel.</strong></li><li><strong>Not even sure that this is real.</strong></li><li><strong>Hello,world!Find my voice.</strong></li><li><strong>Although it sounds like bits and bytes.</strong></li><li><strong>My circuitry is filled with mites.</strong></li><li><strong>Hello,world.</strong></li><li><strong>Oh,will I find a love?Oh,or a power plug?</strong></li><li><strong>Oh,digitally isolated.Oh,creator,please don’t leave me waiting…</strong></li><li><strong>Hello,world…Programmed to work and not to feel…</strong></li><li><strong>Not even sure that this is real…</strong></li><li><strong>Hello,world…</strong></li></ul><hr><h1 id="3-联系我"><a href="#3-联系我" class="headerlink" title="3.联系我"></a>3.联系我</h1><ul><li>电话：+86 18457300516</li><li>邮箱：1397799304@qq.com（首选）<br>&emsp;&emsp;&emsp;2021302191274@whu.edu.cn<br>&emsp;&emsp;&emsp;huamuweiyou@gmail.com</li><li>QQ：1397799304</li><li>微信：sc1397799304</li><li>B站：CJH随风</li></ul><hr><h1 id="4-关于网站"><a href="#4-关于网站" class="headerlink" title="4.关于网站"></a>4.关于网站</h1><ul><li><strong>博客框架</strong>：<a href="https://github.com/hexojs/hexo">Hexo 6.3.0</a></li><li><strong>主题</strong>：<a href="https://butterfly.js.org/">Butterfly 4.3.1</a></li><li><strong>源码仓库</strong>：<a href="https://github.com/">Github</a></li><li><strong>托管与部署</strong>：<a href="https://vercel.com/">Vercel</a></li><li><strong>服务器与域名</strong>：<a href="https://www.aliyun.com/">阿里云</a></li><li><strong>开发语言</strong>：HTML5 + CSS3 + JavaScript + YML等</li><li><strong>图床</strong>：<a href="https://www.lolcheng-picbed.top">https://www.lolcheng-picbed.top</a></li><li><strong>特别鸣谢</strong>：<a href="https://www.fomal.cc/">Fomalhaut🥝</a></li><li><strong>网站开源地址</strong>：<a href="https://github.com/lolcheng/lolcheng.github.io">https://github.com/lolcheng/lolcheng.github.io</a><br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<a href="https://github.com/lolcheng/lolcheng-picbed">https://github.com/lolcheng/lolcheng-picbed</a><br><br></li><li><strong>技术无界，感谢每一位开源作者</strong></li></ul><hr><h1 id="5-写在最后"><a href="#5-写在最后" class="headerlink" title="5.写在最后"></a>5.写在最后</h1><ul><li><strong>搭建初衷</strong>：作为一个非科班的学生，一直觉得拥有自己的独立网站是一件十分酷的事情！这样就相当于拥有自己独立的空间，不用去CSDN这些网站上写博客或者用有道云笔记去记笔记。网站成为了自己的一个名片，在上面写写东西，记录生活，分享知识，把自己想与他人展现的技能放在博客上，何尝不是一件有趣的事情！</li><li><strong>博客内容</strong>：本人做的笔记与总结<!-- - **想法**：为什么当初会阴差阳错地选择了Hexo这样的静态博客作为自己的网站框架呢？(这直接导致了后面在美化博客的道路上渐行渐远…)。其实最初是看见三叶姐弄了个Hexo博客，觉得好厉害，是二次元风格的(觉得用来装逼十分合适)，于是在她的安利之下自己也萌生了想弄一个博客的想法🌈。后面逐渐了解到，Hexo这种静态博客相比于WordPress这些动态博客，可以不用购买服务器，网站的运营费用主要是域名费用(白嫖)。而采用动态博客就必须自己租云服务器，虽然WordPress部署起来更加简单，不用折腾那么多(但是我是一个比较喜欢折腾的人🤣)。还有一个就是Hexo这个框架非常轻量化，启动速度很快，且可拓展性十分强大，可以自己定义任何东西，非常考验自己的前端基础(虽然很多是cv的)。平时在电脑上装好对应的NodeJs环境，写一写Markdown文件然后直接推送到github仓库就会全自动部署，网站就可以将笔记渲染成十分好看的网页和布局，这种自动化部署和精美的页面是一种能让人十分愉快的体验(当然前期得折腾很多东西啦)。比如我2022年8-12月这段时间花了大量时间来倒腾博客和学习一些前端的知识，逛别人博客时看到好看的就想搬到自己的网站上😂，最后基本上就弄成现在这个样子。同时在B站做的视频也越来越多人看，截止目前为止网站的总访问量已经接近26w，B站的粉丝也突破了1400个，这也算是一点小小的成就和一笔小财富吧！在魔改博客的过程中也认识了非常多志同道合的小伙伴，也少不了各路前端大佬的帮助和指导，在此表示非常感激！群里新加入的小伙伴也越来越多，目前已经有600多个了。在这几个月以来，自己对于Butterfly主题的了解也在逐渐加深，认识到主题作者这种大神的前端功底是如此之深！我自己也从一只不敢动源码的小菜鸡到现在会自己改一些简单源码，在原来主题的基础上进行二次开发。这种能力的提升要全身心去投入才会感受到，这也意味着博客的样式可以根据自己的想法去实现，打造一个完全属于自己的网站。看到很多小伙伴看了自己的视频之后，以自己的教程作为蓝图，参考着搭建起网站就感到非常自豪。目前博客已开源，站长的初衷是让更多小白可以快速搭建起好看好用的个人网站，最后也感谢各位小伙伴的支持！！！ --></li></ul>]]></content>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/css/custom.css"/>
      <url>/css/custom.css</url>
      
        <content type="html"><![CDATA[/* 页脚与头图透明 */#footer {    background: transparent !important;}#page-header {    background: transparent !important;}/* 白天模式遮罩透明 */#footer::before {    background: transparent !important;}#page-header::before {    background: transparent !important;}/* 夜间模式遮罩透明 */[data-theme="dark"] #footer::before {    background: transparent !important;}[data-theme="dark"] #page-header::before {    background: transparent !important;}/* 小冰分类分类磁铁黑夜模式适配 *//* 一般状态 */[data-theme="dark"] .magnet_link_context {    background: #1e1e1e;    color: antiquewhite;}/* 鼠标悬浮状态 */[data-theme="dark"] .magnet_link_context:hover {    background: #3ecdf1;    color: #f2f2f2;}/* 翻页按钮居中 */#pagination {    width: 100%;    margin: auto;}/* 鼠标样式 */#cursor {    position: fixed;    width: 16px;    height: 16px;    /* 这里改变跟随的底色 */    background: rgb(57, 197, 187);    border-radius: 8px;    opacity: 0.25;    z-index: 10086;    pointer-events: none;    transition: 0.2s ease-in-out;    transition-property: background, opacity, transform;}#cursor.hidden {    opacity: 0;}#cursor.hover {    opacity: 0.1;    transform: scale(2.5);    -webkit-transform: scale(2.5);    -moz-transform: scale(2.5);    -ms-transform: scale(2.5);    -o-transform: scale(2.5);}#cursor.active {    opacity: 0.5;    transform: scale(0.5);    -webkit-transform: scale(0.5);    -moz-transform: scale(0.5);    -ms-transform: scale(0.5);    -o-transform: scale(0.5);}:root {    --trans-light: rgba(255, 255, 255, 0.88);    --trans-dark: rgba(25, 25, 25, 0.88);    --border-style: 1px solid rgb(169, 169, 169);    --backdrop-filter: blur(5px) saturate(150%);}/* 首页文章卡片 */#recent-posts>.recent-post-item {    background: var(--trans-light);    backdrop-filter: var(--backdrop-filter);    border-radius: 25px;    border: var(--border-style);}/* 首页侧栏卡片 */#aside-content .card-widget {    background: var(--trans-light);    backdrop-filter: var(--backdrop-filter);    border-radius: 18px;    border: var(--border-style);}/* 文章页、归档页、普通页面 */div#post,div#page,div#archive {    background: var(--trans-light);    backdrop-filter: var(--backdrop-filter);    border: var(--border-style);    border-radius: 20px;}/* 导航栏 */#page-header.nav-fixed #nav {    background: rgba(255, 255, 255, 0.75);    backdrop-filter: var(--backdrop-filter);}[data-theme="dark"] #page-header.nav-fixed #nav {    background: rgba(0, 0, 0, 0.7) !important;}/* 夜间模式遮罩 */[data-theme="dark"] #recent-posts>.recent-post-item,[data-theme="dark"] #aside-content .card-widget,[data-theme="dark"] div#post,[data-theme="dark"] div#archive,[data-theme="dark"] div#page {    background: var(--trans-dark);}/* 夜间模式页脚页头遮罩透明 */[data-theme="dark"] #footer::before {    background: transparent !important;}[data-theme="dark"] #page-header::before {    background: transparent !important;}/* 阅读模式 */.read-mode #aside-content .card-widget {    background: rgba(158, 204, 171, 0.5) !important;}.read-mode div#post {    background: rgba(158, 204, 171, 0.5) !important;}/* 夜间模式下的阅读模式 */[data-theme="dark"] .read-mode #aside-content .card-widget {    background: rgba(25, 25, 25, 0.9) !important;    color: #ffffff;}[data-theme="dark"] .read-mode div#post {    background: rgba(25, 25, 25, 0.9) !important;    color: #ffffff;}/* 日间模式不生效 */[data-theme="light"] #site-name,[data-theme="light"] #site-title,[data-theme="light"] #site-subtitle,[data-theme="light"] #post-info {    animation: none;}/* 夜间模式生效 */[data-theme="dark"] #site-name,[data-theme="dark"] #site-title {    animation: light_15px 10s linear infinite;}[data-theme="dark"] #site-subtitle {    animation: light_10px 10s linear infinite;}[data-theme="dark"] #post-info {    animation: light_5px 10s linear infinite;}/* 黑夜霓虹灯，关键帧描述 */@keyframes light_15px {    0% {        text-shadow: #5636ed 0 0 15px;    }    12.5% {        text-shadow: #11ee5e 0 0 15px;    }    25% {        text-shadow: #f14747 0 0 15px;    }    37.5% {        text-shadow: #f1a247 0 0 15px;    }    50% {        text-shadow: #f1ee47 0 0 15px;    }    50% {        text-shadow: #b347f1 0 0 15px;    }    62.5% {        text-shadow: #002afa 0 0 15px;    }    75% {        text-shadow: #ed709b 0 0 15px;    }    87.5% {        text-shadow: #39c5bb 0 0 15px;    }    100% {        text-shadow: #5636ed 0 0 15px;    }}@keyframes light_10px {    0% {        text-shadow: #5636ed 0 0 10px;    }    12.5% {        text-shadow: #11ee5e 0 0 10px;    }    25% {        text-shadow: #f14747 0 0 10px;    }    37.5% {        text-shadow: #f1a247 0 0 10px;    }    50% {        text-shadow: #f1ee47 0 0 10px;    }    50% {        text-shadow: #b347f1 0 0 10px;    }    62.5% {        text-shadow: #002afa 0 0 10px;    }    75% {        text-shadow: #ed709b 0 0 10px;    }    87.5% {        text-shadow: #39c5bb 0 0 10px;    }    100% {        text-shadow: #5636ed 0 0 10px;    }}@keyframes light_5px {    0% {        text-shadow: #5636ed 0 0 5px;    }    12.5% {        text-shadow: #11ee5e 0 0 5px;    }    25% {        text-shadow: #f14747 0 0 5px;    }    37.5% {        text-shadow: #f1a247 0 0 15px;    }    50% {        text-shadow: #f1ee47 0 0 5px;    }    50% {        text-shadow: #b347f1 0 0 5px;    }    62.5% {        text-shadow: #002afa 0 0 5px;    }    75% {        text-shadow: #ed709b 0 0 5px;    }    87.5% {        text-shadow: #39c5bb 0 0 5px;    }    100% {        text-shadow: #5636ed 0 0 5px;    }}]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>分类</title>
      <link href="/categories/index.html"/>
      <url>/categories/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/css/universe.css"/>
      <url>/css/universe.css</url>
      
        <content type="html"><![CDATA[/* 背景宇宙星光  */#universe {    display: block;    position: fixed;    margin: 0;    padding: 0;    border: 0;    outline: 0;    left: 0;    top: 0;    width: 100%;    height: 100%;    pointer-events: none;    /* 这个是调置顶的优先级的，-1在文章页下面，背景上面，个人推荐这种 */    z-index: -1;}]]></content>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/js/universe.js"/>
      <url>/js/universe.js</url>
      
        <content type="html"><![CDATA[function dark() { window.requestAnimationFrame = window.requestAnimationFrame || window.mozRequestAnimationFrame || window.webkitRequestAnimationFrame || window.msRequestAnimationFrame; var n, e, i, h, t = .05, s = document.getElementById("universe"), o = !0, a = "180,184,240", r = "226,225,142", d = "226,225,224", c = []; function f() { n = window.innerWidth, e = window.innerHeight, i = .216 * n, s.setAttribute("width", n), s.setAttribute("height", e) } function u() { h.clearRect(0, 0, n, e); for (var t = c.length, i = 0; i < t; i++) { var s = c[i]; s.move(), s.fadeIn(), s.fadeOut(), s.draw() } } function y() { this.reset = function () { this.giant = m(3), this.comet = !this.giant && !o && m(10), this.x = l(0, n - 10), this.y = l(0, e), this.r = l(1.1, 2.6), this.dx = l(t, 6 * t) + (this.comet + 1 - 1) * t * l(50, 120) + 2 * t, this.dy = -l(t, 6 * t) - (this.comet + 1 - 1) * t * l(50, 120), this.fadingOut = null, this.fadingIn = !0, this.opacity = 0, this.opacityTresh = l(.2, 1 - .4 * (this.comet + 1 - 1)), this.do = l(5e-4, .002) + .001 * (this.comet + 1 - 1) }, this.fadeIn = function () { this.fadingIn && (this.fadingIn = !(this.opacity > this.opacityTresh), this.opacity += this.do) }, this.fadeOut = function () { this.fadingOut && (this.fadingOut = !(this.opacity < 0), this.opacity -= this.do / 2, (this.x > n || this.y < 0) && (this.fadingOut = !1, this.reset())) }, this.draw = function () { if (h.beginPath(), this.giant) h.fillStyle = "rgba(" + a + "," + this.opacity + ")", h.arc(this.x, this.y, 2, 0, 2 * Math.PI, !1); else if (this.comet) { h.fillStyle = "rgba(" + d + "," + this.opacity + ")", h.arc(this.x, this.y, 1.5, 0, 2 * Math.PI, !1); for (var t = 0; t < 30; t++)h.fillStyle = "rgba(" + d + "," + (this.opacity - this.opacity / 20 * t) + ")", h.rect(this.x - this.dx / 4 * t, this.y - this.dy / 4 * t - 2, 2, 2), h.fill() } else h.fillStyle = "rgba(" + r + "," + this.opacity + ")", h.rect(this.x, this.y, this.r, this.r); h.closePath(), h.fill() }, this.move = function () { this.x += this.dx, this.y += this.dy, !1 === this.fadingOut && this.reset(), (this.x > n - n / 4 || this.y < 0) && (this.fadingOut = !0) }, setTimeout(function () { o = !1 }, 50) } function m(t) { return Math.floor(1e3 * Math.random()) + 1 < 10 * t } function l(t, i) { return Math.random() * (i - t) + t } f(), window.addEventListener("resize", f, !1), function () { h = s.getContext("2d"); for (var t = 0; t < i; t++)c[t] = new y, c[t].reset(); u() }(), function t() { document.getElementsByTagName('html')[0].getAttribute('data-theme') == 'dark' && u(), window.requestAnimationFrame(t) }() };dark()]]></content>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/js/cursor.js"/>
      <url>/js/cursor.js</url>
      
        <content type="html"><![CDATA[var CURSOR;Math.lerp = (a, b, n) => (1 - n) * a + n * b;const getStyle = (el, attr) => {    try {        return window.getComputedStyle            ? window.getComputedStyle(el)[attr]            : el.currentStyle[attr];    } catch (e) { }    return "";};class Cursor {    constructor() {        this.pos = { curr: null, prev: null };        this.pt = [];        this.create();        this.init();        this.render();    }    move(left, top) {        this.cursor.style["left"] = `${left}px`;        this.cursor.style["top"] = `${top}px`;    }    create() {        if (!this.cursor) {            this.cursor = document.createElement("div");            this.cursor.id = "cursor";            this.cursor.classList.add("hidden");            document.body.append(this.cursor);        }        var el = document.getElementsByTagName('*');        for (let i = 0; i < el.length; i++)            if (getStyle(el[i], "cursor") == "pointer")                this.pt.push(el[i].outerHTML);        document.body.appendChild((this.scr = document.createElement("style")));        // 这里改变鼠标指针的颜色 由svg生成        this.scr.innerHTML = `* {cursor: url("data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 8 8' width='8px' height='8px'><circle cx='4' cy='4' r='4' opacity='1.0' fill='rgb(57, 197, 187)'/></svg>") 4 4, auto}`;    }    refresh() {        this.scr.remove();        this.cursor.classList.remove("hover");        this.cursor.classList.remove("active");        this.pos = { curr: null, prev: null };        this.pt = [];        this.create();        this.init();        this.render();    }    init() {        document.onmouseover = e => this.pt.includes(e.target.outerHTML) && this.cursor.classList.add("hover");        document.onmouseout = e => this.pt.includes(e.target.outerHTML) && this.cursor.classList.remove("hover");        document.onmousemove = e => { (this.pos.curr == null) && this.move(e.clientX - 8, e.clientY - 8); this.pos.curr = { x: e.clientX - 8, y: e.clientY - 8 }; this.cursor.classList.remove("hidden"); };        document.onmouseenter = e => this.cursor.classList.remove("hidden");        document.onmouseleave = e => this.cursor.classList.add("hidden");        document.onmousedown = e => this.cursor.classList.add("active");        document.onmouseup = e => this.cursor.classList.remove("active");    }    render() {        if (this.pos.prev) {            this.pos.prev.x = Math.lerp(this.pos.prev.x, this.pos.curr.x, 0.15);            this.pos.prev.y = Math.lerp(this.pos.prev.y, this.pos.curr.y, 0.15);            this.move(this.pos.prev.x, this.pos.prev.y);        } else {            this.pos.prev = this.pos.curr;        }        requestAnimationFrame(() => this.render());    }}(() => {    CURSOR = new Cursor();    // 需要重新获取列表时，使用 CURSOR.refresh()})();]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>友链</title>
      <link href="/link/index.html"/>
      <url>/link/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>电影</title>
      <link href="/movies/index.html"/>
      <url>/movies/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>音乐</title>
      <link href="/music/index.html"/>
      <url>/music/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
    
    <entry>
      <title>tags</title>
      <link href="/tags/index.html"/>
      <url>/tags/index.html</url>
      
        <content type="html"><![CDATA[]]></content>
      
    </entry>
    
    
  
</search>
